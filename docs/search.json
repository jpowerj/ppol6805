[
  {
    "objectID": "w14/slides.html#references",
    "href": "w14/slides.html#references",
    "title": "Week 14: Final Project Poster Session",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "w14/index.html",
    "href": "w14/index.html",
    "title": "Week 14: Final Project Poster Session",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 14: Dec 3"
    ]
  },
  {
    "objectID": "w14/index.html#references",
    "href": "w14/index.html#references",
    "title": "Week 14: Final Project Poster Session",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 14: Dec 3"
    ]
  },
  {
    "objectID": "w12/slides.html#final-project-details",
    "href": "w12/slides.html#final-project-details",
    "title": "Week 12: Tools for Final Projects",
    "section": "Final Project Details",
    "text": "Final Project Details\n\nProject Showcase: 6:30-9pm, Wed, December 3, 2025\n\nCome eat falafel and show off your cool visualizations and regression coefficients!\n\nReports: Due 5:59pm, Fri, December 12, 2025\n\nIf you‚Äôre in DSAN 6000 and you‚Äôre worried about that final project‚Ä¶ See next slide!"
  },
  {
    "objectID": "w12/slides.html#due-date-details",
    "href": "w12/slides.html#due-date-details",
    "title": "Week 12: Tools for Final Projects",
    "section": "Due Date Details",
    "text": "Due Date Details"
  },
  {
    "objectID": "w12/slides.html#presentation-setup",
    "href": "w12/slides.html#presentation-setup",
    "title": "Week 12: Tools for Final Projects",
    "section": "Presentation Setup",
    "text": "Presentation Setup\n\nEach of your desks becomes a ‚Äútable‚Äù at a GIS conference!\nEveryone can go around and ask others about projects üòª\nBut, FOOD \\(\\implies\\) you can also stay!"
  },
  {
    "objectID": "w12/slides.html#report-setup",
    "href": "w12/slides.html#report-setup",
    "title": "Week 12: Tools for Final Projects",
    "section": "Report Setup",
    "text": "Report Setup\n\nGitHub repository (for your portfolio!)\n\nGH Pages site: your_username.github.io/gis-project\n\n‚Ä¶What do you put in that GitHub repository?\nQuarto Manuscript\nWhat do you put in the Quarto manuscript?\nWriteup + Visualizations + Code, interspersed!\n\n‚ÄúLiterate Programming‚Äù \\(\\Rightarrow\\) Reproducible Results!"
  },
  {
    "objectID": "w12/slides.html#motivation-when-does-non-spatial-regression-work",
    "href": "w12/slides.html#motivation-when-does-non-spatial-regression-work",
    "title": "Week 12: Tools for Final Projects",
    "section": "Motivation: When Does Non-Spatial Regression ‚ÄúWork‚Äù?",
    "text": "Motivation: When Does Non-Spatial Regression ‚ÄúWork‚Äù?\n\\[\nY_i = \\beta_0 + \\beta_1X_{i,1} + \\beta_2X_{i,2} + \\cdots + \\beta_MX_{i,M} + \\varepsilon_i\n\\]\n\nImportance of OLS regression: can give us the Best Linear Unbiased Estimator (BLUE)\nThis is only true if the Gauss-Markov assumptions hold‚Äîone of these is that the error terms are uncorrelated:\n\\[\n\\text{Cov}[\\varepsilon_i, \\varepsilon_j] = 0 \\; \\forall i \\neq j\n\\]"
  },
  {
    "objectID": "w12/slides.html#spatial-autocorrelation-in-residuals",
    "href": "w12/slides.html#spatial-autocorrelation-in-residuals",
    "title": "Week 12: Tools for Final Projects",
    "section": "Spatial Autocorrelation in Residuals",
    "text": "Spatial Autocorrelation in Residuals\n\nWe have now seen several models / datasets where effect of some variable \\(X\\) (say, population) on another variable \\(Y\\) (say, disease count) is spatial! (Kind of the whole point of the class üòú)\nSo, to see when OLS will ‚Äúwork‚Äù, vs.¬†when you need to incorporate GIS, key step is plotting the spatial distribution of regression residuals!"
  },
  {
    "objectID": "w12/slides.html#example-italian-elections",
    "href": "w12/slides.html#example-italian-elections",
    "title": "Week 12: Tools for Final Projects",
    "section": "Example: Italian Elections",
    "text": "Example: Italian Elections\n\n\n\n\n\nWard and Gleditsch (2018), Figure 2.3\n\n\n\n\n\n\nWard and Gleditsch (2018), Figure 2.4"
  },
  {
    "objectID": "w12/slides.html#will-ols-work-here",
    "href": "w12/slides.html#will-ols-work-here",
    "title": "Week 12: Tools for Final Projects",
    "section": "Will OLS ‚ÄúWork‚Äù Here?",
    "text": "Will OLS ‚ÄúWork‚Äù Here?\n\nCan we use OLS to derive the BLUE of the effect of GDP on voting?\n\n\n\n\nPlain OLS\n\n\n\n\n\\(N = 477\\)\n\\(\\widehat{\\beta}\\)\nSE\n\\(t\\)\n\n\n\n\nIntercept\n35.30\n2.21\n15.96\n\n\nLog GDP per cap\n13.46\n0.65\n20.84\n\n\n\nMoran‚Äôs \\(I\\) for residuals = 0.47(!)\n\n¬†\n\n\nSpatial Regression\n\n\n\n\n\\(N = 477\\)\n\\(\\widehat{\\beta}\\)\nSE\n\\(t\\)\n\n\n\n\nIntercept\n4.70\n1.66\n2.80\n\n\nLog GDP per cap\n1.77\n0.48\n3.66\n\n\n\\(\\rho\\)\n0.87\n0.02\n36.7"
  },
  {
    "objectID": "w12/slides.html#what-does-it-mean-that-spatial-effect-is-significant",
    "href": "w12/slides.html#what-does-it-mean-that-spatial-effect-is-significant",
    "title": "Week 12: Tools for Final Projects",
    "section": "What Does it Mean that ‚ÄúSpatial Effect‚Äù is Significant?",
    "text": "What Does it Mean that ‚ÄúSpatial Effect‚Äù is Significant?\n\n(From the future‚Ä¶ your HW4!)"
  },
  {
    "objectID": "w12/slides.html#case-1-no-residual-spatial-autocorrelation",
    "href": "w12/slides.html#case-1-no-residual-spatial-autocorrelation",
    "title": "Week 12: Tools for Final Projects",
    "section": "Case 1: No Residual Spatial Autocorrelation",
    "text": "Case 1: No Residual Spatial Autocorrelation\n\nExample: Residuals have Moran‚Äôs \\(I\\) near 0‚Ä¶\n‚Ä¶Don‚Äôt need GIS at all!"
  },
  {
    "objectID": "w12/slides.html#case-2-conditional-autoregressive-model-car",
    "href": "w12/slides.html#case-2-conditional-autoregressive-model-car",
    "title": "Week 12: Tools for Final Projects",
    "section": "Case 2: Conditional Autoregressive Model (CAR)",
    "text": "Case 2: Conditional Autoregressive Model (CAR)\n\nGIS, but‚Ä¶ only for ‚Äúfixing‚Äù your regression\n\n\\[\nY_i = \\underbrace{\\mu_i}_{\\text{Non-spatial model}} + \\underbrace{\\frac{1}{w_{i,\\cdot}}\\sum_{j \\neq i}(Y_j - \\mu_j)}_{\\text{Spatial Autocorrelation}} + \\varepsilon_i\n\\]"
  },
  {
    "objectID": "w12/slides.html#case-3-simultaneous-autoregressive-model-sar",
    "href": "w12/slides.html#case-3-simultaneous-autoregressive-model-sar",
    "title": "Week 12: Tools for Final Projects",
    "section": "Case 3: Simultaneous Autoregressive Model (SAR)",
    "text": "Case 3: Simultaneous Autoregressive Model (SAR)\n\nThe main event! Here we are explicitly modeling ‚Äúspatially lagged‚Äù versions of our dependent variable \\(Y\\)!\n\n\\[\nY = \\mathbf{X}\\beta + \\rho \\underbrace{\\mathbf{W}Y}_{\\mathclap{\\text{Spatially-lagged }Y}} + \\boldsymbol\\varepsilon\n\\]"
  },
  {
    "objectID": "w12/slides.html#research-methodology-hypotheses",
    "href": "w12/slides.html#research-methodology-hypotheses",
    "title": "Week 12: Tools for Final Projects",
    "section": "Research Methodology: Hypotheses",
    "text": "Research Methodology: Hypotheses\n\nSocial Science (McCourt):\n\n\n\nMachine Learning (DSAN):"
  },
  {
    "objectID": "w12/slides.html#secretly-my-opportunity-to-do-more-spatial-regression",
    "href": "w12/slides.html#secretly-my-opportunity-to-do-more-spatial-regression",
    "title": "Week 12: Tools for Final Projects",
    "section": "(Secretly My Opportunity to do More Spatial Regression!)",
    "text": "(Secretly My Opportunity to do More Spatial Regression!)\n\nWhat explains previously-observed instances of separatist insurgencies?\nCan we predict separatist insurgencies?\nOne (spatial) idea: how far away are [centers of power] from [regions of countervailing power]?\n\\(X\\) = Distance from capital, \\(Y\\) = Insurgency\nUnit of observation: Regions? Insurgent uprisings? Countries?"
  },
  {
    "objectID": "w12/slides.html#operationalizing",
    "href": "w12/slides.html#operationalizing",
    "title": "Week 12: Tools for Final Projects",
    "section": "Operationalizing",
    "text": "Operationalizing\n\nThe variables in previous slide are conceptual\nOperationalizing = ‚ÄúTurning into measurable quantities‚Äù\n\\(X\\) = MeanDistance(Capital, Insurgent Region), \\(Y = \\mathbf{1}[\\text{Insurgency}]\\)\nAlternative:\n\n\\[\nY = \\begin{cases}\n2 &\\text{if Successful Insurgency} \\\\\n1 &\\text{if Failed Insurgency} \\\\\n0 &\\text{if No Insurgency}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "w12/slides.html#connection-matrices",
    "href": "w12/slides.html#connection-matrices",
    "title": "Week 12: Tools for Final Projects",
    "section": "Connection Matrices",
    "text": "Connection Matrices\n\nspdep\nNeighbors if Centroids are close\nNeighbors if Capitals are close\nü§î"
  },
  {
    "objectID": "w12/slides.html#visualizing-spatial-data",
    "href": "w12/slides.html#visualizing-spatial-data",
    "title": "Week 12: Tools for Final Projects",
    "section": "Visualizing Spatial Data",
    "text": "Visualizing Spatial Data\n\nMy recommendation for final presentations: Tiptoe from mapview \\(\\leadsto\\) Leaflet!\n\n\n\n\nCode\n# library(osmdata) |&gt; suppressPackageStartupMessages()\n# library(leaflet)\n# assign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\n# placebb &lt;- osmdata::getbb(\"Barcelona\")\n# hospitals &lt;- placebb |&gt;\n#   opq() |&gt;\n#   add_osm_feature(key = \"amenity\", value = \"hospital\") |&gt;\n#   osmdata_sf()\n# motorways &lt;- placebb |&gt;\n#   opq() |&gt;\n#   add_osm_feature(\n#     key = \"highway\",\n#     value = \"motorway\"\n#   ) |&gt;\n#   osmdata_sf()\n# leaflet() |&gt;\n#   addTiles() |&gt;\n#   addPolylines(\n#     data = motorways$osm_lines,\n#     color = \"black\"\n#   ) |&gt;\n#   addPolygons(\n#     data = hospitals$osm_polygons,\n#     label = hospitals$osm_polygons$name\n#   )"
  },
  {
    "objectID": "w12/slides.html#custom-icons",
    "href": "w12/slides.html#custom-icons",
    "title": "Week 12: Tools for Final Projects",
    "section": "Custom Icons!",
    "text": "Custom Icons!\n\n\n\n\nChicago\nDetroit\n\n\n\n\nPopulation\n2,746,388\n631,524\n\n\n\n\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet.extras2) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\ncity_df &lt;- tibble::tribble(\n  ~city, ~lon, ~lat, ~pop,\n  \"Chicago\", 41.950567516553896, -87.93011127491978, 2746388,\n  \"Detroit\", 42.45123004999075, -83.18402319217698, 631524\n)\ncity_sf &lt;- sf::st_as_sf(\n  city_df,\n  coords = c(\"lat\", \"lon\"),\n  crs=4326\n)\ncity_buf_sf &lt;- city_sf |&gt; sf::st_buffer(20000)\ncity_cases_sf &lt;- city_buf_sf |&gt; sf::st_sample(size=rep(10,2)) |&gt; sf::st_as_sf()\ncity_cases_sf$city &lt;- \"Detroit (10 Cases)\"\ncity_cases_sf[1:10, 'city'] &lt;- \"Chicago (10 Cases)\"\ncity_cases_sf$sample &lt;- \"Flu\"\ncity_pop_sf &lt;- city_buf_sf |&gt;\n  sf::st_sample(size=c(16, 4)) |&gt; sf::st_as_sf()\ncity_pop_sf$city &lt;- \"Detroit\"\ncity_pop_sf[1:16, 'city'] &lt;- \"Chicago\"\ncity_pop_sf$sample &lt;- \"People\"\ncity_combined_sf &lt;- bind_rows(city_cases_sf, city_pop_sf)\n# mapview(city_combined_sf, zcol=\"city\", marker=\"sample\")\nFlu = makeIcon(\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/240px-Maki2-danger-24.svg.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/24px-Maki2-danger-24.svg.png\",\n    20,\n    20\n)\nPeople = makeIcon(\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  20,\n  20\n)\n\ncity_combined_sf$r &lt;- ifelse(city_combined_sf$sample == \"Flu\", 0, 4)\ncity_flu_sf &lt;- city_combined_sf |&gt; filter(sample == \"Flu\")\ncity_ppl_sf &lt;- city_combined_sf |&gt; filter(sample == \"People\")\nleaflet(city_flu_sf) |&gt;\n  addProviderTiles(\"CartoDB.Positron\") |&gt;\n  addMarkers(data=city_flu_sf, icon = Flu) |&gt;\n  addMarkers(data=city_ppl_sf, icon = People)"
  },
  {
    "objectID": "w12/slides.html#remote-sensed-raster-data",
    "href": "w12/slides.html#remote-sensed-raster-data",
    "title": "Week 12: Tools for Final Projects",
    "section": "Remote-Sensed / Raster Data",
    "text": "Remote-Sensed / Raster Data\n\nYou‚Äôve seen (to some extent) terra\nstars: Same group behind sf\nGoogle solar panel data\n.tif files: Dynamically loaded"
  },
  {
    "objectID": "w12/slides.html#anonymization-synthetic-datasets",
    "href": "w12/slides.html#anonymization-synthetic-datasets",
    "title": "Week 12: Tools for Final Projects",
    "section": "Anonymization / Synthetic Datasets",
    "text": "Anonymization / Synthetic Datasets\n\nDifferential privacy\nUsed by the US Census(!) Since 2020"
  },
  {
    "objectID": "w12/slides.html#example-bolshevik-revolution-rightarrow-bipolar-world",
    "href": "w12/slides.html#example-bolshevik-revolution-rightarrow-bipolar-world",
    "title": "Week 12: Tools for Final Projects",
    "section": "Example: Bolshevik Revolution \\(\\rightarrow\\) ‚ÄúBipolar‚Äù World",
    "text": "Example: Bolshevik Revolution \\(\\rightarrow\\) ‚ÄúBipolar‚Äù World\n\n\nNull hypothesis: no spatial effect of democratization/de-democratization on neighboring countries\nIf null hypothesis is true, and countries democratize/de-democratize independently‚Ä¶ could this pattern still arise?"
  },
  {
    "objectID": "w12/slides.html#references",
    "href": "w12/slides.html#references",
    "title": "Week 12: Tools for Final Projects",
    "section": "References",
    "text": "References\n\n\nWard, Michael D., and Kristian Skrede Gleditsch. 2018. Spatial Regression Models. SAGE Publications."
  },
  {
    "objectID": "w12/index.html",
    "href": "w12/index.html",
    "title": "Week 12: Tools for Final Projects",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#final-project-details",
    "href": "w12/index.html#final-project-details",
    "title": "Week 12: Tools for Final Projects",
    "section": "Final Project Details",
    "text": "Final Project Details\n\nProject Showcase: 6:30-9pm, Wed, December 3, 2025\n\nCome eat falafel and show off your cool visualizations and regression coefficients!\n\nReports: Due 5:59pm, Fri, December 12, 2025\n\nIf you‚Äôre in DSAN 6000 and you‚Äôre worried about that final project‚Ä¶ See next slide!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#due-date-details",
    "href": "w12/index.html#due-date-details",
    "title": "Week 12: Tools for Final Projects",
    "section": "Due Date Details",
    "text": "Due Date Details",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#presentation-setup",
    "href": "w12/index.html#presentation-setup",
    "title": "Week 12: Tools for Final Projects",
    "section": "Presentation Setup",
    "text": "Presentation Setup\n\nEach of your desks becomes a ‚Äútable‚Äù at a GIS conference!\nEveryone can go around and ask others about projects üòª\nBut, FOOD \\(\\implies\\) you can also stay!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#report-setup",
    "href": "w12/index.html#report-setup",
    "title": "Week 12: Tools for Final Projects",
    "section": "Report Setup",
    "text": "Report Setup\n\nGitHub repository (for your portfolio!)\n\nGH Pages site: your_username.github.io/gis-project\n\n‚Ä¶What do you put in that GitHub repository?\nQuarto Manuscript\nWhat do you put in the Quarto manuscript?\nWriteup + Visualizations + Code, interspersed!\n\n‚ÄúLiterate Programming‚Äù \\(\\Rightarrow\\) Reproducible Results!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#motivation-when-does-non-spatial-regression-work",
    "href": "w12/index.html#motivation-when-does-non-spatial-regression-work",
    "title": "Week 12: Tools for Final Projects",
    "section": "Motivation: When Does Non-Spatial Regression ‚ÄúWork‚Äù?",
    "text": "Motivation: When Does Non-Spatial Regression ‚ÄúWork‚Äù?\n\\[\nY_i = \\beta_0 + \\beta_1X_{i,1} + \\beta_2X_{i,2} + \\cdots + \\beta_MX_{i,M} + \\varepsilon_i\n\\]\n\nImportance of OLS regression: can give us the Best Linear Unbiased Estimator (BLUE)\nThis is only true if the Gauss-Markov assumptions hold‚Äîone of these is that the error terms are uncorrelated:\n\\[\n\\text{Cov}[\\varepsilon_i, \\varepsilon_j] = 0 \\; \\forall i \\neq j\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#spatial-autocorrelation-in-residuals",
    "href": "w12/index.html#spatial-autocorrelation-in-residuals",
    "title": "Week 12: Tools for Final Projects",
    "section": "Spatial Autocorrelation in Residuals",
    "text": "Spatial Autocorrelation in Residuals\n\nWe have now seen several models / datasets where effect of some variable \\(X\\) (say, population) on another variable \\(Y\\) (say, disease count) is spatial! (Kind of the whole point of the class üòú)\nSo, to see when OLS will ‚Äúwork‚Äù, vs.¬†when you need to incorporate GIS, key step is plotting the spatial distribution of regression residuals!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#example-italian-elections",
    "href": "w12/index.html#example-italian-elections",
    "title": "Week 12: Tools for Final Projects",
    "section": "Example: Italian Elections",
    "text": "Example: Italian Elections\n\n\n\n\n\nWard and Gleditsch (2018), Figure 2.3\n\n\n\n\n\n\nWard and Gleditsch (2018), Figure 2.4",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#will-ols-work-here",
    "href": "w12/index.html#will-ols-work-here",
    "title": "Week 12: Tools for Final Projects",
    "section": "Will OLS ‚ÄúWork‚Äù Here?",
    "text": "Will OLS ‚ÄúWork‚Äù Here?\n\nCan we use OLS to derive the BLUE of the effect of GDP on voting?\n\n\n\n\nPlain OLS\n\n\n\n\n\\(N = 477\\)\n\\(\\widehat{\\beta}\\)\nSE\n\\(t\\)\n\n\n\n\nIntercept\n35.30\n2.21\n15.96\n\n\nLog GDP per cap\n13.46\n0.65\n20.84\n\n\n\nMoran‚Äôs \\(I\\) for residuals = 0.47(!)\n\n¬†\n\n\nSpatial Regression\n\n\n\n\n\\(N = 477\\)\n\\(\\widehat{\\beta}\\)\nSE\n\\(t\\)\n\n\n\n\nIntercept\n4.70\n1.66\n2.80\n\n\nLog GDP per cap\n1.77\n0.48\n3.66\n\n\n\\(\\rho\\)\n0.87\n0.02\n36.7",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#what-does-it-mean-that-spatial-effect-is-significant",
    "href": "w12/index.html#what-does-it-mean-that-spatial-effect-is-significant",
    "title": "Week 12: Tools for Final Projects",
    "section": "What Does it Mean that ‚ÄúSpatial Effect‚Äù is Significant?",
    "text": "What Does it Mean that ‚ÄúSpatial Effect‚Äù is Significant?\n\n\n\n(From the future‚Ä¶ your HW4!)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#case-1-no-residual-spatial-autocorrelation",
    "href": "w12/index.html#case-1-no-residual-spatial-autocorrelation",
    "title": "Week 12: Tools for Final Projects",
    "section": "Case 1: No Residual Spatial Autocorrelation",
    "text": "Case 1: No Residual Spatial Autocorrelation\n\nExample: Residuals have Moran‚Äôs \\(I\\) near 0‚Ä¶\n‚Ä¶Don‚Äôt need GIS at all!",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#case-2-conditional-autoregressive-model-car",
    "href": "w12/index.html#case-2-conditional-autoregressive-model-car",
    "title": "Week 12: Tools for Final Projects",
    "section": "Case 2: Conditional Autoregressive Model (CAR)",
    "text": "Case 2: Conditional Autoregressive Model (CAR)\n\nGIS, but‚Ä¶ only for ‚Äúfixing‚Äù your regression\n\n\\[\nY_i = \\underbrace{\\mu_i}_{\\text{Non-spatial model}} + \\underbrace{\\frac{1}{w_{i,\\cdot}}\\sum_{j \\neq i}(Y_j - \\mu_j)}_{\\text{Spatial Autocorrelation}} + \\varepsilon_i\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#case-3-simultaneous-autoregressive-model-sar",
    "href": "w12/index.html#case-3-simultaneous-autoregressive-model-sar",
    "title": "Week 12: Tools for Final Projects",
    "section": "Case 3: Simultaneous Autoregressive Model (SAR)",
    "text": "Case 3: Simultaneous Autoregressive Model (SAR)\n\nThe main event! Here we are explicitly modeling ‚Äúspatially lagged‚Äù versions of our dependent variable \\(Y\\)!\n\n\\[\nY = \\mathbf{X}\\beta + \\rho \\underbrace{\\mathbf{W}Y}_{\\mathclap{\\text{Spatially-lagged }Y}} + \\boldsymbol\\varepsilon\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#research-methodology-hypotheses",
    "href": "w12/index.html#research-methodology-hypotheses",
    "title": "Week 12: Tools for Final Projects",
    "section": "Research Methodology: Hypotheses",
    "text": "Research Methodology: Hypotheses\n\nSocial Science (McCourt):\n\n\n\nMachine Learning (DSAN):",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#secretly-my-opportunity-to-do-more-spatial-regression",
    "href": "w12/index.html#secretly-my-opportunity-to-do-more-spatial-regression",
    "title": "Week 12: Tools for Final Projects",
    "section": "(Secretly My Opportunity to do More Spatial Regression!)",
    "text": "(Secretly My Opportunity to do More Spatial Regression!)\n\nWhat explains previously-observed instances of separatist insurgencies?\nCan we predict separatist insurgencies?\nOne (spatial) idea: how far away are [centers of power] from [regions of countervailing power]?\n\\(X\\) = Distance from capital, \\(Y\\) = Insurgency\nUnit of observation: Regions? Insurgent uprisings? Countries?",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#operationalizing",
    "href": "w12/index.html#operationalizing",
    "title": "Week 12: Tools for Final Projects",
    "section": "Operationalizing",
    "text": "Operationalizing\n\nThe variables in previous slide are conceptual\nOperationalizing = ‚ÄúTurning into measurable quantities‚Äù\n\\(X\\) = MeanDistance(Capital, Insurgent Region), \\(Y = \\mathbf{1}[\\text{Insurgency}]\\)\nAlternative:\n\n\\[\nY = \\begin{cases}\n2 &\\text{if Successful Insurgency} \\\\\n1 &\\text{if Failed Insurgency} \\\\\n0 &\\text{if No Insurgency}\n\\end{cases}\n\\]",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#connection-matrices",
    "href": "w12/index.html#connection-matrices",
    "title": "Week 12: Tools for Final Projects",
    "section": "Connection Matrices",
    "text": "Connection Matrices\n\nspdep\nNeighbors if Centroids are close\nNeighbors if Capitals are close\nü§î",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#visualizing-spatial-data",
    "href": "w12/index.html#visualizing-spatial-data",
    "title": "Week 12: Tools for Final Projects",
    "section": "Visualizing Spatial Data",
    "text": "Visualizing Spatial Data\n\nMy recommendation for final presentations: Tiptoe from mapview \\(\\leadsto\\) Leaflet!\n\n\n\nCode\n# library(osmdata) |&gt; suppressPackageStartupMessages()\n# library(leaflet)\n# assign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\n# placebb &lt;- osmdata::getbb(\"Barcelona\")\n# hospitals &lt;- placebb |&gt;\n#   opq() |&gt;\n#   add_osm_feature(key = \"amenity\", value = \"hospital\") |&gt;\n#   osmdata_sf()\n# motorways &lt;- placebb |&gt;\n#   opq() |&gt;\n#   add_osm_feature(\n#     key = \"highway\",\n#     value = \"motorway\"\n#   ) |&gt;\n#   osmdata_sf()\n# leaflet() |&gt;\n#   addTiles() |&gt;\n#   addPolylines(\n#     data = motorways$osm_lines,\n#     color = \"black\"\n#   ) |&gt;\n#   addPolygons(\n#     data = hospitals$osm_polygons,\n#     label = hospitals$osm_polygons$name\n#   )",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#custom-icons",
    "href": "w12/index.html#custom-icons",
    "title": "Week 12: Tools for Final Projects",
    "section": "Custom Icons!",
    "text": "Custom Icons!\n\n\n\n\nChicago\nDetroit\n\n\n\n\nPopulation\n2,746,388\n631,524\n\n\n\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet.extras2) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\ncity_df &lt;- tibble::tribble(\n  ~city, ~lon, ~lat, ~pop,\n  \"Chicago\", 41.950567516553896, -87.93011127491978, 2746388,\n  \"Detroit\", 42.45123004999075, -83.18402319217698, 631524\n)\ncity_sf &lt;- sf::st_as_sf(\n  city_df,\n  coords = c(\"lat\", \"lon\"),\n  crs=4326\n)\ncity_buf_sf &lt;- city_sf |&gt; sf::st_buffer(20000)\ncity_cases_sf &lt;- city_buf_sf |&gt; sf::st_sample(size=rep(10,2)) |&gt; sf::st_as_sf()\ncity_cases_sf$city &lt;- \"Detroit (10 Cases)\"\ncity_cases_sf[1:10, 'city'] &lt;- \"Chicago (10 Cases)\"\ncity_cases_sf$sample &lt;- \"Flu\"\ncity_pop_sf &lt;- city_buf_sf |&gt;\n  sf::st_sample(size=c(16, 4)) |&gt; sf::st_as_sf()\ncity_pop_sf$city &lt;- \"Detroit\"\ncity_pop_sf[1:16, 'city'] &lt;- \"Chicago\"\ncity_pop_sf$sample &lt;- \"People\"\ncity_combined_sf &lt;- bind_rows(city_cases_sf, city_pop_sf)\n# mapview(city_combined_sf, zcol=\"city\", marker=\"sample\")\nFlu = makeIcon(\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/240px-Maki2-danger-24.svg.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/24px-Maki2-danger-24.svg.png\",\n    20,\n    20\n)\nPeople = makeIcon(\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  20,\n  20\n)\n\ncity_combined_sf$r &lt;- ifelse(city_combined_sf$sample == \"Flu\", 0, 4)\ncity_flu_sf &lt;- city_combined_sf |&gt; filter(sample == \"Flu\")\ncity_ppl_sf &lt;- city_combined_sf |&gt; filter(sample == \"People\")\nleaflet(city_flu_sf) |&gt;\n  addProviderTiles(\"CartoDB.Positron\") |&gt;\n  addMarkers(data=city_flu_sf, icon = Flu) |&gt;\n  addMarkers(data=city_ppl_sf, icon = People)",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#remote-sensed-raster-data",
    "href": "w12/index.html#remote-sensed-raster-data",
    "title": "Week 12: Tools for Final Projects",
    "section": "Remote-Sensed / Raster Data",
    "text": "Remote-Sensed / Raster Data\n\nYou‚Äôve seen (to some extent) terra\nstars: Same group behind sf\nGoogle solar panel data\n.tif files: Dynamically loaded",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#anonymization-synthetic-datasets",
    "href": "w12/index.html#anonymization-synthetic-datasets",
    "title": "Week 12: Tools for Final Projects",
    "section": "Anonymization / Synthetic Datasets",
    "text": "Anonymization / Synthetic Datasets\n\nDifferential privacy\nUsed by the US Census(!) Since 2020",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#example-bolshevik-revolution-rightarrow-bipolar-world",
    "href": "w12/index.html#example-bolshevik-revolution-rightarrow-bipolar-world",
    "title": "Week 12: Tools for Final Projects",
    "section": "Example: Bolshevik Revolution \\(\\rightarrow\\) ‚ÄúBipolar‚Äù World",
    "text": "Example: Bolshevik Revolution \\(\\rightarrow\\) ‚ÄúBipolar‚Äù World\n\n\n\n\n\n\nNull hypothesis: no spatial effect of democratization/de-democratization on neighboring countries\nIf null hypothesis is true, and countries democratize/de-democratize independently‚Ä¶ could this pattern still arise?",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "w12/index.html#references",
    "href": "w12/index.html#references",
    "title": "Week 12: Tools for Final Projects",
    "section": "References",
    "text": "References\n\n\nWard, Michael D., and Kristian Skrede Gleditsch. 2018. Spatial Regression Models. SAGE Publications.",
    "crumbs": [
      "Week 12: Nov 12"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "",
    "text": "Welcome to the Fall 2025 version of Geographic Information Systems (GIS) for Spatial Data Science at Georgetown University! Please note that the most up-to-date version of this syllabus will always be available at jjacobs.me/ppol6805",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-staff-and-office-hours",
    "href": "syllabus.html#course-staff-and-office-hours",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Course Staff and Office Hours",
    "text": "Course Staff and Office Hours\n\nProf.¬†Jeff Jacobs, jj1088@georgetown.edu: Schedule office hour slots at jjacobs.me/meet\n\nTues 4:30-7:00pm, Weds 3-4pm, Thurs 3-4pm\n(Please try to schedule at least 8 hours in advance, and let me know briefly what you‚Äôd like to discuss, so I have time to prepare! For example, you can provide links to anything you‚Äôd like me to read beforehand, via the ‚ÄúAdditional Info‚Äù portion of the signup form)\n\nTA Christy Hsu, [th1010@georgetown.edu]\n\nCoding Workshop Coordinator (Fridays, 2-3pm in Car Barn 230)\n\nTA Yumi Li, [xl794@georgetown.edu]\n\nOffice hours by appointment",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Course Description",
    "text": "Course Description\nThis course provides students with an overview of Geographic Information Systems (GIS), encompassing both general principles of geospatial data analysis and their applications for studying important issues of climate change, international conflict, economic development, and urban planning, among other areas of application.\nThe beginning of the course emphasizes fundamentals of GIS design and use, such as projection systems, raster and vector data, and efficient representation and storage of geospatial data. As students become more comfortable with these foundations, the course will shift to a greater emphasis on applications during the second half of the semester. Particular emphasis will be placed on effective visualization of spatial data, through creation of static publication-quality maps as well as interactive maps for web applications and data dashboards.\nThe course will utilize libraries from R, Python, and JavaScript as needed, so experience using any of these languages will be helpful, but is not required.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignment-structure",
    "href": "syllabus.html#assignment-structure",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Assignment Structure",
    "text": "Assignment Structure\nOn the basis of the guidelines we‚Äôve developed for courses offered through DSAN, this course will have one in-class midterm but no final exam! Instead, you will work on a final project throughout the second half of the course. Each of the four units will involve a homework assignment, and final grades will be determined using the following weighting scheme:\n\n\n\nCategory\nPercent of Final Grade\n\n\n\n\nIn-Class Midterm (Nov 5)\n25%\n\n\nFinal Project\n30%\n\n\nHomeworks\n45%\n\n\nHW1: GIS Concepts: Fun with Vectors and Rasters\n9%\n\n\nHW2: Unary and Binary Operations, Spatial Joins\n9%\n\n\nHW3: Autocorrelation, Clustering, and Point Processes\n9%\n\n\nHW4: Spatial Regression\n9%\n\n\nHW5: Spatial Regression\n9%\n\n\n\nThe course does not have any ‚Äúofficial‚Äù prerequisites, but a general comfort with R and/or Python is helpful: most of the code shown on slides is in R, but we will also discuss equivalent Python libraries you can use if you prefer!\nIf you have never used R or Python before, however (or if you haven‚Äôt used it in a while and feel like your skills are rusty), you can:\n\nFirst browse the materials on the Resources page, and then\nAttend the weekly coding workshops led by TA Christy Hsu!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-topics-calendar",
    "href": "syllabus.html#course-topics-calendar",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Course Topics / Calendar",
    "text": "Course Topics / Calendar\nThe following is a rough map of what we will work through together throughout the semester; given that everyone learns at a different pace, my aim is to leave us with a good amount of flexibility in terms of how much time we spend on each topic.\nIf I find that it takes me longer than a week to convey a certain topic in sufficient depth, for example, then I view it as a strength rather than a weakness of the course that we can then rearrange the calendar below by adding an extra week on that particular topic! Similarly, if it seems like I am spending too much time on a topic, to the point that students seem bored or impatient to move onto the next topic, we can move a topic intended for the next week to the current week!\nIf you find any discrepancies between this schedule and Georgetown‚Äôs official calendar, please let me know.\n\n\n\n\n\n\n\n\n\nUnit\nWeek\nDate\nTopic\n\n\n\n\nUnit 1: GIS Concepts\n1\nAug 27\nIntroduction to GIS\n\n\n\n2\nSep 3\nHow Do Maps Work?\n\n\n\n3\nSep 10\nVector and Raster Representations\nHW1 Released\n\n\nUnit 2: Geospatial Operations\n4\nSep 17\nUnary Operations\n\n\n\n5\nSep 24\nBinary Operations and DE-9IM\n[Deliverable] HW1 due 11:59pm EDT; HW2 Release\n\n\n\n6\nOct 1\nSpatial Joins and Areal-Weighted Interpolation\n\n\nUnit 3: Spatial Data Science I: Foundations\n7\nOct 8\nSpatial Data Science: Three Forms of Spatial Autocorrelation\n[Deliverable] HW2, 11:59pm; HW3 Release\n\n\n\n\n\n\n\n\n\nTipRecommended Readings/Resources (In Order)\n\n\n\n\nAmazing video introduction to analyzing spatial autocorrelation for epidemiology using R: Xie (2022)\nThree ‚Äòcore‚Äô spatial-statistical datatypes: Schabenberger and Gotway (2004), Section 1.2: Types of Spatial Data (pgs. 6-13)\nBaddeley, Rubak, and Turner (2015), Chapter 5: Point Process Methods (pgs. 127-154)\n\n\n\n\n\n\n8\nOct 15\nPoint Processes: Null Models, Clustering, and Regularity\n\n\n\n\n\n\n\n\n\nTipRecommended Readings/Resources (In Order)\n\n\n\n\nIntensity Functions (First-order properties of point processes): Baddeley, Rubak, and Turner (2015), Chapter 6: Intensity (pgs. 157-198)\nPair Correlation Functions (Second-order properties of point processes): Baddeley, Rubak, and Turner (2015), Chapter 7: Correlation (pgs. 199-254)\nMonte Carlo Simulation: Waller and Gotway (2004), Section 5.2.3: Hypothesis Tests of CSR via Monte Carlo Methods (pgs. 125-126ff)\n\n\n\n\n\nUnit 4: Spatial Data Science II: Methods\n9\nOct 22\nEvaluating Spatial Hypotheses I: Point Data\n[Deliverable] HW3 due 11:59pm EDT; Midterm Guide Release\n\n\n\n10\nOct 29\nEvaluating Spatial Hypotheses II: Areal Data\n\n\n\n\n11\nNov 5\nIn-Class Midterm\nHW4 Release\n\n\nUnit 5: Final Projects\n12\nNov 12\nTools for Final Projects\n\n\n\n13\nNov 19\nIn-Class Office Hours\n[Deliverable] HW4 due 11:59pm EDT; HW5 Release\n\n\n\n\nNov 26\nNo Class (Fall Break)\n\n\n\n14\nDec 3\nFinal Project Poster Session\n\n\n\n\nDec 5 (Friday), 5:59pm\n[Deliverable] Final Project, HW5",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assignment-distribution-submission-and-grading",
    "href": "syllabus.html#assignment-distribution-submission-and-grading",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Assignment Distribution, Submission, and Grading",
    "text": "Assignment Distribution, Submission, and Grading\nThe programming assignments for the course will be managed through a JupyterHub server, which you will connect to in order to work on assignments with more computing power than is possible on your laptops (and with the necessary GIS libraries pre-installed)! This means that, to work on and submit the assignments, you will use the workflow described in the Positron connection guide, which you can always find within the ‚ÄúWriteups‚Äù section linked in the sidebar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#late-policy",
    "href": "syllabus.html#late-policy",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Late Policy",
    "text": "Late Policy\nAfter the due date, for each homework assignment, you will have a grace period of 24 hours to submit the assignment without a lateness penalty. After this 24 hour grace period, late penalties will be applied up until 66 hours after the due date. Specifically, late penalties will be applied based on the following scale (unless you obtain an excused lateness from one of the instructional staff!):\n\n0 to 24 hours after due date: no penalty\n24 to 30 hours after due date: 2.5% penalty\n30 to 42 hours after due date: 5% penalty\n42 to 54 hours after due date: 10% penalty\n54 to 66 hours after due date: 20% penalty\nMore than 66 hours after due date: Assignment submissions no longer accepted (without instructor approval)1",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#final-letter-grade-determination",
    "href": "syllabus.html#final-letter-grade-determination",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Final Letter Grade Determination",
    "text": "Final Letter Grade Determination\nOnce all assignments have been graded, we will compute your final numeric grade according to the above weighting, rounded to two decimal places. The letter grade that we report to Georgetown on the basis of this numeric grade will then follow the DSAN letter grade policy as follows, where the start and end points for each range are inclusive:\n\n\n\nRange Start\nRange End\nLetter Grade\n\n\n\n\n92.50\n100.00\nA\n\n\n89.50\n92.49\nA-\n\n\n87.99\n89.49\nB+\n\n\n81.50\n87.98\nB\n\n\n79.50\n81.49\nB-\n\n\n69.50\n79.49\nC\n\n\n59.50\n69.49\nD\n\n\n0.00\n59.49\nF",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#title-ixsexual-misconduct-statement",
    "href": "syllabus.html#title-ixsexual-misconduct-statement",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Title IX/Sexual Misconduct Statement",
    "text": "Title IX/Sexual Misconduct Statement\nGeorgetown University and its faculty are committed to supporting survivors and those impacted by sexual misconduct, which includes sexual assault, sexual harassment, relationship violence, and stalking. Georgetown requires faculty members, unless otherwise designated as confidential, to report all disclosures of sexual misconduct to the University Title IX Coordinator or a Deputy Title IX Coordinator.\nIf you disclose an incident of sexual misconduct to a professor in or outside of the classroom (with the exception of disclosures in papers), that faculty member must report the incident to the Title IX Coordinator, or Deputy Title IX Coordinator. The coordinator will, in turn, reach out to the student to provide support, resources, and the option to meet. [Please note that the student is not required to meet with the Title IX coordinator.]. More information about reporting options and resources can be found in the Sexual Misconduct Resource Center.\nIf you would prefer to speak to someone confidentially, Georgetown has a number of fully confidential professional resources that can provide support and assistance. These resources include:\n\nHealth Education Services for Sexual Assault Response and Prevention: Confidential email sarp@georgetown.edu\nCounseling and Psychiatric Services (CAPS): 202-687-6985\n\nAfter hours you can call 833-960-3006 to reach Fonemed, a telehealth service, and ask for the on-call CAPS clinician",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#gsas-and-mccourt-resources-and-policies",
    "href": "syllabus.html#gsas-and-mccourt-resources-and-policies",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "GSAS and McCourt Resources and Policies",
    "text": "GSAS and McCourt Resources and Policies\nYou can find a collection of relevant resources and policies for students on the GSAS website, and the Provost‚Äôs policy on accommodating students‚Äô religious observances on the Campus Ministry website.\nYou can also make use of the Student Academic Resource Center. In particular, within the Resource Center there is a link to Georgetown‚Äôs Disability Support page. If you believe you have a disability, you can contact the Academic Resource Center (arc@georgetown.edu) for further information. The ARC is located in the Leavey Center, Suite 335 (202-687-8354), and it is the campus office responsible for reviewing documentation provided by students with disabilities and for determining reasonable accommodations in accordance with the Americans with Disabilities Act (ADA) and University policies.\n\nMcCourt Academic Integrity Policy\nMcCourt School students are expected to uphold the academic policies set forth by Georgetown University and the Graduate School of Arts and Sciences. Students should therefore familiarize themselves with all the rules, regulations, and procedures relevant to their pursuit of a Graduate School degree. The relevant policies are listed at this link.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "PPOL 6805 / DSAN 6750",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExcused lateness exceptions, in turn, will be grounded in a policy where you can ‚Äúpause‚Äù the class (due date-wise, but also just, expectation-of-progress-wise more generally) to take the time you need to handle things happening in your life. Then, you can ‚Äúresume‚Äù work once you feel more centered/once you find yourself back on stable ground. The ‚ÄúMaslow‚Äôs hierarchy‚Äù model from psychology provides a straightforward way to think about this approach:Learning GIS is way up there in the blue triangle, so, it‚Äôs important that you feel like the first four levels are solidified before you turn your focus back to classwork. And, it‚Äôs a win-win, because it means that once you‚Äôre back in action you can be more engaged and receptive to new topics, rather than being forced to ‚Äúsimulate‚Äù being in the blue triangle while in reality struggling in other spots!‚Ü©Ô∏é",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "w06/slides.html#almost-a-spatial-join",
    "href": "w06/slides.html#almost-a-spatial-join",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Almost a Spatial Join",
    "text": "Almost a Spatial Join\n\n\nCode\nsource(\"../dsan-globals/_globals.r\")\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(rnaturalearth) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nN &lt;- 10\nsampled_points_sf &lt;- sf::st_sample(africa_union_sf, N) |&gt; sf::st_sf() |&gt; mutate(temp = runif(N, 0, 100))\nsampled_points_map &lt;- mapview(sampled_points_sf, label=\"Random Point\", col.regions=cbPalette[1], legend=FALSE)\ncountries_points_sf &lt;- africa_sf[sampled_points_sf,]\nfiltered_map &lt;- mapview(countries_points_sf, label=\"geounit\", legend=FALSE) + sampled_points_map\n(africa_map + sampled_points_map) | filtered_map"
  },
  {
    "objectID": "w06/slides.html#spatial-filter-neq-spatial-join",
    "href": "w06/slides.html#spatial-filter-neq-spatial-join",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Spatial Filter \\(\\neq\\) Spatial Join",
    "text": "Spatial Filter \\(\\neq\\) Spatial Join\n\nThe issue: Data attributes of POINTs are not merged into data attributes of POLYGONs\n\n\n\n\nPOINT Attributes\n\n\n\nCode\nst_geometry(sampled_points_sf) &lt;- c(\"geom\")\nsampled_points_sf |&gt; head()\n\n\n\n\n\n\ngeom\ntemp\n\n\n\n\nPOINT (25.13669 -10.26536)\n51.880463\n\n\nPOINT (-5.100807 15.54896)\n37.143558\n\n\nPOINT (-8.31297 24.72026)\n49.780183\n\n\nPOINT (-11.99807 12.42975)\n36.045325\n\n\nPOINT (25.63262 -19.65709)\n69.893106\n\n\nPOINT (0.1314828 17.26716)\n7.535125\n\n\n\n\n\n\n\n\nPOLYGON Attributes\n\n\n\nCode\ncountries_points_sf |&gt; head(4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeaturecla\nscalerank\nlabelrank\nsovereignt\nsov_a3\nadm0_dif\nlevel\ntype\ntlc\nadmin\nadm0_a3\ngeou_dif\ngeounit\ngu_a3\nsu_dif\nsubunit\nsu_a3\nbrk_diff\nname\nname_long\nbrk_a3\nbrk_name\nbrk_group\nabbrev\npostal\nformal_en\nformal_fr\nname_ciawf\nnote_adm0\nnote_brk\nname_sort\nname_alt\nmapcolor7\nmapcolor8\nmapcolor9\nmapcolor13\npop_est\npop_rank\npop_year\ngdp_md\ngdp_year\neconomy\nincome_grp\nfips_10\niso_a2\niso_a2_eh\niso_a3\niso_a3_eh\niso_n3\niso_n3_eh\nun_a3\nwb_a2\nwb_a3\nwoe_id\nwoe_id_eh\nwoe_note\nadm0_iso\nadm0_diff\nadm0_tlc\nadm0_a3_us\nadm0_a3_fr\nadm0_a3_ru\nadm0_a3_es\nadm0_a3_cn\nadm0_a3_tw\nadm0_a3_in\nadm0_a3_np\nadm0_a3_pk\nadm0_a3_de\nadm0_a3_gb\nadm0_a3_br\nadm0_a3_il\nadm0_a3_ps\nadm0_a3_sa\nadm0_a3_eg\nadm0_a3_ma\nadm0_a3_pt\nadm0_a3_ar\nadm0_a3_jp\nadm0_a3_ko\nadm0_a3_vn\nadm0_a3_tr\nadm0_a3_id\nadm0_a3_pl\nadm0_a3_gr\nadm0_a3_it\nadm0_a3_nl\nadm0_a3_se\nadm0_a3_bd\nadm0_a3_ua\nadm0_a3_un\nadm0_a3_wb\ncontinent\nregion_un\nsubregion\nregion_wb\nname_len\nlong_len\nabbrev_len\ntiny\nhomepart\nmin_zoom\nmin_label\nmax_label\nlabel_x\nlabel_y\nne_id\nwikidataid\nname_ar\nname_bn\nname_de\nname_en\nname_es\nname_fa\nname_fr\nname_el\nname_he\nname_hi\nname_hu\nname_id\nname_it\nname_ja\nname_ko\nname_nl\nname_pl\nname_pt\nname_ru\nname_sv\nname_tr\nname_uk\nname_ur\nname_vi\nname_zh\nname_zht\nfclass_iso\ntlc_diff\nfclass_tlc\nfclass_us\nfclass_fr\nfclass_ru\nfclass_es\nfclass_cn\nfclass_tw\nfclass_in\nfclass_np\nfclass_pk\nfclass_de\nfclass_gb\nfclass_br\nfclass_il\nfclass_ps\nfclass_sa\nfclass_eg\nfclass_ma\nfclass_pt\nfclass_ar\nfclass_jp\nfclass_ko\nfclass_vn\nfclass_tr\nfclass_id\nfclass_pl\nfclass_gr\nfclass_it\nfclass_nl\nfclass_se\nfclass_bd\nfclass_ua\ngeometry\n\n\n\n\n67\nAdmin-0 country\n1\n3\nSenegal\nSEN\n0\n2\nSovereign country\n1\nSenegal\nSEN\n0\nSenegal\nSEN\n0\nSenegal\nSEN\n0\nSenegal\nSenegal\nSEN\nSenegal\nNA\nSen.\nSN\nRepublic of Senegal\nNA\nSenegal\nNA\nNA\nSenegal\nNA\n2\n6\n5\n5\n16296364\n14\n2019\n23578\n2019\n7. Least developed region\n4. Lower middle income\nSG\nSN\nSN\nSEN\nSEN\n686\n686\n686\nSN\nSEN\n23424943\n23424943\nExact WOE match as country\nSEN\nNA\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n7\n7\n4\n-99\n1\n0\n2.7\n8\n-14.778586\n15.13813\n1159321243\nQ1041\nÿßŸÑÿ≥ŸÜÿ∫ÿßŸÑ\n‡¶∏‡ßá‡¶®‡ßá‡¶ó‡¶æ‡¶≤\nSenegal\nSenegal\nSenegal\nÿ≥ŸÜ⁄ØÿßŸÑ\nS√©n√©gal\nŒ£ŒµŒΩŒµŒ≥Œ¨ŒªŒ∑\n◊°◊†◊í◊ú\n‡§∏‡•á‡§®‡•á‡§ó‡§≤\nSzeneg√°l\nSenegal\nSenegal\n„Çª„Éç„Ç¨„É´\nÏÑ∏ÎÑ§Í∞à\nSenegal\nSenegal\nSenegal\n–°–µ–Ω–µ–≥–∞–ª\nSenegal\nSenegal\n–°–µ–Ω–µ–≥–∞–ª\nÿ≥€åŸÜ€å⁄ØÿßŸÑ\nS√©n√©gal\nÂ°ûÂÜÖÂä†Â∞î\nÂ°ûÂÖßÂä†Áàæ\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-12.28062 1‚Ä¶\n\n\n112\nAdmin-0 country\n5\n3\nMauritania\nMRT\n0\n2\nSovereign country\n1\nMauritania\nMRT\n0\nMauritania\nMRT\n0\nMauritania\nMRT\n0\nMauritania\nMauritania\nMRT\nMauritania\nNA\nMrt.\nMR\nIslamic Republic of Mauritania\nNA\nMauritania\nNA\nNA\nMauritania\nNA\n3\n3\n2\n1\n4525696\n12\n2019\n7600\n2019\n7. Least developed region\n5. Low income\nMR\nMR\nMR\nMRT\nMRT\n478\n478\n478\nMR\nMRT\n23424896\n23424896\nExact WOE match as country\nMRT\nNA\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n10\n10\n4\n-99\n1\n0\n3.0\n8\n-9.740299\n19.58706\n1159321075\nQ1025\nŸÖŸàÿ±Ÿäÿ™ÿßŸÜŸäÿß\n‡¶Æ‡ßå‡¶∞‡¶ø‡¶§‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ\nMauretanien\nMauritania\nMauritania\nŸÖŸàÿ±€åÿ™ÿßŸÜ€å\nMauritanie\nŒúŒ±œÖœÅŒπœÑŒ±ŒΩŒØŒ±\n◊û◊ê◊ï◊®◊ô◊ò◊†◊ô◊î\n‡§Æ‡•â‡§∞‡•Ä‡§§‡§æ‡§®‡§ø‡§Ø‡§æ\nMaurit√°nia\nMauritania\nMauritania\n„É¢„Éº„É™„Çø„Éã„Ç¢\nÎ™®Î¶¨ÌÉÄÎãà\nMauritani√´\nMauretania\nMaurit√¢nia\n–ú–∞–≤—Ä–∏—Ç–∞–Ω–∏—è\nMauretanien\nMoritanya\n–ú–∞–≤—Ä–∏—Ç–∞–Ω—ñ—è\nŸÖŸàÿ±€åÿ™ÿßŸÜ€å€Å\nMauritanie\nÊØõÈáåÂ°îÂ∞º‰∫ö\nËåÖÂà©Â°îÂ∞º‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-16.37334 1‚Ä¶\n\n\n114\nAdmin-0 country\n1\n3\nMali\nMLI\n0\n2\nSovereign country\n1\nMali\nMLI\n0\nMali\nMLI\n0\nMali\nMLI\n0\nMali\nMali\nMLI\nMali\nNA\nMali\nML\nRepublic of Mali\nNA\nMali\nNA\nNA\nMali\nNA\n1\n4\n1\n7\n19658031\n14\n2019\n17279\n2019\n7. Least developed region\n5. Low income\nML\nML\nML\nMLI\nMLI\n466\n466\n466\nML\nMLI\n23424891\n23424891\nExact WOE match as country\nMLI\nNA\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n4\n4\n4\n-99\n1\n0\n3.0\n7\n-2.038455\n18.69271\n1159321063\nQ912\nŸÖÿßŸÑŸä\n‡¶Æ‡¶æ‡¶≤‡¶ø\nMali\nMali\nMal√≠\nŸÖÿßŸÑ€å\nMali\nŒúŒ¨ŒªŒπ\n◊û◊ê◊ú◊ô\n‡§Æ‡§æ‡§≤‡•Ä\nMali\nMali\nMali\n„Éû„É™ÂÖ±ÂíåÂõΩ\nÎßêÎ¶¨\nMali\nMali\nMali\n–ú–∞–ª–∏\nMali\nMali\n–ú–∞–ª—ñ\nŸÖÿßŸÑ€å\nMali\nÈ©¨Èáå\nÈ¶¨Âà©ÂÖ±ÂíåÂúã\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-11.3894 12‚Ä¶\n\n\n152\nAdmin-0 country\n1\n3\nGuinea\nGIN\n0\n2\nSovereign country\n1\nGuinea\nGIN\n0\nGuinea\nGIN\n0\nGuinea\nGIN\n0\nGuinea\nGuinea\nGIN\nGuinea\nNA\nGin.\nGN\nRepublic of Guinea\nNA\nGuinea\nNA\nNA\nGuinea\nNA\n6\n3\n7\n2\n12771246\n14\n2019\n12296\n2019\n7. Least developed region\n5. Low income\nGV\nGN\nGN\nGIN\nGIN\n324\n324\n324\nGN\nGIN\n23424835\n23424835\nExact WOE match as country\nGIN\nNA\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n6\n6\n4\n-99\n1\n0\n3.0\n8\n-10.016402\n10.61852\n1159320795\nQ1006\nÿ∫ŸäŸÜŸäÿß\n‡¶ó‡¶ø‡¶®‡¶ø\nGuinea\nGuinea\nGuinea\n⁄Ø€åŸÜŸá\nGuin√©e\nŒìŒøœÖŒπŒΩŒ≠Œ±\n◊í◊ô◊†◊ê◊î\n‡§ó‡§ø‡§®‡•Ä\nGuinea\nGuinea\nGuinea\n„ÇÆ„Éã„Ç¢\nÍ∏∞Îãà\nGuinee\nGwinea\nGuin√©\n–ì–≤–∏–Ω–µ—è\nGuinea\nGine\n–ì–≤—ñ–Ω–µ—è\nÿ¨ŸÖ€ÅŸàÿ±€å€Å ⁄ØŸÜ€å\nGuin√©e\nÂá†ÂÜÖ‰∫ö\nÂπæÂÖß‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-10.2832 8‚Ä¶."
  },
  {
    "objectID": "w06/slides.html#our-first-real-spatial-join-st_join",
    "href": "w06/slides.html#our-first-real-spatial-join-st_join",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Our First Real Spatial Join: st_join()",
    "text": "Our First Real Spatial Join: st_join()\n\n\nCode\njoined_sf &lt;- countries_points_sf |&gt; st_join(sampled_points_sf)\njoined_sf |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeaturecla\nscalerank\nlabelrank\nsovereignt\nsov_a3\nadm0_dif\nlevel\ntype\ntlc\nadmin\nadm0_a3\ngeou_dif\ngeounit\ngu_a3\nsu_dif\nsubunit\nsu_a3\nbrk_diff\nname\nname_long\nbrk_a3\nbrk_name\nbrk_group\nabbrev\npostal\nformal_en\nformal_fr\nname_ciawf\nnote_adm0\nnote_brk\nname_sort\nname_alt\nmapcolor7\nmapcolor8\nmapcolor9\nmapcolor13\npop_est\npop_rank\npop_year\ngdp_md\ngdp_year\neconomy\nincome_grp\nfips_10\niso_a2\niso_a2_eh\niso_a3\niso_a3_eh\niso_n3\niso_n3_eh\nun_a3\nwb_a2\nwb_a3\nwoe_id\nwoe_id_eh\nwoe_note\nadm0_iso\nadm0_diff\nadm0_tlc\nadm0_a3_us\nadm0_a3_fr\nadm0_a3_ru\nadm0_a3_es\nadm0_a3_cn\nadm0_a3_tw\nadm0_a3_in\nadm0_a3_np\nadm0_a3_pk\nadm0_a3_de\nadm0_a3_gb\nadm0_a3_br\nadm0_a3_il\nadm0_a3_ps\nadm0_a3_sa\nadm0_a3_eg\nadm0_a3_ma\nadm0_a3_pt\nadm0_a3_ar\nadm0_a3_jp\nadm0_a3_ko\nadm0_a3_vn\nadm0_a3_tr\nadm0_a3_id\nadm0_a3_pl\nadm0_a3_gr\nadm0_a3_it\nadm0_a3_nl\nadm0_a3_se\nadm0_a3_bd\nadm0_a3_ua\nadm0_a3_un\nadm0_a3_wb\ncontinent\nregion_un\nsubregion\nregion_wb\nname_len\nlong_len\nabbrev_len\ntiny\nhomepart\nmin_zoom\nmin_label\nmax_label\nlabel_x\nlabel_y\nne_id\nwikidataid\nname_ar\nname_bn\nname_de\nname_en\nname_es\nname_fa\nname_fr\nname_el\nname_he\nname_hi\nname_hu\nname_id\nname_it\nname_ja\nname_ko\nname_nl\nname_pl\nname_pt\nname_ru\nname_sv\nname_tr\nname_uk\nname_ur\nname_vi\nname_zh\nname_zht\nfclass_iso\ntlc_diff\nfclass_tlc\nfclass_us\nfclass_fr\nfclass_ru\nfclass_es\nfclass_cn\nfclass_tw\nfclass_in\nfclass_np\nfclass_pk\nfclass_de\nfclass_gb\nfclass_br\nfclass_il\nfclass_ps\nfclass_sa\nfclass_eg\nfclass_ma\nfclass_pt\nfclass_ar\nfclass_jp\nfclass_ko\nfclass_vn\nfclass_tr\nfclass_id\nfclass_pl\nfclass_gr\nfclass_it\nfclass_nl\nfclass_se\nfclass_bd\nfclass_ua\ntemp\ngeometry\n\n\n\n\n67\nAdmin-0 country\n1\n3\nSenegal\nSEN\n0\n2\nSovereign country\n1\nSenegal\nSEN\n0\nSenegal\nSEN\n0\nSenegal\nSEN\n0\nSenegal\nSenegal\nSEN\nSenegal\nNA\nSen.\nSN\nRepublic of Senegal\nNA\nSenegal\nNA\nNA\nSenegal\nNA\n2\n6\n5\n5\n16296364\n14\n2019\n23578\n2019\n7. Least developed region\n4. Lower middle income\nSG\nSN\nSN\nSEN\nSEN\n686\n686\n686\nSN\nSEN\n23424943\n23424943\nExact WOE match as country\nSEN\nNA\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\nSEN\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n7\n7\n4\n-99\n1\n0\n2.7\n8\n-14.778586\n15.13813\n1159321243\nQ1041\nÿßŸÑÿ≥ŸÜÿ∫ÿßŸÑ\n‡¶∏‡ßá‡¶®‡ßá‡¶ó‡¶æ‡¶≤\nSenegal\nSenegal\nSenegal\nÿ≥ŸÜ⁄ØÿßŸÑ\nS√©n√©gal\nŒ£ŒµŒΩŒµŒ≥Œ¨ŒªŒ∑\n◊°◊†◊í◊ú\n‡§∏‡•á‡§®‡•á‡§ó‡§≤\nSzeneg√°l\nSenegal\nSenegal\n„Çª„Éç„Ç¨„É´\nÏÑ∏ÎÑ§Í∞à\nSenegal\nSenegal\nSenegal\n–°–µ–Ω–µ–≥–∞–ª\nSenegal\nSenegal\n–°–µ–Ω–µ–≥–∞–ª\nÿ≥€åŸÜ€å⁄ØÿßŸÑ\nS√©n√©gal\nÂ°ûÂÜÖÂä†Â∞î\nÂ°ûÂÖßÂä†Áàæ\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n36.045325\nMULTIPOLYGON (((-12.28062 1‚Ä¶\n\n\n112\nAdmin-0 country\n5\n3\nMauritania\nMRT\n0\n2\nSovereign country\n1\nMauritania\nMRT\n0\nMauritania\nMRT\n0\nMauritania\nMRT\n0\nMauritania\nMauritania\nMRT\nMauritania\nNA\nMrt.\nMR\nIslamic Republic of Mauritania\nNA\nMauritania\nNA\nNA\nMauritania\nNA\n3\n3\n2\n1\n4525696\n12\n2019\n7600\n2019\n7. Least developed region\n5. Low income\nMR\nMR\nMR\nMRT\nMRT\n478\n478\n478\nMR\nMRT\n23424896\n23424896\nExact WOE match as country\nMRT\nNA\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n10\n10\n4\n-99\n1\n0\n3.0\n8\n-9.740299\n19.58706\n1159321075\nQ1025\nŸÖŸàÿ±Ÿäÿ™ÿßŸÜŸäÿß\n‡¶Æ‡ßå‡¶∞‡¶ø‡¶§‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ\nMauretanien\nMauritania\nMauritania\nŸÖŸàÿ±€åÿ™ÿßŸÜ€å\nMauritanie\nŒúŒ±œÖœÅŒπœÑŒ±ŒΩŒØŒ±\n◊û◊ê◊ï◊®◊ô◊ò◊†◊ô◊î\n‡§Æ‡•â‡§∞‡•Ä‡§§‡§æ‡§®‡§ø‡§Ø‡§æ\nMaurit√°nia\nMauritania\nMauritania\n„É¢„Éº„É™„Çø„Éã„Ç¢\nÎ™®Î¶¨ÌÉÄÎãà\nMauritani√´\nMauretania\nMaurit√¢nia\n–ú–∞–≤—Ä–∏—Ç–∞–Ω–∏—è\nMauretanien\nMoritanya\n–ú–∞–≤—Ä–∏—Ç–∞–Ω—ñ—è\nŸÖŸàÿ±€åÿ™ÿßŸÜ€å€Å\nMauritanie\nÊØõÈáåÂ°îÂ∞º‰∫ö\nËåÖÂà©Â°îÂ∞º‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n49.780183\nMULTIPOLYGON (((-16.37334 1‚Ä¶\n\n\n112.1\nAdmin-0 country\n5\n3\nMauritania\nMRT\n0\n2\nSovereign country\n1\nMauritania\nMRT\n0\nMauritania\nMRT\n0\nMauritania\nMRT\n0\nMauritania\nMauritania\nMRT\nMauritania\nNA\nMrt.\nMR\nIslamic Republic of Mauritania\nNA\nMauritania\nNA\nNA\nMauritania\nNA\n3\n3\n2\n1\n4525696\n12\n2019\n7600\n2019\n7. Least developed region\n5. Low income\nMR\nMR\nMR\nMRT\nMRT\n478\n478\n478\nMR\nMRT\n23424896\n23424896\nExact WOE match as country\nMRT\nNA\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\nMRT\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n10\n10\n4\n-99\n1\n0\n3.0\n8\n-9.740299\n19.58706\n1159321075\nQ1025\nŸÖŸàÿ±Ÿäÿ™ÿßŸÜŸäÿß\n‡¶Æ‡ßå‡¶∞‡¶ø‡¶§‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ\nMauretanien\nMauritania\nMauritania\nŸÖŸàÿ±€åÿ™ÿßŸÜ€å\nMauritanie\nŒúŒ±œÖœÅŒπœÑŒ±ŒΩŒØŒ±\n◊û◊ê◊ï◊®◊ô◊ò◊†◊ô◊î\n‡§Æ‡•â‡§∞‡•Ä‡§§‡§æ‡§®‡§ø‡§Ø‡§æ\nMaurit√°nia\nMauritania\nMauritania\n„É¢„Éº„É™„Çø„Éã„Ç¢\nÎ™®Î¶¨ÌÉÄÎãà\nMauritani√´\nMauretania\nMaurit√¢nia\n–ú–∞–≤—Ä–∏—Ç–∞–Ω–∏—è\nMauretanien\nMoritanya\n–ú–∞–≤—Ä–∏—Ç–∞–Ω—ñ—è\nŸÖŸàÿ±€åÿ™ÿßŸÜ€å€Å\nMauritanie\nÊØõÈáåÂ°îÂ∞º‰∫ö\nËåÖÂà©Â°îÂ∞º‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n45.477871\nMULTIPOLYGON (((-16.37334 1‚Ä¶\n\n\n114\nAdmin-0 country\n1\n3\nMali\nMLI\n0\n2\nSovereign country\n1\nMali\nMLI\n0\nMali\nMLI\n0\nMali\nMLI\n0\nMali\nMali\nMLI\nMali\nNA\nMali\nML\nRepublic of Mali\nNA\nMali\nNA\nNA\nMali\nNA\n1\n4\n1\n7\n19658031\n14\n2019\n17279\n2019\n7. Least developed region\n5. Low income\nML\nML\nML\nMLI\nMLI\n466\n466\n466\nML\nMLI\n23424891\n23424891\nExact WOE match as country\nMLI\nNA\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n4\n4\n4\n-99\n1\n0\n3.0\n7\n-2.038455\n18.69271\n1159321063\nQ912\nŸÖÿßŸÑŸä\n‡¶Æ‡¶æ‡¶≤‡¶ø\nMali\nMali\nMal√≠\nŸÖÿßŸÑ€å\nMali\nŒúŒ¨ŒªŒπ\n◊û◊ê◊ú◊ô\n‡§Æ‡§æ‡§≤‡•Ä\nMali\nMali\nMali\n„Éû„É™ÂÖ±ÂíåÂõΩ\nÎßêÎ¶¨\nMali\nMali\nMali\n–ú–∞–ª–∏\nMali\nMali\n–ú–∞–ª—ñ\nŸÖÿßŸÑ€å\nMali\nÈ©¨Èáå\nÈ¶¨Âà©ÂÖ±ÂíåÂúã\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n37.143558\nMULTIPOLYGON (((-11.3894 12‚Ä¶\n\n\n114.1\nAdmin-0 country\n1\n3\nMali\nMLI\n0\n2\nSovereign country\n1\nMali\nMLI\n0\nMali\nMLI\n0\nMali\nMLI\n0\nMali\nMali\nMLI\nMali\nNA\nMali\nML\nRepublic of Mali\nNA\nMali\nNA\nNA\nMali\nNA\n1\n4\n1\n7\n19658031\n14\n2019\n17279\n2019\n7. Least developed region\n5. Low income\nML\nML\nML\nMLI\nMLI\n466\n466\n466\nML\nMLI\n23424891\n23424891\nExact WOE match as country\nMLI\nNA\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\nMLI\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n4\n4\n4\n-99\n1\n0\n3.0\n7\n-2.038455\n18.69271\n1159321063\nQ912\nŸÖÿßŸÑŸä\n‡¶Æ‡¶æ‡¶≤‡¶ø\nMali\nMali\nMal√≠\nŸÖÿßŸÑ€å\nMali\nŒúŒ¨ŒªŒπ\n◊û◊ê◊ú◊ô\n‡§Æ‡§æ‡§≤‡•Ä\nMali\nMali\nMali\n„Éû„É™ÂÖ±ÂíåÂõΩ\nÎßêÎ¶¨\nMali\nMali\nMali\n–ú–∞–ª–∏\nMali\nMali\n–ú–∞–ª—ñ\nŸÖÿßŸÑ€å\nMali\nÈ©¨Èáå\nÈ¶¨Âà©ÂÖ±ÂíåÂúã\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7.535125\nMULTIPOLYGON (((-11.3894 12‚Ä¶\n\n\n152\nAdmin-0 country\n1\n3\nGuinea\nGIN\n0\n2\nSovereign country\n1\nGuinea\nGIN\n0\nGuinea\nGIN\n0\nGuinea\nGIN\n0\nGuinea\nGuinea\nGIN\nGuinea\nNA\nGin.\nGN\nRepublic of Guinea\nNA\nGuinea\nNA\nNA\nGuinea\nNA\n6\n3\n7\n2\n12771246\n14\n2019\n12296\n2019\n7. Least developed region\n5. Low income\nGV\nGN\nGN\nGIN\nGIN\n324\n324\n324\nGN\nGIN\n23424835\n23424835\nExact WOE match as country\nGIN\nNA\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\nGIN\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n6\n6\n4\n-99\n1\n0\n3.0\n8\n-10.016402\n10.61852\n1159320795\nQ1006\nÿ∫ŸäŸÜŸäÿß\n‡¶ó‡¶ø‡¶®‡¶ø\nGuinea\nGuinea\nGuinea\n⁄Ø€åŸÜŸá\nGuin√©e\nŒìŒøœÖŒπŒΩŒ≠Œ±\n◊í◊ô◊†◊ê◊î\n‡§ó‡§ø‡§®‡•Ä\nGuinea\nGuinea\nGuinea\n„ÇÆ„Éã„Ç¢\nÍ∏∞Îãà\nGuinee\nGwinea\nGuin√©\n–ì–≤–∏–Ω–µ—è\nGuinea\nGine\n–ì–≤—ñ–Ω–µ—è\nÿ¨ŸÖ€ÅŸàÿ±€å€Å ⁄ØŸÜ€å\nGuin√©e\nÂá†ÂÜÖ‰∫ö\nÂπæÂÖß‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n60.728323\nMULTIPOLYGON (((-10.2832 8‚Ä¶."
  },
  {
    "objectID": "w06/slides.html#but-we-were-still-in-easy-mode",
    "href": "w06/slides.html#but-we-were-still-in-easy-mode",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "But‚Ä¶ We Were Still in Easy Mode",
    "text": "But‚Ä¶ We Were Still in Easy Mode\n\nEvery point could be matched one-to-one with a country. But what if‚Ä¶ üò±\n\n\n\nCode\ng &lt;- st_make_grid(st_bbox(st_as_sfc(\"LINESTRING(0 0,1 1)\")), n = c(2,2))\npar(mar = rep(0,4))\nplot(g)\nplot(g[1] * diag(c(3/4, 1)) + c(0.25, 0.125), add = TRUE, lty = 2)\ntext(c(.2, .8, .2, .8), c(.2, .2, .8, .8), c(1,2,4,8), col = 'red')"
  },
  {
    "objectID": "w06/slides.html#spatially-intensive-vs.-spatially-extensive",
    "href": "w06/slides.html#spatially-intensive-vs.-spatially-extensive",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Spatially Intensive vs.¬†Spatially Extensive",
    "text": "Spatially Intensive vs.¬†Spatially Extensive\n\nExtensive attributes: associated with a physical size (length, area, volume, counts of items). Ex: population count.\n\nAssociated with an area \\(\\implies\\) if that area is cut into smaller areas, the population count needs to be split too\n(At minimum, the sum of the population counts for the smaller areas needs to equal the total for the larger area)\n\nIntensive attributes: Not proportional to support: if the area is split, values may vary but on average remain the same. Ex: population density\n\nIf an area is split into smaller areas, population density is not split similarly!\nThe sum of population densities for the smaller areas is a meaningless measure\nInstead, the mean will be more useful as ~similar to the density of the total"
  },
  {
    "objectID": "w06/slides.html#handling-the-extensive-case",
    "href": "w06/slides.html#handling-the-extensive-case",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Handling the Extensive Case",
    "text": "Handling the Extensive Case\n\nAssume the extensive attribute \\(Y\\) is uniformly distributed over a space \\(S_i\\) (e.g., for population counts we assume everyone is evenly-spaced across the region)\nWe first compute \\(Y_{ij}\\), derived from \\(Y_i\\) for a sub-area of \\(S_i\\), \\(A_{ij} = S_i \\cap T_j\\):\n\\[\n\\hat{Y}_{ij}(A_{ij}) = \\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\]\nwhere \\(|\\cdot|\\) denotes area.\nThen we can compute \\(Y_j(T_j)\\) by summing all the elements over area \\(T_j\\):\n\n\\[\n\\hat{Y}_j(T_j) = \\sum_{i=1}^{p}\\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\]"
  },
  {
    "objectID": "w06/slides.html#handling-the-intensive-case",
    "href": "w06/slides.html#handling-the-intensive-case",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Handling the Intensive Case",
    "text": "Handling the Intensive Case\n\nAssume the variable \\(Y\\) has constant value over a space \\(S_i\\) (e.g., population density in assumed to be the same across all sub-areas)\nThen the estimate for a sub-area is the same as the estimate for the total area:\n\n\\[\n\\hat{Y}_{ij} = Y_i(S_i)\n\\]\n\nSo that we can obtain estimates of \\(Y\\) for new spatial units \\(T_j\\) via area-weighted average of the source values:\n\n\\[\n\\hat{Y}_j(T_j) = \\sum_{i=1}^{p}\\frac{|A_{ij}|}{|T_j|}Y_j(S_i)\n\\]"
  },
  {
    "objectID": "w06/slides.html#lets-go-see-it-in-action",
    "href": "w06/slides.html#lets-go-see-it-in-action",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Let‚Äôs Go See It In Action!",
    "text": "Let‚Äôs Go See It In Action!\n¬†\n\nWeek 6 Lab: Interpolating Kurdistan"
  },
  {
    "objectID": "w06/slides.html#references",
    "href": "w06/slides.html#references",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "w06/index.html",
    "href": "w06/index.html",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#almost-a-spatial-join",
    "href": "w06/index.html#almost-a-spatial-join",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Almost a Spatial Join",
    "text": "Almost a Spatial Join\n\n\nCode\nsource(\"../dsan-globals/_globals.r\")\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(rnaturalearth) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nN &lt;- 10\nsampled_points_sf &lt;- sf::st_sample(africa_union_sf, N) |&gt; sf::st_sf() |&gt; mutate(temp = runif(N, 0, 100))\nsampled_points_map &lt;- mapview(sampled_points_sf, label=\"Random Point\", col.regions=cbPalette[1], legend=FALSE)\ncountries_points_sf &lt;- africa_sf[sampled_points_sf,]\nfiltered_map &lt;- mapview(countries_points_sf, label=\"geounit\", legend=FALSE) + sampled_points_map\n(africa_map + sampled_points_map) | filtered_map\n\n\nLoading required namespace: leaflet.extras2",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#spatial-filter-neq-spatial-join",
    "href": "w06/index.html#spatial-filter-neq-spatial-join",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Spatial Filter \\(\\neq\\) Spatial Join",
    "text": "Spatial Filter \\(\\neq\\) Spatial Join\n\nThe issue: Data attributes of POINTs are not merged into data attributes of POLYGONs\n\n\n\n\nPOINT Attributes\n\n\n\nCode\nst_geometry(sampled_points_sf) &lt;- c(\"geom\")\nsampled_points_sf |&gt; head()\n\n\n\n\n\n\ngeom\ntemp\n\n\n\n\nPOINT (33.5931 29.08277)\n97.0442031\n\n\nPOINT (1.979177 13.72218)\n63.0309917\n\n\nPOINT (5.197797 32.08048)\n75.3301563\n\n\nPOINT (2.091349 8.460578)\n0.0173522\n\n\nPOINT (10.31404 1.262392)\n75.3951204\n\n\nPOINT (19.00772 -17.86188)\n81.0229567\n\n\n\n\n\n\n\n\nPOLYGON Attributes\n\n\n\nCode\ncountries_points_sf |&gt; head(4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeaturecla\nscalerank\nlabelrank\nsovereignt\nsov_a3\nadm0_dif\nlevel\ntype\ntlc\nadmin\nadm0_a3\ngeou_dif\ngeounit\ngu_a3\nsu_dif\nsubunit\nsu_a3\nbrk_diff\nname\nname_long\nbrk_a3\nbrk_name\nbrk_group\nabbrev\npostal\nformal_en\nformal_fr\nname_ciawf\nnote_adm0\nnote_brk\nname_sort\nname_alt\nmapcolor7\nmapcolor8\nmapcolor9\nmapcolor13\npop_est\npop_rank\npop_year\ngdp_md\ngdp_year\neconomy\nincome_grp\nfips_10\niso_a2\niso_a2_eh\niso_a3\niso_a3_eh\niso_n3\niso_n3_eh\nun_a3\nwb_a2\nwb_a3\nwoe_id\nwoe_id_eh\nwoe_note\nadm0_iso\nadm0_diff\nadm0_tlc\nadm0_a3_us\nadm0_a3_fr\nadm0_a3_ru\nadm0_a3_es\nadm0_a3_cn\nadm0_a3_tw\nadm0_a3_in\nadm0_a3_np\nadm0_a3_pk\nadm0_a3_de\nadm0_a3_gb\nadm0_a3_br\nadm0_a3_il\nadm0_a3_ps\nadm0_a3_sa\nadm0_a3_eg\nadm0_a3_ma\nadm0_a3_pt\nadm0_a3_ar\nadm0_a3_jp\nadm0_a3_ko\nadm0_a3_vn\nadm0_a3_tr\nadm0_a3_id\nadm0_a3_pl\nadm0_a3_gr\nadm0_a3_it\nadm0_a3_nl\nadm0_a3_se\nadm0_a3_bd\nadm0_a3_ua\nadm0_a3_un\nadm0_a3_wb\ncontinent\nregion_un\nsubregion\nregion_wb\nname_len\nlong_len\nabbrev_len\ntiny\nhomepart\nmin_zoom\nmin_label\nmax_label\nlabel_x\nlabel_y\nne_id\nwikidataid\nname_ar\nname_bn\nname_de\nname_en\nname_es\nname_fa\nname_fr\nname_el\nname_he\nname_hi\nname_hu\nname_id\nname_it\nname_ja\nname_ko\nname_nl\nname_pl\nname_pt\nname_ru\nname_sv\nname_tr\nname_uk\nname_ur\nname_vi\nname_zh\nname_zht\nfclass_iso\ntlc_diff\nfclass_tlc\nfclass_us\nfclass_fr\nfclass_ru\nfclass_es\nfclass_cn\nfclass_tw\nfclass_in\nfclass_np\nfclass_pk\nfclass_de\nfclass_gb\nfclass_br\nfclass_il\nfclass_ps\nfclass_sa\nfclass_eg\nfclass_ma\nfclass_pt\nfclass_ar\nfclass_jp\nfclass_ko\nfclass_vn\nfclass_tr\nfclass_id\nfclass_pl\nfclass_gr\nfclass_it\nfclass_nl\nfclass_se\nfclass_bd\nfclass_ua\ngeometry\n\n\n\n\n57\nAdmin-0 country\n1\n2\nSouth Africa\nZAF\n0\n2\nSovereign country\n1\nSouth Africa\nZAF\n0\nSouth Africa\nZAF\n0\nSouth Africa\nZAF\n0\nSouth Africa\nSouth Africa\nZAF\nSouth Africa\nNA\nS.Af.\nZA\nRepublic of South Africa\nNA\nSouth Africa\nNA\nNA\nSouth Africa\nNA\n2\n3\n4\n2\n58558270\n16\n2019\n351431\n2019\n5. Emerging region: G20\n3. Upper middle income\nSF\nZA\nZA\nZAF\nZAF\n710\n710\n710\nZA\nZAF\n23424942\n23424942\nExact WOE match as country\nZAF\nNA\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\n-99\n-99\nAfrica\nAfrica\nSouthern Africa\nSub-Saharan Africa\n12\n12\n5\n-99\n1\n0\n1.7\n6.7\n23.665734\n-29.708776\n1159321431\nQ258\nÿ¨ŸÜŸàÿ® ÿ£ŸÅÿ±ŸäŸÇŸäÿß\n‡¶¶‡¶ï‡ßç‡¶∑‡¶ø‡¶£ ‡¶Ü‡¶´‡ßç‡¶∞‡¶ø‡¶ï‡¶æ\nS√ºdafrika\nSouth Africa\nSud√°frica\nÿ¢ŸÅÿ±€åŸÇÿß€å ÿ¨ŸÜŸàÿ®€å\nAfrique du Sud\nŒùœåœÑŒπŒ± ŒëœÜœÅŒπŒ∫ŒÆ\n◊ì◊®◊ï◊ù ◊ê◊§◊®◊ô◊ß◊î\n‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§´‡§º‡•ç‡§∞‡•Ä‡§ï‡§æ\nD√©l-afrikai K√∂zt√°rsas√°g\nAfrika Selatan\nSudafrica\nÂçó„Ç¢„Éï„É™„Ç´ÂÖ±ÂíåÂõΩ\nÎÇ®ÏïÑÌîÑÎ¶¨Ïπ¥ Í≥µÌôîÍµ≠\nZuid-Afrika\nPo≈Çudniowa Afryka\n√Åfrica do Sul\n–Æ–ê–†\nSydafrika\nG√ºney Afrika Cumhuriyeti\n–ü—ñ–≤–¥–µ–Ω–Ω–æ-–ê—Ñ—Ä–∏–∫–∞–Ω—Å—å–∫–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞\nÿ¨ŸÜŸàÿ®€å ÿßŸÅÿ±€åŸÇÿß\nC·ªông h√≤a Nam Phi\nÂçóÈùû\nÂçóÈùû\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((29.36484 -2‚Ä¶\n\n\n92\nAdmin-0 country\n1\n3\nNiger\nNER\n0\n2\nSovereign country\n1\nNiger\nNER\n0\nNiger\nNER\n0\nNiger\nNER\n0\nNiger\nNiger\nNER\nNiger\nNA\nNiger\nNE\nRepublic of Niger\nNA\nNiger\nNA\nNA\nNiger\nNA\n4\n5\n3\n13\n23310715\n15\n2019\n12911\n2019\n7. Least developed region\n5. Low income\nNG\nNE\nNE\nNER\nNER\n562\n562\n562\nNE\nNER\n23424906\n23424906\nExact WOE match as country\nNER\nNA\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n5\n5\n5\n-99\n1\n0\n3.0\n8.0\n9.504356\n17.446195\n1159321087\nQ1032\nÿßŸÑŸÜŸäÿ¨ÿ±\n‡¶®‡¶æ‡¶á‡¶ú‡¶æ‡¶∞\nNiger\nNiger\nN√≠ger\nŸÜ€åÿ¨ÿ±\nNiger\nŒùŒØŒ≥Œ∑œÅŒ±œÇ\n◊†◊ô◊ñ‚Äô◊®\n‡§®‡§æ‡§á‡§ú‡§∞\nNiger\nNiger\nNiger\n„Éã„Ç∏„Çß„Éº„É´\nÎãàÏ†úÎ•¥\nNiger\nNiger\nN√≠ger\n–ù–∏–≥–µ—Ä\nNiger\nNijer\n–ù—ñ–≥–µ—Ä\nŸÜÿßÿ¶ÿ¨ÿ±\nNiger\nÂ∞ºÊó•Â∞î\nÂ∞ºÊó•\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((13.60635 13‚Ä¶\n\n\n102\nAdmin-0 country\n1\n3\nNamibia\nNAM\n0\n2\nSovereign country\n1\nNamibia\nNAM\n0\nNamibia\nNAM\n0\nNamibia\nNAM\n0\nNamibia\nNamibia\nNAM\nNamibia\nNA\nNam.\nNA\nRepublic of Namibia\nNA\nNamibia\nNA\nNA\nNamibia\nNA\n4\n1\n1\n7\n2494530\n12\n2019\n12366\n2019\n6. Developing region\n3. Upper middle income\nWA\nNA\nNA\nNAM\nNAM\n516\n516\n516\nNA\nNAM\n23424987\n23424987\nExact WOE match as country\nNAM\nNA\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\n-99\n-99\nAfrica\nAfrica\nSouthern Africa\nSub-Saharan Africa\n7\n7\n4\n-99\n1\n0\n3.0\n7.5\n17.108166\n-20.575298\n1159321085\nQ1030\nŸÜÿßŸÖŸäÿ®Ÿäÿß\n‡¶®‡¶æ‡¶Æ‡¶ø‡¶¨‡¶ø‡¶Ø‡¶º‡¶æ\nNamibia\nNamibia\nNamibia\nŸÜÿßŸÖ€åÿ®€åÿß\nNamibie\nŒùŒ±ŒºŒØŒºœÄŒπŒ±\n◊†◊û◊ô◊ë◊ô◊î\n‡§®‡§æ‡§Æ‡•Ä‡§¨‡§ø‡§Ø‡§æ\nNam√≠bia\nNamibia\nNamibia\n„Éä„Éü„Éì„Ç¢\nÎÇòÎØ∏ÎπÑÏïÑ\nNamibi√´\nNamibia\nNam√≠bia\n–ù–∞–º–∏–±–∏—è\nNamibia\nNamibya\n–ù–∞–º—ñ–±—ñ—è\nŸÜŸÖ€åÿ®€åÿß\nNamibia\nÁ∫≥Á±≥ÊØî‰∫ö\nÁ¥çÁ±≥ÊØî‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((23.38066 -1‚Ä¶\n\n\n172\nAdmin-0 country\n1\n2\nEthiopia\nETH\n0\n2\nSovereign country\n1\nEthiopia\nETH\n0\nEthiopia\nETH\n0\nEthiopia\nETH\n0\nEthiopia\nEthiopia\nETH\nEthiopia\nNA\nEth.\nET\nFederal Democratic Republic of Ethiopia\nNA\nEthiopia\nNA\nNA\nEthiopia\nNA\n4\n4\n1\n13\n112078730\n17\n2019\n95912\n2019\n7. Least developed region\n5. Low income\nET\nET\nET\nETH\nETH\n231\n231\n231\nET\nETH\n23424808\n23424808\nExact WOE match as country\nETH\nNA\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\n-99\n-99\nAfrica\nAfrica\nEastern Africa\nSub-Saharan Africa\n8\n8\n4\n-99\n1\n0\n2.0\n7.0\n39.088600\n8.032795\n1159320617\nQ115\nÿ•ÿ´ŸäŸàÿ®Ÿäÿß\n‡¶á‡¶•‡¶ø‡¶ì‡¶™‡¶ø‡¶Ø‡¶º‡¶æ\n√Ñthiopien\nEthiopia\nEtiop√≠a\nÿßÿ™€åŸàŸæ€å\n√âthiopie\nŒëŒπŒ∏ŒπŒøœÄŒØŒ±\n◊ê◊™◊ô◊ï◊§◊ô◊î\n‡§á‡§•‡§ø‡§Ø‡•ã‡§™‡§ø‡§Ø‡§æ\nEti√≥pia\nEthiopia\nEtiopia\n„Ç®„ÉÅ„Ç™„Éî„Ç¢\nÏóêÌã∞Ïò§ÌîºÏïÑ\nEthiopi√´\nEtiopia\nEti√≥pia\n–≠—Ñ–∏–æ–ø–∏—è\nEtiopien\nEtiyopya\n–ï—Ñ—ñ–æ–ø—ñ—è\nÿß€åÿ™⁄æŸàŸæ€åÿß\nEthiopia\nÂüÉÂ°û‰øÑÊØî‰∫ö\nË°£Á¥¢ÊØî‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((35.26836 5‚Ä¶.",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#our-first-real-spatial-join-st_join",
    "href": "w06/index.html#our-first-real-spatial-join-st_join",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Our First Real Spatial Join: st_join()",
    "text": "Our First Real Spatial Join: st_join()\n\n\nCode\njoined_sf &lt;- countries_points_sf |&gt; st_join(sampled_points_sf)\njoined_sf |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeaturecla\nscalerank\nlabelrank\nsovereignt\nsov_a3\nadm0_dif\nlevel\ntype\ntlc\nadmin\nadm0_a3\ngeou_dif\ngeounit\ngu_a3\nsu_dif\nsubunit\nsu_a3\nbrk_diff\nname\nname_long\nbrk_a3\nbrk_name\nbrk_group\nabbrev\npostal\nformal_en\nformal_fr\nname_ciawf\nnote_adm0\nnote_brk\nname_sort\nname_alt\nmapcolor7\nmapcolor8\nmapcolor9\nmapcolor13\npop_est\npop_rank\npop_year\ngdp_md\ngdp_year\neconomy\nincome_grp\nfips_10\niso_a2\niso_a2_eh\niso_a3\niso_a3_eh\niso_n3\niso_n3_eh\nun_a3\nwb_a2\nwb_a3\nwoe_id\nwoe_id_eh\nwoe_note\nadm0_iso\nadm0_diff\nadm0_tlc\nadm0_a3_us\nadm0_a3_fr\nadm0_a3_ru\nadm0_a3_es\nadm0_a3_cn\nadm0_a3_tw\nadm0_a3_in\nadm0_a3_np\nadm0_a3_pk\nadm0_a3_de\nadm0_a3_gb\nadm0_a3_br\nadm0_a3_il\nadm0_a3_ps\nadm0_a3_sa\nadm0_a3_eg\nadm0_a3_ma\nadm0_a3_pt\nadm0_a3_ar\nadm0_a3_jp\nadm0_a3_ko\nadm0_a3_vn\nadm0_a3_tr\nadm0_a3_id\nadm0_a3_pl\nadm0_a3_gr\nadm0_a3_it\nadm0_a3_nl\nadm0_a3_se\nadm0_a3_bd\nadm0_a3_ua\nadm0_a3_un\nadm0_a3_wb\ncontinent\nregion_un\nsubregion\nregion_wb\nname_len\nlong_len\nabbrev_len\ntiny\nhomepart\nmin_zoom\nmin_label\nmax_label\nlabel_x\nlabel_y\nne_id\nwikidataid\nname_ar\nname_bn\nname_de\nname_en\nname_es\nname_fa\nname_fr\nname_el\nname_he\nname_hi\nname_hu\nname_id\nname_it\nname_ja\nname_ko\nname_nl\nname_pl\nname_pt\nname_ru\nname_sv\nname_tr\nname_uk\nname_ur\nname_vi\nname_zh\nname_zht\nfclass_iso\ntlc_diff\nfclass_tlc\nfclass_us\nfclass_fr\nfclass_ru\nfclass_es\nfclass_cn\nfclass_tw\nfclass_in\nfclass_np\nfclass_pk\nfclass_de\nfclass_gb\nfclass_br\nfclass_il\nfclass_ps\nfclass_sa\nfclass_eg\nfclass_ma\nfclass_pt\nfclass_ar\nfclass_jp\nfclass_ko\nfclass_vn\nfclass_tr\nfclass_id\nfclass_pl\nfclass_gr\nfclass_it\nfclass_nl\nfclass_se\nfclass_bd\nfclass_ua\ntemp\ngeometry\n\n\n\n\n57\nAdmin-0 country\n1\n2\nSouth Africa\nZAF\n0\n2\nSovereign country\n1\nSouth Africa\nZAF\n0\nSouth Africa\nZAF\n0\nSouth Africa\nZAF\n0\nSouth Africa\nSouth Africa\nZAF\nSouth Africa\nNA\nS.Af.\nZA\nRepublic of South Africa\nNA\nSouth Africa\nNA\nNA\nSouth Africa\nNA\n2\n3\n4\n2\n58558270\n16\n2019\n351431\n2019\n5. Emerging region: G20\n3. Upper middle income\nSF\nZA\nZA\nZAF\nZAF\n710\n710\n710\nZA\nZAF\n23424942\n23424942\nExact WOE match as country\nZAF\nNA\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\nZAF\n-99\n-99\nAfrica\nAfrica\nSouthern Africa\nSub-Saharan Africa\n12\n12\n5\n-99\n1\n0\n1.7\n6.7\n23.665734\n-29.708776\n1159321431\nQ258\nÿ¨ŸÜŸàÿ® ÿ£ŸÅÿ±ŸäŸÇŸäÿß\n‡¶¶‡¶ï‡ßç‡¶∑‡¶ø‡¶£ ‡¶Ü‡¶´‡ßç‡¶∞‡¶ø‡¶ï‡¶æ\nS√ºdafrika\nSouth Africa\nSud√°frica\nÿ¢ŸÅÿ±€åŸÇÿß€å ÿ¨ŸÜŸàÿ®€å\nAfrique du Sud\nŒùœåœÑŒπŒ± ŒëœÜœÅŒπŒ∫ŒÆ\n◊ì◊®◊ï◊ù ◊ê◊§◊®◊ô◊ß◊î\n‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§´‡§º‡•ç‡§∞‡•Ä‡§ï‡§æ\nD√©l-afrikai K√∂zt√°rsas√°g\nAfrika Selatan\nSudafrica\nÂçó„Ç¢„Éï„É™„Ç´ÂÖ±ÂíåÂõΩ\nÎÇ®ÏïÑÌîÑÎ¶¨Ïπ¥ Í≥µÌôîÍµ≠\nZuid-Afrika\nPo≈Çudniowa Afryka\n√Åfrica do Sul\n–Æ–ê–†\nSydafrika\nG√ºney Afrika Cumhuriyeti\n–ü—ñ–≤–¥–µ–Ω–Ω–æ-–ê—Ñ—Ä–∏–∫–∞–Ω—Å—å–∫–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞\nÿ¨ŸÜŸàÿ®€å ÿßŸÅÿ±€åŸÇÿß\nC·ªông h√≤a Nam Phi\nÂçóÈùû\nÂçóÈùû\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n67.81674\nMULTIPOLYGON (((29.36484 -2‚Ä¶\n\n\n92\nAdmin-0 country\n1\n3\nNiger\nNER\n0\n2\nSovereign country\n1\nNiger\nNER\n0\nNiger\nNER\n0\nNiger\nNER\n0\nNiger\nNiger\nNER\nNiger\nNA\nNiger\nNE\nRepublic of Niger\nNA\nNiger\nNA\nNA\nNiger\nNA\n4\n5\n3\n13\n23310715\n15\n2019\n12911\n2019\n7. Least developed region\n5. Low income\nNG\nNE\nNE\nNER\nNER\n562\n562\n562\nNE\nNER\n23424906\n23424906\nExact WOE match as country\nNER\nNA\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\nNER\n-99\n-99\nAfrica\nAfrica\nWestern Africa\nSub-Saharan Africa\n5\n5\n5\n-99\n1\n0\n3.0\n8.0\n9.504356\n17.446195\n1159321087\nQ1032\nÿßŸÑŸÜŸäÿ¨ÿ±\n‡¶®‡¶æ‡¶á‡¶ú‡¶æ‡¶∞\nNiger\nNiger\nN√≠ger\nŸÜ€åÿ¨ÿ±\nNiger\nŒùŒØŒ≥Œ∑œÅŒ±œÇ\n◊†◊ô◊ñ‚Äô◊®\n‡§®‡§æ‡§á‡§ú‡§∞\nNiger\nNiger\nNiger\n„Éã„Ç∏„Çß„Éº„É´\nÎãàÏ†úÎ•¥\nNiger\nNiger\nN√≠ger\n–ù–∏–≥–µ—Ä\nNiger\nNijer\n–ù—ñ–≥–µ—Ä\nŸÜÿßÿ¶ÿ¨ÿ±\nNiger\nÂ∞ºÊó•Â∞î\nÂ∞ºÊó•\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n63.03099\nMULTIPOLYGON (((13.60635 13‚Ä¶\n\n\n102\nAdmin-0 country\n1\n3\nNamibia\nNAM\n0\n2\nSovereign country\n1\nNamibia\nNAM\n0\nNamibia\nNAM\n0\nNamibia\nNAM\n0\nNamibia\nNamibia\nNAM\nNamibia\nNA\nNam.\nNA\nRepublic of Namibia\nNA\nNamibia\nNA\nNA\nNamibia\nNA\n4\n1\n1\n7\n2494530\n12\n2019\n12366\n2019\n6. Developing region\n3. Upper middle income\nWA\nNA\nNA\nNAM\nNAM\n516\n516\n516\nNA\nNAM\n23424987\n23424987\nExact WOE match as country\nNAM\nNA\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\nNAM\n-99\n-99\nAfrica\nAfrica\nSouthern Africa\nSub-Saharan Africa\n7\n7\n4\n-99\n1\n0\n3.0\n7.5\n17.108166\n-20.575298\n1159321085\nQ1030\nŸÜÿßŸÖŸäÿ®Ÿäÿß\n‡¶®‡¶æ‡¶Æ‡¶ø‡¶¨‡¶ø‡¶Ø‡¶º‡¶æ\nNamibia\nNamibia\nNamibia\nŸÜÿßŸÖ€åÿ®€åÿß\nNamibie\nŒùŒ±ŒºŒØŒºœÄŒπŒ±\n◊†◊û◊ô◊ë◊ô◊î\n‡§®‡§æ‡§Æ‡•Ä‡§¨‡§ø‡§Ø‡§æ\nNam√≠bia\nNamibia\nNamibia\n„Éä„Éü„Éì„Ç¢\nÎÇòÎØ∏ÎπÑÏïÑ\nNamibi√´\nNamibia\nNam√≠bia\n–ù–∞–º–∏–±–∏—è\nNamibia\nNamibya\n–ù–∞–º—ñ–±—ñ—è\nŸÜŸÖ€åÿ®€åÿß\nNamibia\nÁ∫≥Á±≥ÊØî‰∫ö\nÁ¥çÁ±≥ÊØî‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n81.02296\nMULTIPOLYGON (((23.38066 -1‚Ä¶\n\n\n172\nAdmin-0 country\n1\n2\nEthiopia\nETH\n0\n2\nSovereign country\n1\nEthiopia\nETH\n0\nEthiopia\nETH\n0\nEthiopia\nETH\n0\nEthiopia\nEthiopia\nETH\nEthiopia\nNA\nEth.\nET\nFederal Democratic Republic of Ethiopia\nNA\nEthiopia\nNA\nNA\nEthiopia\nNA\n4\n4\n1\n13\n112078730\n17\n2019\n95912\n2019\n7. Least developed region\n5. Low income\nET\nET\nET\nETH\nETH\n231\n231\n231\nET\nETH\n23424808\n23424808\nExact WOE match as country\nETH\nNA\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\nETH\n-99\n-99\nAfrica\nAfrica\nEastern Africa\nSub-Saharan Africa\n8\n8\n4\n-99\n1\n0\n2.0\n7.0\n39.088600\n8.032795\n1159320617\nQ115\nÿ•ÿ´ŸäŸàÿ®Ÿäÿß\n‡¶á‡¶•‡¶ø‡¶ì‡¶™‡¶ø‡¶Ø‡¶º‡¶æ\n√Ñthiopien\nEthiopia\nEtiop√≠a\nÿßÿ™€åŸàŸæ€å\n√âthiopie\nŒëŒπŒ∏ŒπŒøœÄŒØŒ±\n◊ê◊™◊ô◊ï◊§◊ô◊î\n‡§á‡§•‡§ø‡§Ø‡•ã‡§™‡§ø‡§Ø‡§æ\nEti√≥pia\nEthiopia\nEtiopia\n„Ç®„ÉÅ„Ç™„Éî„Ç¢\nÏóêÌã∞Ïò§ÌîºÏïÑ\nEthiopi√´\nEtiopia\nEti√≥pia\n–≠—Ñ–∏–æ–ø–∏—è\nEtiopien\nEtiyopya\n–ï—Ñ—ñ–æ–ø—ñ—è\nÿß€åÿ™⁄æŸàŸæ€åÿß\nEthiopia\nÂüÉÂ°û‰øÑÊØî‰∫ö\nË°£Á¥¢ÊØî‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n81.21944\nMULTIPOLYGON (((35.26836 5‚Ä¶.\n\n\n175\nAdmin-0 country\n1\n4\nEquatorial Guinea\nGNQ\n0\n2\nSovereign country\n1\nEquatorial Guinea\nGNQ\n0\nEquatorial Guinea\nGNQ\n0\nEquatorial Guinea\nGNQ\n0\nEq. Guinea\nEquatorial Guinea\nGNQ\nEq. Guinea\nNA\nEq. G.\nGQ\nRepublic of Equatorial Guinea\nNA\nEquatorial Guinea\nNA\nNA\nEquatorial Guinea\nNA\n4\n1\n4\n8\n1355986\n12\n2019\n11026\n2019\n7. Least developed region\n2. High income: nonOECD\nEK\nGQ\nGQ\nGNQ\nGNQ\n226\n226\n226\nGQ\nGNQ\n23424804\n23424804\nExact WOE match as country\nGNQ\nNA\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\nGNQ\n-99\n-99\nAfrica\nAfrica\nMiddle Africa\nSub-Saharan Africa\n10\n17\n6\n-99\n1\n0\n4.0\n9.0\n8.990200\n2.333000\n1159320801\nQ983\nÿ∫ŸäŸÜŸäÿß ÿßŸÑÿßÿ≥ÿ™Ÿàÿßÿ¶Ÿäÿ©\n‡¶¨‡¶ø‡¶∑‡ßÅ‡¶¨‡ßÄ‡¶Ø‡¶º ‡¶ó‡¶ø‡¶®‡¶ø\n√Ñquatorialguinea\nEquatorial Guinea\nGuinea Ecuatorial\n⁄Ø€åŸÜŸá ÿßÿ≥ÿ™Ÿàÿß€å€å\nGuin√©e √©quatoriale\nŒôœÉŒ∑ŒºŒµœÅŒπŒΩŒÆ ŒìŒøœÖŒπŒΩŒ≠Œ±\n◊í◊ô◊†◊ê◊î ◊î◊û◊©◊ï◊ï◊†◊ô◊™\n‡§≠‡•Ç‡§Æ‡§ß‡•ç‡§Ø‡§∞‡•á‡§ñ‡•Ä‡§Ø ‡§ó‡§ø‡§®‡•Ä\nEgyenl√≠t≈ëi-Guinea\nGuinea Khatulistiwa\nGuinea Equatoriale\nËµ§ÈÅì„ÇÆ„Éã„Ç¢\nÏ†ÅÎèÑ Í∏∞Îãà\nEquatoriaal-Guinea\nGwinea R√≥wnikowa\nGuin√© Equatorial\n–≠–∫–≤–∞—Ç–æ—Ä–∏–∞–ª—å–Ω–∞—è –ì–≤–∏–Ω–µ—è\nEkvatorialguinea\nEkvator Ginesi\n–ï–∫–≤–∞—Ç–æ—Ä—ñ–∞–ª—å–Ω–∞ –ì–≤—ñ–Ω–µ—è\nÿßÿ≥ÿ™Ÿàÿßÿ¶€å ⁄ØŸÜ€å\nGuinea X√≠ch ƒê·∫°o\nËµ§ÈÅìÂá†ÂÜÖ‰∫ö\nËµ§ÈÅìÂπæÂÖß‰∫û\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n75.39512\nMULTIPOLYGON (((8.735742 3‚Ä¶.\n\n\n177\nAdmin-0 country\n1\n2\nEgypt\nEGY\n0\n2\nSovereign country\n1\nEgypt\nEGY\n0\nEgypt\nEGY\n0\nEgypt\nEGY\n0\nEgypt\nEgypt\nEGY\nEgypt\nNA\nEgypt\nEG\nArab Republic of Egypt\nNA\nEgypt\nNA\nNA\nEgypt, Arab Rep.\nNA\n4\n6\n7\n2\n100388073\n17\n2019\n303092\n2019\n5. Emerging region: G20\n4. Lower middle income\nEG\nEG\nEG\nEGY\nEGY\n818\n818\n818\nEG\nEGY\n23424802\n23424802\nExact WOE match as country\nEGY\nNA\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\nEGY\n-99\n-99\nAfrica\nAfrica\nNorthern Africa\nMiddle East & North Africa\n5\n5\n5\n-99\n1\n0\n1.7\n6.7\n29.445837\n26.186173\n1159320575\nQ79\nŸÖÿµÿ±\n‡¶Æ‡¶ø‡¶∂‡¶∞\n√Ñgypten\nEgypt\nEgipto\nŸÖÿµÿ±\n√âgypte\nŒëŒØŒ≥œÖœÄœÑŒøœÇ\n◊û◊¶◊®◊ô◊ù\n‡§Æ‡§ø‡§∏‡•ç‡§∞\nEgyiptom\nMesir\nEgitto\n„Ç®„Ç∏„Éó„Éà\nÏù¥ÏßëÌä∏\nEgypte\nEgipt\nEgito\n–ï–≥–∏–ø–µ—Ç\nEgypten\nMƒ±sƒ±r\n–Ñ–≥–∏–ø–µ—Ç\nŸÖÿµÿ±\nAi C·∫≠p\nÂüÉÂèä\nÂüÉÂèä\nAdmin-0 country\nNA\nAdmin-0 country\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n97.04420\nMULTIPOLYGON (((36.87139 21‚Ä¶",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#but-we-were-still-in-easy-mode",
    "href": "w06/index.html#but-we-were-still-in-easy-mode",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "But‚Ä¶ We Were Still in Easy Mode",
    "text": "But‚Ä¶ We Were Still in Easy Mode\n\nEvery point could be matched one-to-one with a country. But what if‚Ä¶ üò±\n\n\n\nCode\ng &lt;- st_make_grid(st_bbox(st_as_sfc(\"LINESTRING(0 0,1 1)\")), n = c(2,2))\npar(mar = rep(0,4))\nplot(g)\nplot(g[1] * diag(c(3/4, 1)) + c(0.25, 0.125), add = TRUE, lty = 2)\ntext(c(.2, .8, .2, .8), c(.2, .2, .8, .8), c(1,2,4,8), col = 'red')",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#spatially-intensive-vs.-spatially-extensive",
    "href": "w06/index.html#spatially-intensive-vs.-spatially-extensive",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Spatially Intensive vs.¬†Spatially Extensive",
    "text": "Spatially Intensive vs.¬†Spatially Extensive\n\nExtensive attributes: associated with a physical size (length, area, volume, counts of items). Ex: population count.\n\nAssociated with an area \\(\\implies\\) if that area is cut into smaller areas, the population count needs to be split too\n(At minimum, the sum of the population counts for the smaller areas needs to equal the total for the larger area)\n\nIntensive attributes: Not proportional to support: if the area is split, values may vary but on average remain the same. Ex: population density\n\nIf an area is split into smaller areas, population density is not split similarly!\nThe sum of population densities for the smaller areas is a meaningless measure\nInstead, the mean will be more useful as ~similar to the density of the total",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#handling-the-extensive-case",
    "href": "w06/index.html#handling-the-extensive-case",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Handling the Extensive Case",
    "text": "Handling the Extensive Case\n\nAssume the extensive attribute \\(Y\\) is uniformly distributed over a space \\(S_i\\) (e.g., for population counts we assume everyone is evenly-spaced across the region)\nWe first compute \\(Y_{ij}\\), derived from \\(Y_i\\) for a sub-area of \\(S_i\\), \\(A_{ij} = S_i \\cap T_j\\):\n\\[\n\\hat{Y}_{ij}(A_{ij}) = \\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\]\nwhere \\(|\\cdot|\\) denotes area.\nThen we can compute \\(Y_j(T_j)\\) by summing all the elements over area \\(T_j\\):\n\n\\[\n\\hat{Y}_j(T_j) = \\sum_{i=1}^{p}\\frac{|A_{ij}|}{|S_i|}Y_i(S_i)\n\\]",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#handling-the-intensive-case",
    "href": "w06/index.html#handling-the-intensive-case",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Handling the Intensive Case",
    "text": "Handling the Intensive Case\n\nAssume the variable \\(Y\\) has constant value over a space \\(S_i\\) (e.g., population density in assumed to be the same across all sub-areas)\nThen the estimate for a sub-area is the same as the estimate for the total area:\n\n\\[\n\\hat{Y}_{ij} = Y_i(S_i)\n\\]\n\nSo that we can obtain estimates of \\(Y\\) for new spatial units \\(T_j\\) via area-weighted average of the source values:\n\n\\[\n\\hat{Y}_j(T_j) = \\sum_{i=1}^{p}\\frac{|A_{ij}|}{|T_j|}Y_j(S_i)\n\\]",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#lets-go-see-it-in-action",
    "href": "w06/index.html#lets-go-see-it-in-action",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "Let‚Äôs Go See It In Action!",
    "text": "Let‚Äôs Go See It In Action!\n¬†\n\nWeek 6 Lab: Interpolating Kurdistan",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w06/index.html#references",
    "href": "w06/index.html#references",
    "title": "Week 6: Spatial Joins and Areal-Weighted Interpolation",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 6: Oct 1"
    ]
  },
  {
    "objectID": "w08/slides.html#morans-i",
    "href": "w08/slides.html#morans-i",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Moran‚Äôs \\(I\\)",
    "text": "Moran‚Äôs \\(I\\)\n\\[\nI =\n\\underset{\\text{Inverse of Variance}}{\\boxed{\\frac{n}{\\sum_{i=1}^{n}(y_i - \\overline{y})^2}}}\n\\frac\n  {\\overbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}(y_i - \\overline{y})(y_j - \\overline{y})}^{\\text{Weighted Covariance}}}\n  {\\underbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}}_{\\text{Normalize Weights}}}\n\\]\n\n\\(I\\) is Large when:\n\n\\(y_i\\) and \\(y_j\\) are neighbors: \\(w_{ij}\\), and\n\\(y_i\\) and \\(y_j\\) large at the same time: \\((y_i - \\overline{y})(y_j - \\overline{y})\\)"
  },
  {
    "objectID": "w08/slides.html#local-indicators-of-spatial-autocorrelation-lisa",
    "href": "w08/slides.html#local-indicators-of-spatial-autocorrelation-lisa",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Local Indicators of Spatial Autocorrelation (LISA)",
    "text": "Local Indicators of Spatial Autocorrelation (LISA)\n\ntldr: See how much a given location \\(\\mathbf{s}\\) contributes to overall Moran‚Äôs \\(I\\)\nLocal Moran‚Äôs \\(I\\):\n\n\\[\nI_i = \\frac{y_i - \\overline{y}}{S_i^2}\\sum_{j=1}^{n}w_{ij}(y_j - \\overline{y})\n\\]"
  },
  {
    "objectID": "w08/slides.html#or-non-human-nature-examples",
    "href": "w08/slides.html#or-non-human-nature-examples",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "‚Ä¶Or, [Non-Human] Nature Examples",
    "text": "‚Ä¶Or, [Non-Human] Nature Examples\n\n\n\n\n\n\nNamibian ‚ÄúFairy Circles‚Äù; Smithsonian Magazine: Namibia‚Äôs mysterious fairy circles may be competition üëÄ between plants\n\n\n\n\n\nTermite mounds in Mozambique\n\n\n\n\n\n\nFree stock photo by @natalinadmay\n\n\n\n\n\n\nThree kestral (bird) colonies form a triangle straddling the Basilicata and Apulia regions of Italy; from Morinay et al. (2023)\n\n\n\n\n\nSpatial clustering of birdsongs; from Crates et al. (2021)"
  },
  {
    "objectID": "w08/slides.html#but-a-challenge",
    "href": "w08/slides.html#but-a-challenge",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "But, a Challenge‚Ä¶",
    "text": "But, a Challenge‚Ä¶\nTypically depends on context and/or level of resolution and/or level of analysis\n\nFrom Waller and Gotway (2004)"
  },
  {
    "objectID": "w08/slides.html#why-na√Øve",
    "href": "w08/slides.html#why-na√Øve",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Why ‚ÄúNa√Øve‚Äù?",
    "text": "Why ‚ÄúNa√Øve‚Äù?\n\nRegional data: easiest way to visualize / operationalize simple measures of clustering via spatial autocorrelation\nSo, we develop intuitions for measures like Moran‚Äôs \\(I\\) by looking at lattice data, but‚Ä¶\nNa√Øve because we‚Äôre not modeling the lattice regions (cells) themselves!\nNon-na√Øve clustering: Knowing the clusters but also what process led to their formation! Which brings us to‚Ä¶"
  },
  {
    "objectID": "w08/slides.html#spatial-randomness",
    "href": "w08/slides.html#spatial-randomness",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Spatial Randomness",
    "text": "Spatial Randomness\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6805)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n#reg_sims &lt;- rMaternI(N, r=r_core, win=obs_window)\ncond_reg_sims &lt;- rSSI(r=r_core, N)\n# CSR data\n#csr_sims &lt;- rpoispp(N, win=obs_window)\ncond_sr_sims &lt;- rpoint(N, win=obs_window)\n### Clustered data\n#clust_sims &lt;- rMatClust(kappa=6, r=2.5*r_core, mu=10, win=obs_window)\n#clust_sims &lt;- rMatClust(mu=5, kappa=1, scale=0.1, win=obs_window, n.cond=N, w.cond=obs_window)\n#clust_sims &lt;- rclusterBKBC(clusters=\"MatClust\", kappa=10, mu=10, scale=0.05, verbose=FALSE)\n# Each cluster consist of 10 points in a disc of radius 0.2\nnclust &lt;- function(x0, y0, radius, n) {\n    #print(n)\n    return(runifdisc(10, radius, centre=c(x0, y0)))\n}\ncond_clust_sims &lt;- rNeymanScott(kappa=5, expand=0.0, rclust=nclust, radius=2*r_core, n=10)\n# And PLOT\nplot_w &lt;- 400\nplot_h &lt;- 400\nplot_scale &lt;- 2.25\ncond_reg_plot &lt;- cond_reg_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_reg.png\", cond_reg_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncond_sr_plot &lt;- cond_sr_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_sr.png\", cond_sr_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncond_clust_plot &lt;- cond_clust_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_clust.png\", cond_clust_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed \\(N\\)\n60\n\n60\n\n60\n\n\nProblem with fixed \\(N\\): Learning there are \\(n_1\\) points in region \\(R_1\\) \\(\\Rightarrow\\) there are \\(N - n_1\\) points outside \\(R_1\\)"
  },
  {
    "objectID": "w08/slides.html#complete-spatial-randomness-csr",
    "href": "w08/slides.html#complete-spatial-randomness-csr",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Complete Spatial Randomness (CSR)",
    "text": "Complete Spatial Randomness (CSR)\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6807)\nlambda &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n# Regularity via Inhibition\nreg_sims &lt;- rMaternI(lambda, r=r_core, win=obs_window)\n# CSR data\ncsr_sims &lt;- rpoispp(N, win=obs_window)\n### Clustered data\nclust_mu &lt;- 10\nclust_sims &lt;- rMatClust(kappa=lambda / clust_mu, scale=2*r_core, mu=10, win=obs_window)\n# And PLOT\nplot_w &lt;- 400\nplot_h &lt;- 400\nplot_scale &lt;- 2.25\nreg_plot &lt;- reg_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",reg_sims$n)) +\n  dsan_theme()\nggsave(\"images/reg.png\", reg_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncsr_plot &lt;- csr_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",csr_sims$n)) +\n  dsan_theme()\nggsave(\"images/csr.png\", csr_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\nclust_plot &lt;- clust_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",clust_sims$n)) +\n  dsan_theme()\nggsave(\"images/clust.png\", clust_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed Intensity \\(\\lambda\\)\n60\n\n60\n\n60\n\n\nRandom \\(N\\)"
  },
  {
    "objectID": "w08/slides.html#caveat-1-measures-are-relative-to-window-of-observation",
    "href": "w08/slides.html#caveat-1-measures-are-relative-to-window-of-observation",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Caveat 1: Measures are Relative to Window of Observation",
    "text": "Caveat 1: Measures are Relative to Window of Observation\nSame data can be spatially random within one window, clustered or regular in others!\n\n\nCode\nN &lt;- 60\nobs_window &lt;- square(1)\nwindow_scale &lt;- 3.5\ncsr_sims_square &lt;- rpoispp(N, win=obs_window)\n# Triangular window\nobs_window_tri &lt;- st_sfc(st_polygon(list(\n    matrix(c(0.3,0.1,0.7,0.1,0.5,0.5,0.3,0.1), byrow=TRUE, nrow=4)\n)))\nobs_window_geom &lt;- st_sfc(st_linestring(\n    matrix(c(0,0,1,0,1,1,0,1,0,0), byrow=TRUE, nrow=5)\n))\ncsr_sims_tri &lt;- ppp(csr_sims_square$x, csr_sims_square$y, window=as.owin(obs_window_tri))\ntri_plot &lt;- csr_sims_tri |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme(\"quarter\");\nggsave(\"images/window_tri.png\", tri_plot, width=plot_w, height=plot_h, units=\"px\", scale=window_scale)\n# Square window\nsquare_plot &lt;- csr_sims_square |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  geom_sf(data=obs_window_tri |&gt; sf::st_boundary()) +\n  dsan_theme(\"quarter\")\nggsave(\"images/window_square.png\", square_plot, width=plot_w, height=plot_h, units=\"px\", scale=window_scale)\n# Circular window\nobs_window_disc &lt;- st_sfc(st_point(c(1, 0.5))) |&gt; st_buffer(1.2)\ncsr_sims_circ &lt;- ppp(csr_sims_square$x, csr_sims_square$y, window=as.owin(obs_window_disc))\ncirc_plot &lt;- csr_sims_circ |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  geom_sf(data=obs_window_geom) +\n  dsan_theme(\"quarter\")\nggsave(\"images/window_circ.png\", circ_plot, width=plot_w, height=plot_h, units=\"px\", scale=window_scale)\n\n\n\n\n\n\n\n\n\n\nRegular\nCSR\nClustered"
  },
  {
    "objectID": "w08/slides.html#caveat-2-summary-statistics-like-i-are-not-models",
    "href": "w08/slides.html#caveat-2-summary-statistics-like-i-are-not-models",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!",
    "text": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!\n\nMoran‚Äôs \\(I\\) is to GISers what a thermometer is to doctors\nMeasures symptoms; many possible underlying causes!\nNeed to ask why autocorrelation seems to be present!"
  },
  {
    "objectID": "w08/slides.html#why-do-events-appear-where-they-do",
    "href": "w08/slides.html#why-do-events-appear-where-they-do",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "[] Why Do Events Appear Where They Do?",
    "text": "[] Why Do Events Appear Where They Do?\n\n\nCode\ncenter_l_function &lt;- function(x, ...) {\n  if (!spatstat.geom::is.ppp(x) && !spatstat.geom::is.fv(x)) {\n    stop(\"Please provide either ppp or fv object.\")\n  }\n  if (spatstat.geom::is.ppp(x)) {\n    x &lt;- spatstat.explore::Lest(x, ...)\n  }\n  r &lt;- x$r\n  l_centered &lt;- spatstat.explore::eval.fv(x - r)\n  return(l_centered)\n}\ncond_clust_sf &lt;- cond_clust_sims |&gt; sf::st_as_sf()\npines_plot &lt;- cond_clust_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic(base_size=12)\nggsave(\"images/pines.png\", pines_plot)\n# density() calls density.ppp() if the argument is a ppp object\nden &lt;- density(cond_clust_sims, sigma = 0.1)\n#summary(den)\npng(\"images/intensity_plot.png\")\nplot(den, main = \"Intensity Œª(s)\")\ncontour(den, add = TRUE) # contour plot\ndev.off()\n# And Gest / Kest / Lest\n# saveRDS(cond_clust_sims, \"cond_clust_sims.rds\")\npcf_result &lt;- spatstat.explore::pcf.ppp(\n  cond_clust_sims,\n  divisor=\"d\",\n  stoyan=0.25,\n  bw=0.05,\n  r=seq(from=0.0, to=1.0, by=0.001)\n)\npng(\"images/spatstat_pcf.png\")\nplot(pcf_result, xlim=c(0, 1), main=\"pcf\")\ndev.off()\n# kest_result &lt;- Kest(cond_clust_sims, rmax=0.5, correction=\"best\")\n# lest_result &lt;- center_l_function(cond_clust_sims, rmax=0.5)\n# png(\"images/lest.png\")\n# plot(lest_result, main=\"K(h)\")\n# dev.off()\n\n\n\n\n\n\n\n\n\n\n\nFirst-Order\nSecond-Order\n\n\n\n\n\nEvents considered individually \\(\\Rightarrow\\) Intensity function \\(\\lambda(\\mathbf{s})\\)\nEvents considered pairwise \\(\\Rightarrow\\) Pairwise Correlation Function \\(\\textrm{pcf}(\\vec{h})\\)"
  },
  {
    "objectID": "w08/slides.html#the-tree-grid-mystery",
    "href": "w08/slides.html#the-tree-grid-mystery",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "The Tree-Grid Mystery",
    "text": "The Tree-Grid Mystery\nYou‚Äôve been hired as an archaeologist ‚Äì congratulations! Your job: determine whether arrangement of trees formed:\n\nNaturally, via a process of resource competition, or\nArtificially, via an ancient civilization planting in a grid‚Ä¶"
  },
  {
    "objectID": "w08/slides.html#two-possible-histories",
    "href": "w08/slides.html#two-possible-histories",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Two Possible Histories‚Ä¶",
    "text": "Two Possible Histories‚Ä¶\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Art}}\\): Artificial Formation\n\n\n\n\n\nCode (Step 1: Grid Creation)\nha_base &lt;- 28\nsquare_sf &lt;- sf::st_as_sf(spatstat.geom::square(1))\ngrid_sf &lt;- sf::st_as_sf(sf::st_make_grid(square_sf))\ngrid_buffer_sf &lt;- grid_sf |&gt; sf::st_buffer(dist=-0.01, singleSide = TRUE)\ngrid_buffer_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Point Generation)\ngrid_points &lt;- sf::st_sample(grid_buffer_sf, size=rep(1,100))\ngrid_buffer_sf |&gt; ggplot(aes(shape='Cell')) +\n  geom_sf() +\n  geom_sf(data=grid_points) +\n  scale_shape_manual(\"Shape\", values=c('Cell'=19)) +\n  theme_classic(base_size=ha_base) +\n  theme(\n    legend.title = element_blank(),\n    # legend.text = element_text(size=18)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\ngrid_ppp &lt;- as.ppp(grid_points, W=spatstat.geom::square(1))\ngrid_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Nat}}\\): Natural Formation\n\n\n\n\n\nCode (Step 1: Tree Generation)\nhn_base &lt;- 28\nr &lt;- 0.05\npois_ppp &lt;- rpoispp(150)\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Competition)\nage &lt;- runif(npoints(pois_ppp))\npair_dists &lt;- pairdist(pois_ppp)\nclose &lt;- (pair_dists &lt; r)\nlater &lt;- outer(age, age, \"&gt;\")\nkilled &lt;- apply(close & later, 1, any)\nkilled_ppp &lt;- pois_ppp[killed]\nalive_ppp &lt;- pois_ppp[!killed]\npois_window_sf &lt;- pois_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"window\")\npois_killed_sf &lt;- killed_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\npois_alive_sf &lt;- alive_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\nalive_buff_sf &lt;- pois_alive_sf |&gt; sf::st_buffer(r) |&gt; sf::st_union() |&gt; sf::st_intersection(pois_window_sf)\nggplot() +\n  geom_sf(data=pois_window_sf) +\n  geom_sf(data=alive_buff_sf, aes(color='Inhibition', shape='Inhibition'), linetype='dashed') +\n  geom_sf(data=pois_killed_sf, aes(color='Dead', shape='Dead'), size=2, stroke=2) +\n  geom_sf(data=pois_alive_sf, aes(color='Alive', shape='Alive'), size=1, stroke=1) +\n  scale_shape_manual(name=NULL, values=c(\"Alive\"=19, \"Dead\"=4, 'Inhibition'=21), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  scale_color_manual(name=NULL, values=c(\"Alive\"=\"black\", \"Dead\"=cb_palette[1], \"Inhibition\"=\"black\"), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  guides(shape=guide_legend(override.aes=list(fill = \"white\"))) +\n  theme_classic(base_size = hn_base) +\n  theme(plot.margin = unit(c(0,0,0,0), \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\nalive_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)"
  },
  {
    "objectID": "w08/slides.html#why-do-events-appear-where-they-do-1",
    "href": "w08/slides.html#why-do-events-appear-where-they-do-1",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Why Do Events Appear Where They Do?",
    "text": "Why Do Events Appear Where They Do?\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6809)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n### Clustered data\nclust_ppp &lt;- rMatClust(\n  kappa=6,\n  scale=r_core,\n  mu=10\n)\nclust_sf &lt;- clust_ppp |&gt; sf::st_as_sf()\nclust_plot &lt;- clust_sf |&gt;\n  ggplot() +\n  geom_sf(size=2) +\n  theme_classic(base_size=18)\nggsave(\"images/clust_ppp.png\", clust_plot, width=3, height=3)\n# Intensity fn\nclust_intensity &lt;- density(clust_ppp, sigma = 0.1)\npng(\"images/clust_intensity.png\")\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,0,0), cex=2)\nplot(clust_intensity, main=NULL)\ncontour(clust_intensity, add = TRUE)\ndev.off()\n### PCF\nclust_pcf &lt;- spatstat.explore::pcf(\n  clust_ppp, divisor=\"d\",\n  r=seq(from=0.00, to=0.50, by=0.01)\n)\nclust_pcf_plot &lt;- clust_pcf |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  labs(x=\"Distance\", y=\"Density\") +\n  theme_classic(base_size=14)\nggsave(\"images/clust_pcf.png\", clust_pcf_plot, width=3, height=3)\n\n\n\n\n\n\n\n\n\n\nOriginal Data\nFirst-Order\nSecond-Order\n\n\n\n\n\\(N = 60\\) Events\nEvents modeled individually\\(\\Rightarrow\\) Intensity Function \\(\\lambda(\\mathbf{s})\\)\nEvents modeled pairwise \\(\\Rightarrow\\) Pairwise-Corr Function \\(\\textrm{pcf}(\\vec{h})\\)"
  },
  {
    "objectID": "w08/slides.html#what-do-these-functions-detect",
    "href": "w08/slides.html#what-do-these-functions-detect",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "What Do These Functions ‚ÄúDetect‚Äù?",
    "text": "What Do These Functions ‚ÄúDetect‚Äù?\n\n\n\n\nCode (Fixed Points)\nsq_base &lt;- 16\nsq_psize &lt;- 2.5\nobs_window &lt;- square(1)\nr0 &lt;- 0.2\nsq_df &lt;- tibble::tribble(\n  ~x, ~y,\n  0.5-r0,0.5-r0,\n  0.5+r0,0.5+r0,\n  0.5-r0,0.5+r0,\n  0.5+r0,0.5-r0\n)\nsq_sf &lt;- sf::st_as_sf(\n  sq_df,\n  coords = c(\"x\",\"y\")\n)\nsq_ppp &lt;- as.ppp(sq_sf, W=obs_window)\nsq_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,1,0))\nsq_density &lt;- density(sq_ppp)\nplot(sq_density, main=NULL, xaxs='i', yaxs='i')\ncontour(sq_density, xaxs='i', yaxs='i', add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### PCF\npcf_result &lt;- spatstat.explore::pcf(\n  sq_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\npcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode (CSR Points)\ncsr_ppp &lt;- spatstat.random::rpoispp(\n  lambda = 60,\n  win=obs_window\n)\ncsr_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(\n  mar=c(0,0,0,2),\n  las=2,\n  oma=c(0,0,1,0)\n)\ncsr_density &lt;- density(csr_ppp)\nplot(csr_density, main=NULL, xaxs=\"i\", yaxs=\"i\")\ncontour(csr_density, xaxs=\"i\", yaxs=\"i\", add = TRUE, lwd=1.5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_pcf_result &lt;- spatstat.explore::pcf(\n  csr_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\ncsr_pcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)"
  },
  {
    "objectID": "w08/slides.html#poisson-point-processes-csr",
    "href": "w08/slides.html#poisson-point-processes-csr",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Poisson Point Processes (CSR)",
    "text": "Poisson Point Processes (CSR)\nspatstat.random::rpoispp(lambda, win)\n\n \\(N \\sim \\text{Pois}(\\lambda)\\)\n For \\(i \\in \\{1, \\ldots, N\\}\\):\n\nGenerate \\(X_i, Y_i \\sim \\mathcal{U}(\\texttt{win})\\)\n\n\n\n\nCode\nsim_base &lt;- 22\nsim_psize &lt;- 2\nsim_xticks &lt;- seq(from=0.0, to=1.0, by=0.2)\nsim_yticks &lt;- seq(from=0.0, to=1.0, by=0.2)\ngen_pois_df &lt;- function(num_sims=1) {\n  pois_sims &lt;- spatstat.random::rpoispp(\n    lambda = 60, nsim=num_sims\n  )\n  return(tibble::as_tibble(pois_sims))\n}\n#pois_dfs &lt;- gen_pois_df()\n#pois_dfs |&gt; head()\npois_sims &lt;- spatstat.random::rpoispp(\n  lambda = 60, nsim=3\n)\nto_sim_df &lt;- function(cur_sim, sim_name) {\n  cur_df &lt;- tibble::as_tibble(cur_sim) |&gt; mutate(sim=sim_name)\n  return(cur_df)\n}\ncombined_df &lt;- imap(.x=pois_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)"
  },
  {
    "objectID": "w08/slides.html#simple-sequential-inhibition-ssi",
    "href": "w08/slides.html#simple-sequential-inhibition-ssi",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Simple Sequential Inhibition (SSI)",
    "text": "Simple Sequential Inhibition (SSI)\nspatstat.random::rSSI(r, n=Inf, giveup=1000, win)\n\n\\(\\mathbf{S} = \\varnothing\\)\nWhile not done:\n\n Generate \\(\\mathbf{E} = (X, Y) \\sim \\mathcal{U}(\\texttt{win})\\)\n Check if \\(\\mathbf{E}\\) within r units of any existing point in \\(\\mathbf{S}\\)\n\nIf it is, throw \\(\\mathbf{E}\\) away. Otherwise, add \\(\\mathbf{E}\\) to \\(\\mathbf{S}\\)\n\n done=TRUE if \\(\\mathbf{S}\\) has n points OR has been the same for giveup steps\n\n\n\n\nCode\ncapture.output(ssi_sims &lt;- spatstat.random::rSSI(\n  r = 0.05, n=60, nsim=3\n), file=nullfile())\ncombined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=24) +\n  theme(panel.spacing.x = unit(3, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)"
  },
  {
    "objectID": "w08/slides.html#mat√©rn-cluster-process",
    "href": "w08/slides.html#mat√©rn-cluster-process",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Mat√©rn Cluster Process",
    "text": "Mat√©rn Cluster Process\n\n\nspatstat.random::rMatClust(kappa, scale, mu, win)\n\nDocs\n\n\n Generate \\(K(\\kappa)\\) parent points via Poisson Point Process with intensity \\(\\lambda = \\kappa\\)\n For each parent point \\(\\mathbf{s}_i \\in \\left\\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{K(\\kappa)}\\right\\}\\):\n\nGenerate \\(N(\\mu)\\) offspring points via Poisson Point Process with intensity \\(\\lambda = \\mu\\), distributed uniformly within a circle of radius scale centered at \\(\\mathbf{s}_i\\)\n\n Offspring points form the outcome (parent points are thrown away)\n\n\n\nCode\nmatclust_sims &lt;- rMatClust(\n  kappa = 6,\n  scale = 0.075,\n  mu = 10,\n  nsim = 3\n)\nmatclust_df &lt;- imap(.x=matclust_sims, .f=to_sim_df) |&gt; bind_rows()\nmatclust_plot &lt;- matclust_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nmatclust_plot"
  },
  {
    "objectID": "w08/slides.html#mat√©rn-inhibition-process-i-and-ii",
    "href": "w08/slides.html#mat√©rn-inhibition-process-i-and-ii",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Mat√©rn Inhibition Process (I and II)",
    "text": "Mat√©rn Inhibition Process (I and II)\nspatstat.random::rMaternI(kappa, r, win)\nspatstat.random::rMaternII(kappa, r, win)\n\n\n\n\n\n\n\nrMaternI() [Docs]\nrMaternII() [Docs]\n\n\n\n\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\)\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\), plus timestamp \\(t_i \\sim \\mathcal{U}(0,1)\\) for each \\(\\mathbf{s}_i\\)\n\n\n\n\n Delete all pairs of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\) for which \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\)\n\n\n For each pair of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\): if \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\), delete the later point\n\n\n\n\n\n\nCode\nmI_sims &lt;- rMaternI(\n  kappa = 60, r = 0.075, nsim=2\n)\nmII_sims &lt;- rMaternII(\n  kappa = 60, r = 0.075, nsim=2\n)\nmI_combined_df &lt;- imap(.x=mI_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MI \",sim))\nmII_combined_df &lt;- imap(.x=mII_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MII \",sim))\nm_combined_df &lt;- bind_rows(mI_combined_df, mII_combined_df)\nm_plot &lt;- m_combined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nm_plot"
  },
  {
    "objectID": "w08/slides.html#cox-processes-random-intensity-random-events",
    "href": "w08/slides.html#cox-processes-random-intensity-random-events",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Cox Processes: Random Intensity ‚Üí Random Events",
    "text": "Cox Processes: Random Intensity ‚Üí Random Events\n\n\nspatstat.random::rLGCP(model, mu, param, win)\nmodels=c(\"exponential\", \"gauss\", \"stable\", \"gencauchy\", \"matern\")\n\nDocs\n\n\n\nCode\ncox_pcol &lt;- \"black\"\ncox_bg &lt;- \"grey90\"\ncox_pch &lt;- 21\n# inhomogeneous LGCP with Gaussian covariance function\nm &lt;- as.im(function(x, y){\n  5 - 1.5 * (x - 0.5)^2 + 2 * (y - 0.5)^2\n}, W=owin())\nlgcp_sims &lt;- rLGCP(\"gauss\", m, var=0.15, scale =0.5, nsim=3)\n# lgcp_combined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\nplot_lgcp &lt;- function(lgcp_sim) {\n  plot(attr(lgcp_sim, \"Lambda\"), main=NULL)\n  points(lgcp_sim, col=cox_pcol, bg=cox_bg, pch=cox_pch)\n}\npar(mfrow=c(1,3), mar=c(0,0,0,2), oma=c(0,0,0,0), las=2)\nnulls &lt;- lapply(X=lgcp_sims, FUN=plot_lgcp)"
  },
  {
    "objectID": "w08/slides.html#ppp-objects",
    "href": "w08/slides.html#ppp-objects",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "ppp Objects",
    "text": "ppp Objects\n\nThe main datatype used to represent Planar Point Patterns [spatstat book p.¬†41]\nUnlike sf objects, which contain data+geometries for any desired collection of \\(N\\) entities, ppp objects are required to have at least an observation window!\n\n\n\nsf Creation:\n\n\nCode\ntree_df &lt;- tibble::tibble(lon=runif(100,0,1), lat=runif(100,0,1), age=runif(100,0,1))\ntree_sf &lt;- sf::st_as_sf(\n  tree_df,\n  coords = c('lon', 'lat')\n)\ntree_sf |&gt; head(4)\n\n\n\n\n\n\nage\ngeometry\n\n\n\n\n0.8593935\nPOINT (0.5035446 0.05519595)\n\n\n0.9770798\nPOINT (0.2606818 0.3874983)\n\n\n0.9517643\nPOINT (0.5464588 0.8271631)\n\n\n0.0592741\nPOINT (0.7999682 0.5852131)\n\n\n\n\n\n\n\nppp Creation:\n\n\nCode\npois_ppp &lt;- spatstat.random::rpoispp(\n  lambda=100, win=spatstat.geom::square(1)\n)\npois_ppp\n\n\nPlanar point pattern: 93 points\nwindow: rectangle = [0, 1] x [0, 1] units\n\n\nCode\nattributes(pois_ppp)$names\n\n\n[1] \"window\"     \"n\"          \"x\"          \"y\"          \"markformat\"\n\n\nCode\npois_ppp$x |&gt; head(4)\n\n\n[1] 0.51779807 0.62213583 0.84467836 0.05354204"
  },
  {
    "objectID": "w08/slides.html#ppp-leftrightarrow-sf-conversion",
    "href": "w08/slides.html#ppp-leftrightarrow-sf-conversion",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "ppp \\(\\leftrightarrow\\) sf Conversion",
    "text": "ppp \\(\\leftrightarrow\\) sf Conversion\n\n\nppp to sf Conversion:\n\n\nCode\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; head(4)\n\n\n\n\n\n\nlabel\ngeom\n\n\n\n\nwindow\nPOLYGON ((0 0, 1 0, 1 1, 0 ‚Ä¶\n\n\npoint\nPOINT (0.5177981 0.553718)\n\n\npoint\nPOINT (0.6221358 0.3933781)\n\n\npoint\nPOINT (0.8446784 0.8187611)\n\n\n\n\n\n\n\n\nCode\nlibrary(mdthemes) |&gt; suppressPackageStartupMessages()\npois_sf |&gt; ggplot() +\n  geom_sf(data=pois_sf |&gt; filter(label==\"window\"), aes(fill='grey')) +\n  geom_sf(data=pois_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'window'&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'point'&lt;/span&gt;\")) +\n  labs(title = \"&lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;sf&lt;/span&gt; Result\")\n\n\n\n\n\n\n\n\n\n\nsf to ppp Conversion:\n\n\nCode\nsquare_sfc &lt;- sf::st_polygon(list(\n  matrix(c(0,0,1,0,1,1,0,1,0,0), nrow=5, byrow=TRUE)\n)) |&gt; sf::st_sfc()\ntree_ppp &lt;- as.ppp(\n  sf::st_as_sfc(tree_sf),\n  W=as.owin(square_sfc)\n)\ntree_ppp\n\n\nPlanar point pattern: 100 points\nwindow: polygonal boundary\nenclosing rectangle: [0, 1] x [0, 1] units\n\n\n\n\nCode\ntree_ppp_sf &lt;- tree_ppp |&gt; sf::st_as_sf()\ntree_ppp_sf |&gt; ggplot() +\n  geom_sf(aes(fill='gray90')) +\n  geom_sf(data=tree_ppp_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp$window&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp${x,y}&lt;/span&gt;\")) +\n  labs(\n    title = \"&lt;span style='font-family: mono'&gt;sf&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; Result\",\n    x=\"&lt;span style='font-family: mono'&gt;tree_ppp$x&lt;/span&gt;\",\n    y=\"&lt;span style='font-family: mono'&gt;tree_ppp$y&lt;/span&gt;\"\n  ) + \n  guides(fill = guide_legend(order = 1), \n              color = guide_legend(order = 2))"
  },
  {
    "objectID": "w08/slides.html#references",
    "href": "w08/slides.html#references",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "References",
    "text": "References\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point Patterns: Methodology and Applications with R. CRC Press.\n\n\nCrates, Ross, Naomi Langmore, Louis Ranjard, Dejan Stojanovic, Laura Rayner, Dean Ingwersen, and Robert Heinsohn. 2021. ‚ÄúLoss of Vocal Culture and Fitness Costs in a Critically Endangered Songbird.‚Äù Proceedings of the Royal Society B: Biological Sciences 288 (1947): 20210225.\n\n\nMorinay, Jennifer, Louise Riotte-Lambert, Geert Aarts, Federico De Pascalis, Simona Imperio, Michelangelo Morganti, Carlo Catoni, et al. 2023. ‚ÄúWithin-Colony Segregation of Foraging Areas: From Patterns to Processes.‚Äù Oikos 2023 (8): e09926.\n\n\nSchabenberger, Oliver, and Carol A. Gotway. 2004. Statistical Methods for Spatial Data Analysis. CRC Press.\n\n\nWaller, Lance A., and Carol A. Gotway. 2004. Applied Spatial Statistics for Public Health Data. John Wiley & Sons."
  },
  {
    "objectID": "w08/index.html",
    "href": "w08/index.html",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#morans-i",
    "href": "w08/index.html#morans-i",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Moran‚Äôs \\(I\\)",
    "text": "Moran‚Äôs \\(I\\)\n\\[\nI =\n\\underset{\\text{Inverse of Variance}}{\\boxed{\\frac{n}{\\sum_{i=1}^{n}(y_i - \\overline{y})^2}}}\n\\frac\n  {\\overbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}(y_i - \\overline{y})(y_j - \\overline{y})}^{\\text{Weighted Covariance}}}\n  {\\underbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}}_{\\text{Normalize Weights}}}\n\\]\n\n\\(I\\) is Large when:\n\n\\(y_i\\) and \\(y_j\\) are neighbors: \\(w_{ij}\\), and\n\\(y_i\\) and \\(y_j\\) large at the same time: \\((y_i - \\overline{y})(y_j - \\overline{y})\\)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#local-indicators-of-spatial-autocorrelation-lisa",
    "href": "w08/index.html#local-indicators-of-spatial-autocorrelation-lisa",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Local Indicators of Spatial Autocorrelation (LISA)",
    "text": "Local Indicators of Spatial Autocorrelation (LISA)\n\ntldr: See how much a given location \\(\\mathbf{s}\\) contributes to overall Moran‚Äôs \\(I\\)\nLocal Moran‚Äôs \\(I\\):\n\n\\[\nI_i = \\frac{y_i - \\overline{y}}{S_i^2}\\sum_{j=1}^{n}w_{ij}(y_j - \\overline{y})\n\\]",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#or-non-human-nature-examples",
    "href": "w08/index.html#or-non-human-nature-examples",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "‚Ä¶Or, [Non-Human] Nature Examples",
    "text": "‚Ä¶Or, [Non-Human] Nature Examples\n\n\n\n\n\n\nNamibian ‚ÄúFairy Circles‚Äù; Smithsonian Magazine: Namibia‚Äôs mysterious fairy circles may be competition üëÄ between plants\n\n\n\n\n\nTermite mounds in Mozambique\n\n\n\n\n\n\n\nFree stock photo by @natalinadmay\n\n\n\n\n\n\n\nThree kestral (bird) colonies form a triangle straddling the Basilicata and Apulia regions of Italy; from Morinay et al. (2023)\n\n\n\n\n\nSpatial clustering of birdsongs; from Crates et al. (2021)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#but-a-challenge",
    "href": "w08/index.html#but-a-challenge",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "But, a Challenge‚Ä¶",
    "text": "But, a Challenge‚Ä¶\nTypically depends on context and/or level of resolution and/or level of analysis\n\n\n\nFrom Waller and Gotway (2004)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#why-na√Øve",
    "href": "w08/index.html#why-na√Øve",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Why ‚ÄúNa√Øve‚Äù?",
    "text": "Why ‚ÄúNa√Øve‚Äù?\n\nRegional data: easiest way to visualize / operationalize simple measures of clustering via spatial autocorrelation\nSo, we develop intuitions for measures like Moran‚Äôs \\(I\\) by looking at lattice data, but‚Ä¶\nNa√Øve because we‚Äôre not modeling the lattice regions (cells) themselves!\nNon-na√Øve clustering: Knowing the clusters but also what process led to their formation! Which brings us to‚Ä¶",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#spatial-randomness",
    "href": "w08/index.html#spatial-randomness",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Spatial Randomness",
    "text": "Spatial Randomness\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6805)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n#reg_sims &lt;- rMaternI(N, r=r_core, win=obs_window)\ncond_reg_sims &lt;- rSSI(r=r_core, N)\n# CSR data\n#csr_sims &lt;- rpoispp(N, win=obs_window)\ncond_sr_sims &lt;- rpoint(N, win=obs_window)\n### Clustered data\n#clust_sims &lt;- rMatClust(kappa=6, r=2.5*r_core, mu=10, win=obs_window)\n#clust_sims &lt;- rMatClust(mu=5, kappa=1, scale=0.1, win=obs_window, n.cond=N, w.cond=obs_window)\n#clust_sims &lt;- rclusterBKBC(clusters=\"MatClust\", kappa=10, mu=10, scale=0.05, verbose=FALSE)\n# Each cluster consist of 10 points in a disc of radius 0.2\nnclust &lt;- function(x0, y0, radius, n) {\n    #print(n)\n    return(runifdisc(10, radius, centre=c(x0, y0)))\n}\ncond_clust_sims &lt;- rNeymanScott(kappa=5, expand=0.0, rclust=nclust, radius=2*r_core, n=10)\n# And PLOT\nplot_w &lt;- 400\nplot_h &lt;- 400\nplot_scale &lt;- 2.25\ncond_reg_plot &lt;- cond_reg_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_reg.png\", cond_reg_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncond_sr_plot &lt;- cond_sr_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_sr.png\", cond_sr_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncond_clust_plot &lt;- cond_clust_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_clust.png\", cond_clust_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed \\(N\\)\n60\n\n60\n\n60\n\n\nProblem with fixed \\(N\\): Learning there are \\(n_1\\) points in region \\(R_1\\) \\(\\Rightarrow\\) there are \\(N - n_1\\) points outside \\(R_1\\)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#complete-spatial-randomness-csr",
    "href": "w08/index.html#complete-spatial-randomness-csr",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Complete Spatial Randomness (CSR)",
    "text": "Complete Spatial Randomness (CSR)\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6807)\nlambda &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n# Regularity via Inhibition\nreg_sims &lt;- rMaternI(lambda, r=r_core, win=obs_window)\n# CSR data\ncsr_sims &lt;- rpoispp(N, win=obs_window)\n### Clustered data\nclust_mu &lt;- 10\nclust_sims &lt;- rMatClust(kappa=lambda / clust_mu, scale=2*r_core, mu=10, win=obs_window)\n# And PLOT\nplot_w &lt;- 400\nplot_h &lt;- 400\nplot_scale &lt;- 2.25\nreg_plot &lt;- reg_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",reg_sims$n)) +\n  dsan_theme()\nggsave(\"images/reg.png\", reg_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncsr_plot &lt;- csr_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",csr_sims$n)) +\n  dsan_theme()\nggsave(\"images/csr.png\", csr_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\nclust_plot &lt;- clust_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",clust_sims$n)) +\n  dsan_theme()\nggsave(\"images/clust.png\", clust_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed Intensity \\(\\lambda\\)\n60\n\n60\n\n60\n\n\nRandom \\(N\\)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#caveat-1-measures-are-relative-to-window-of-observation",
    "href": "w08/index.html#caveat-1-measures-are-relative-to-window-of-observation",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Caveat 1: Measures are Relative to Window of Observation",
    "text": "Caveat 1: Measures are Relative to Window of Observation\nSame data can be spatially random within one window, clustered or regular in others!\n\n\nCode\nN &lt;- 60\nobs_window &lt;- square(1)\nwindow_scale &lt;- 3.5\ncsr_sims_square &lt;- rpoispp(N, win=obs_window)\n# Triangular window\nobs_window_tri &lt;- st_sfc(st_polygon(list(\n    matrix(c(0.3,0.1,0.7,0.1,0.5,0.5,0.3,0.1), byrow=TRUE, nrow=4)\n)))\nobs_window_geom &lt;- st_sfc(st_linestring(\n    matrix(c(0,0,1,0,1,1,0,1,0,0), byrow=TRUE, nrow=5)\n))\ncsr_sims_tri &lt;- ppp(csr_sims_square$x, csr_sims_square$y, window=as.owin(obs_window_tri))\ntri_plot &lt;- csr_sims_tri |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme(\"quarter\");\nggsave(\"images/window_tri.png\", tri_plot, width=plot_w, height=plot_h, units=\"px\", scale=window_scale)\n# Square window\nsquare_plot &lt;- csr_sims_square |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  geom_sf(data=obs_window_tri |&gt; sf::st_boundary()) +\n  dsan_theme(\"quarter\")\nggsave(\"images/window_square.png\", square_plot, width=plot_w, height=plot_h, units=\"px\", scale=window_scale)\n# Circular window\nobs_window_disc &lt;- st_sfc(st_point(c(1, 0.5))) |&gt; st_buffer(1.2)\ncsr_sims_circ &lt;- ppp(csr_sims_square$x, csr_sims_square$y, window=as.owin(obs_window_disc))\ncirc_plot &lt;- csr_sims_circ |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  geom_sf(data=obs_window_geom) +\n  dsan_theme(\"quarter\")\nggsave(\"images/window_circ.png\", circ_plot, width=plot_w, height=plot_h, units=\"px\", scale=window_scale)\n\n\n\n\n\n\n\n\n\n\nRegular\nCSR\nClustered",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#caveat-2-summary-statistics-like-i-are-not-models",
    "href": "w08/index.html#caveat-2-summary-statistics-like-i-are-not-models",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!",
    "text": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!\n\nMoran‚Äôs \\(I\\) is to GISers what a thermometer is to doctors\nMeasures symptoms; many possible underlying causes!\nNeed to ask why autocorrelation seems to be present!",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#why-do-events-appear-where-they-do",
    "href": "w08/index.html#why-do-events-appear-where-they-do",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "[] Why Do Events Appear Where They Do?",
    "text": "[] Why Do Events Appear Where They Do?\n\n\nCode\ncenter_l_function &lt;- function(x, ...) {\n  if (!spatstat.geom::is.ppp(x) && !spatstat.geom::is.fv(x)) {\n    stop(\"Please provide either ppp or fv object.\")\n  }\n  if (spatstat.geom::is.ppp(x)) {\n    x &lt;- spatstat.explore::Lest(x, ...)\n  }\n  r &lt;- x$r\n  l_centered &lt;- spatstat.explore::eval.fv(x - r)\n  return(l_centered)\n}\ncond_clust_sf &lt;- cond_clust_sims |&gt; sf::st_as_sf()\npines_plot &lt;- cond_clust_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic(base_size=12)\nggsave(\"images/pines.png\", pines_plot)\n# density() calls density.ppp() if the argument is a ppp object\nden &lt;- density(cond_clust_sims, sigma = 0.1)\n#summary(den)\npng(\"images/intensity_plot.png\")\nplot(den, main = \"Intensity Œª(s)\")\ncontour(den, add = TRUE) # contour plot\ndev.off()\n# And Gest / Kest / Lest\n# saveRDS(cond_clust_sims, \"cond_clust_sims.rds\")\npcf_result &lt;- spatstat.explore::pcf.ppp(\n  cond_clust_sims,\n  divisor=\"d\",\n  stoyan=0.25,\n  bw=0.05,\n  r=seq(from=0.0, to=1.0, by=0.001)\n)\npng(\"images/spatstat_pcf.png\")\nplot(pcf_result, xlim=c(0, 1), main=\"pcf\")\ndev.off()\n# kest_result &lt;- Kest(cond_clust_sims, rmax=0.5, correction=\"best\")\n# lest_result &lt;- center_l_function(cond_clust_sims, rmax=0.5)\n# png(\"images/lest.png\")\n# plot(lest_result, main=\"K(h)\")\n# dev.off()\n\n\n\n\n\n\n\n\n\n\n\nFirst-Order\nSecond-Order\n\n\n\n\n\nEvents considered individually \\(\\Rightarrow\\) Intensity function \\(\\lambda(\\mathbf{s})\\)\nEvents considered pairwise \\(\\Rightarrow\\) Pairwise Correlation Function \\(\\textrm{pcf}(\\vec{h})\\)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#the-tree-grid-mystery",
    "href": "w08/index.html#the-tree-grid-mystery",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "The Tree-Grid Mystery",
    "text": "The Tree-Grid Mystery\nYou‚Äôve been hired as an archaeologist ‚Äì congratulations! Your job: determine whether arrangement of trees formed:\n\nNaturally, via a process of resource competition, or\nArtificially, via an ancient civilization planting in a grid‚Ä¶",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#two-possible-histories",
    "href": "w08/index.html#two-possible-histories",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Two Possible Histories‚Ä¶",
    "text": "Two Possible Histories‚Ä¶\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Art}}\\): Artificial Formation\n\n\n\n\n\nCode (Step 1: Grid Creation)\nha_base &lt;- 28\nsquare_sf &lt;- sf::st_as_sf(spatstat.geom::square(1))\ngrid_sf &lt;- sf::st_as_sf(sf::st_make_grid(square_sf))\ngrid_buffer_sf &lt;- grid_sf |&gt; sf::st_buffer(dist=-0.01, singleSide = TRUE)\ngrid_buffer_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Point Generation)\ngrid_points &lt;- sf::st_sample(grid_buffer_sf, size=rep(1,100))\ngrid_buffer_sf |&gt; ggplot(aes(shape='Cell')) +\n  geom_sf() +\n  geom_sf(data=grid_points) +\n  scale_shape_manual(\"Shape\", values=c('Cell'=19)) +\n  theme_classic(base_size=ha_base) +\n  theme(\n    legend.title = element_blank(),\n    # legend.text = element_text(size=18)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\ngrid_ppp &lt;- as.ppp(grid_points, W=spatstat.geom::square(1))\ngrid_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Nat}}\\): Natural Formation\n\n\n\n\n\nCode (Step 1: Tree Generation)\nhn_base &lt;- 28\nr &lt;- 0.05\npois_ppp &lt;- rpoispp(150)\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Competition)\nage &lt;- runif(npoints(pois_ppp))\npair_dists &lt;- pairdist(pois_ppp)\nclose &lt;- (pair_dists &lt; r)\nlater &lt;- outer(age, age, \"&gt;\")\nkilled &lt;- apply(close & later, 1, any)\nkilled_ppp &lt;- pois_ppp[killed]\nalive_ppp &lt;- pois_ppp[!killed]\npois_window_sf &lt;- pois_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"window\")\npois_killed_sf &lt;- killed_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\npois_alive_sf &lt;- alive_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\nalive_buff_sf &lt;- pois_alive_sf |&gt; sf::st_buffer(r) |&gt; sf::st_union() |&gt; sf::st_intersection(pois_window_sf)\nggplot() +\n  geom_sf(data=pois_window_sf) +\n  geom_sf(data=alive_buff_sf, aes(color='Inhibition', shape='Inhibition'), linetype='dashed') +\n  geom_sf(data=pois_killed_sf, aes(color='Dead', shape='Dead'), size=2, stroke=2) +\n  geom_sf(data=pois_alive_sf, aes(color='Alive', shape='Alive'), size=1, stroke=1) +\n  scale_shape_manual(name=NULL, values=c(\"Alive\"=19, \"Dead\"=4, 'Inhibition'=21), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  scale_color_manual(name=NULL, values=c(\"Alive\"=\"black\", \"Dead\"=cb_palette[1], \"Inhibition\"=\"black\"), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  guides(shape=guide_legend(override.aes=list(fill = \"white\"))) +\n  theme_classic(base_size = hn_base) +\n  theme(plot.margin = unit(c(0,0,0,0), \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\nalive_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#why-do-events-appear-where-they-do-1",
    "href": "w08/index.html#why-do-events-appear-where-they-do-1",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Why Do Events Appear Where They Do?",
    "text": "Why Do Events Appear Where They Do?\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6809)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n### Clustered data\nclust_ppp &lt;- rMatClust(\n  kappa=6,\n  scale=r_core,\n  mu=10\n)\nclust_sf &lt;- clust_ppp |&gt; sf::st_as_sf()\nclust_plot &lt;- clust_sf |&gt;\n  ggplot() +\n  geom_sf(size=2) +\n  theme_classic(base_size=18)\nggsave(\"images/clust_ppp.png\", clust_plot, width=3, height=3)\n# Intensity fn\nclust_intensity &lt;- density(clust_ppp, sigma = 0.1)\npng(\"images/clust_intensity.png\")\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,0,0), cex=2)\nplot(clust_intensity, main=NULL)\ncontour(clust_intensity, add = TRUE)\ndev.off()\n### PCF\nclust_pcf &lt;- spatstat.explore::pcf(\n  clust_ppp, divisor=\"d\",\n  r=seq(from=0.00, to=0.50, by=0.01)\n)\nclust_pcf_plot &lt;- clust_pcf |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  labs(x=\"Distance\", y=\"Density\") +\n  theme_classic(base_size=14)\nggsave(\"images/clust_pcf.png\", clust_pcf_plot, width=3, height=3)\n\n\n\n\n\n\n\n\n\n\nOriginal Data\nFirst-Order\nSecond-Order\n\n\n\n\n\\(N = 60\\) Events\nEvents modeled individually\\(\\Rightarrow\\) Intensity Function \\(\\lambda(\\mathbf{s})\\)\nEvents modeled pairwise \\(\\Rightarrow\\) Pairwise-Corr Function \\(\\textrm{pcf}(\\vec{h})\\)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#what-do-these-functions-detect",
    "href": "w08/index.html#what-do-these-functions-detect",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "What Do These Functions ‚ÄúDetect‚Äù?",
    "text": "What Do These Functions ‚ÄúDetect‚Äù?\n\n\n\n\nCode (Fixed Points)\nsq_base &lt;- 16\nsq_psize &lt;- 2.5\nobs_window &lt;- square(1)\nr0 &lt;- 0.2\nsq_df &lt;- tibble::tribble(\n  ~x, ~y,\n  0.5-r0,0.5-r0,\n  0.5+r0,0.5+r0,\n  0.5-r0,0.5+r0,\n  0.5+r0,0.5-r0\n)\nsq_sf &lt;- sf::st_as_sf(\n  sq_df,\n  coords = c(\"x\",\"y\")\n)\nsq_ppp &lt;- as.ppp(sq_sf, W=obs_window)\nsq_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,1,0))\nsq_density &lt;- density(sq_ppp)\nplot(sq_density, main=NULL, xaxs='i', yaxs='i')\ncontour(sq_density, xaxs='i', yaxs='i', add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### PCF\npcf_result &lt;- spatstat.explore::pcf(\n  sq_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\npcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode (CSR Points)\ncsr_ppp &lt;- spatstat.random::rpoispp(\n  lambda = 60,\n  win=obs_window\n)\ncsr_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(\n  mar=c(0,0,0,2),\n  las=2,\n  oma=c(0,0,1,0)\n)\ncsr_density &lt;- density(csr_ppp)\nplot(csr_density, main=NULL, xaxs=\"i\", yaxs=\"i\")\ncontour(csr_density, xaxs=\"i\", yaxs=\"i\", add = TRUE, lwd=1.5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_pcf_result &lt;- spatstat.explore::pcf(\n  csr_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\ncsr_pcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#poisson-point-processes-csr",
    "href": "w08/index.html#poisson-point-processes-csr",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Poisson Point Processes (CSR)",
    "text": "Poisson Point Processes (CSR)\nspatstat.random::rpoispp(lambda, win)\n\n \\(N \\sim \\text{Pois}(\\lambda)\\)\n For \\(i \\in \\{1, \\ldots, N\\}\\):\n\nGenerate \\(X_i, Y_i \\sim \\mathcal{U}(\\texttt{win})\\)\n\n\n\n\nCode\nsim_base &lt;- 22\nsim_psize &lt;- 2\nsim_xticks &lt;- seq(from=0.0, to=1.0, by=0.2)\nsim_yticks &lt;- seq(from=0.0, to=1.0, by=0.2)\ngen_pois_df &lt;- function(num_sims=1) {\n  pois_sims &lt;- spatstat.random::rpoispp(\n    lambda = 60, nsim=num_sims\n  )\n  return(tibble::as_tibble(pois_sims))\n}\n#pois_dfs &lt;- gen_pois_df()\n#pois_dfs |&gt; head()\npois_sims &lt;- spatstat.random::rpoispp(\n  lambda = 60, nsim=3\n)\nto_sim_df &lt;- function(cur_sim, sim_name) {\n  cur_df &lt;- tibble::as_tibble(cur_sim) |&gt; mutate(sim=sim_name)\n  return(cur_df)\n}\ncombined_df &lt;- imap(.x=pois_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#simple-sequential-inhibition-ssi",
    "href": "w08/index.html#simple-sequential-inhibition-ssi",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Simple Sequential Inhibition (SSI)",
    "text": "Simple Sequential Inhibition (SSI)\nspatstat.random::rSSI(r, n=Inf, giveup=1000, win)\n\n\\(\\mathbf{S} = \\varnothing\\)\nWhile not done:\n\n Generate \\(\\mathbf{E} = (X, Y) \\sim \\mathcal{U}(\\texttt{win})\\)\n Check if \\(\\mathbf{E}\\) within r units of any existing point in \\(\\mathbf{S}\\)\n\nIf it is, throw \\(\\mathbf{E}\\) away. Otherwise, add \\(\\mathbf{E}\\) to \\(\\mathbf{S}\\)\n\n done=TRUE if \\(\\mathbf{S}\\) has n points OR has been the same for giveup steps\n\n\n\n\nCode\ncapture.output(ssi_sims &lt;- spatstat.random::rSSI(\n  r = 0.05, n=60, nsim=3\n), file=nullfile())\ncombined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=24) +\n  theme(panel.spacing.x = unit(3, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#mat√©rn-cluster-process",
    "href": "w08/index.html#mat√©rn-cluster-process",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Mat√©rn Cluster Process",
    "text": "Mat√©rn Cluster Process\n\n\nspatstat.random::rMatClust(kappa, scale, mu, win)\n\nDocs\n\n\n\n Generate \\(K(\\kappa)\\) parent points via Poisson Point Process with intensity \\(\\lambda = \\kappa\\)\n For each parent point \\(\\mathbf{s}_i \\in \\left\\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{K(\\kappa)}\\right\\}\\):\n\nGenerate \\(N(\\mu)\\) offspring points via Poisson Point Process with intensity \\(\\lambda = \\mu\\), distributed uniformly within a circle of radius scale centered at \\(\\mathbf{s}_i\\)\n\n Offspring points form the outcome (parent points are thrown away)\n\n\n\nCode\nmatclust_sims &lt;- rMatClust(\n  kappa = 6,\n  scale = 0.075,\n  mu = 10,\n  nsim = 3\n)\nmatclust_df &lt;- imap(.x=matclust_sims, .f=to_sim_df) |&gt; bind_rows()\nmatclust_plot &lt;- matclust_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nmatclust_plot",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#mat√©rn-inhibition-process-i-and-ii",
    "href": "w08/index.html#mat√©rn-inhibition-process-i-and-ii",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Mat√©rn Inhibition Process (I and II)",
    "text": "Mat√©rn Inhibition Process (I and II)\nspatstat.random::rMaternI(kappa, r, win)\nspatstat.random::rMaternII(kappa, r, win)\n\n\n\n\n\n\n\nrMaternI() [Docs]\nrMaternII() [Docs]\n\n\n\n\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\)\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\), plus timestamp \\(t_i \\sim \\mathcal{U}(0,1)\\) for each \\(\\mathbf{s}_i\\)\n\n\n\n\n Delete all pairs of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\) for which \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\)\n\n\n For each pair of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\): if \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\), delete the later point\n\n\n\n\n\n\nCode\nmI_sims &lt;- rMaternI(\n  kappa = 60, r = 0.075, nsim=2\n)\nmII_sims &lt;- rMaternII(\n  kappa = 60, r = 0.075, nsim=2\n)\nmI_combined_df &lt;- imap(.x=mI_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MI \",sim))\nmII_combined_df &lt;- imap(.x=mII_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MII \",sim))\nm_combined_df &lt;- bind_rows(mI_combined_df, mII_combined_df)\nm_plot &lt;- m_combined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nm_plot",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#cox-processes-random-intensity-random-events",
    "href": "w08/index.html#cox-processes-random-intensity-random-events",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "Cox Processes: Random Intensity ‚Üí Random Events",
    "text": "Cox Processes: Random Intensity ‚Üí Random Events\n\n\nspatstat.random::rLGCP(model, mu, param, win)\nmodels=c(\"exponential\", \"gauss\", \"stable\", \"gencauchy\", \"matern\")\n\nDocs\n\n\n\n\nCode\ncox_pcol &lt;- \"black\"\ncox_bg &lt;- \"grey90\"\ncox_pch &lt;- 21\n# inhomogeneous LGCP with Gaussian covariance function\nm &lt;- as.im(function(x, y){\n  5 - 1.5 * (x - 0.5)^2 + 2 * (y - 0.5)^2\n}, W=owin())\nlgcp_sims &lt;- rLGCP(\"gauss\", m, var=0.15, scale =0.5, nsim=3)\n\n\nWarning: 32750 out of 65536 terms (50%) in FFT calculation of matrix square\nroot were negative, and were set to zero. Range: [-2.96, 1910]\n\n\nCode\n# lgcp_combined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\nplot_lgcp &lt;- function(lgcp_sim) {\n  plot(attr(lgcp_sim, \"Lambda\"), main=NULL)\n  points(lgcp_sim, col=cox_pcol, bg=cox_bg, pch=cox_pch)\n}\npar(mfrow=c(1,3), mar=c(0,0,0,2), oma=c(0,0,0,0), las=2)\nnulls &lt;- lapply(X=lgcp_sims, FUN=plot_lgcp)",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#ppp-objects",
    "href": "w08/index.html#ppp-objects",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "ppp Objects",
    "text": "ppp Objects\n\nThe main datatype used to represent Planar Point Patterns [spatstat book p.¬†41]\nUnlike sf objects, which contain data+geometries for any desired collection of \\(N\\) entities, ppp objects are required to have at least an observation window!\n\n\n\nsf Creation:\n\n\nCode\ntree_df &lt;- tibble::tibble(lon=runif(100,0,1), lat=runif(100,0,1), age=runif(100,0,1))\ntree_sf &lt;- sf::st_as_sf(\n  tree_df,\n  coords = c('lon', 'lat')\n)\ntree_sf |&gt; head(4)\n\n\n\n\n\n\nage\ngeometry\n\n\n\n\n0.8593935\nPOINT (0.5035446 0.05519595)\n\n\n0.9770798\nPOINT (0.2606818 0.3874983)\n\n\n0.9517643\nPOINT (0.5464588 0.8271631)\n\n\n0.0592741\nPOINT (0.7999682 0.5852131)\n\n\n\n\n\n\n\nppp Creation:\n\n\nCode\npois_ppp &lt;- spatstat.random::rpoispp(\n  lambda=100, win=spatstat.geom::square(1)\n)\npois_ppp\n\n\nPlanar point pattern: 93 points\nwindow: rectangle = [0, 1] x [0, 1] units\n\n\nCode\nattributes(pois_ppp)$names\n\n\n[1] \"window\"     \"n\"          \"x\"          \"y\"          \"markformat\"\n\n\nCode\npois_ppp$x |&gt; head(4)\n\n\n[1] 0.51779807 0.62213583 0.84467836 0.05354204",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#ppp-leftrightarrow-sf-conversion",
    "href": "w08/index.html#ppp-leftrightarrow-sf-conversion",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "ppp \\(\\leftrightarrow\\) sf Conversion",
    "text": "ppp \\(\\leftrightarrow\\) sf Conversion\n\n\nppp to sf Conversion:\n\n\nCode\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; head(4)\n\n\n\n\n\n\nlabel\ngeom\n\n\n\n\nwindow\nPOLYGON ((0 0, 1 0, 1 1, 0 ‚Ä¶\n\n\npoint\nPOINT (0.5177981 0.553718)\n\n\npoint\nPOINT (0.6221358 0.3933781)\n\n\npoint\nPOINT (0.8446784 0.8187611)\n\n\n\n\n\n\n\n\nCode\nlibrary(mdthemes) |&gt; suppressPackageStartupMessages()\npois_sf |&gt; ggplot() +\n  geom_sf(data=pois_sf |&gt; filter(label==\"window\"), aes(fill='grey')) +\n  geom_sf(data=pois_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'window'&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'point'&lt;/span&gt;\")) +\n  labs(title = \"&lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;sf&lt;/span&gt; Result\")\n\n\n\n\n\n\n\n\n\n\nsf to ppp Conversion:\n\n\nCode\nsquare_sfc &lt;- sf::st_polygon(list(\n  matrix(c(0,0,1,0,1,1,0,1,0,0), nrow=5, byrow=TRUE)\n)) |&gt; sf::st_sfc()\ntree_ppp &lt;- as.ppp(\n  sf::st_as_sfc(tree_sf),\n  W=as.owin(square_sfc)\n)\ntree_ppp\n\n\nPlanar point pattern: 100 points\nwindow: polygonal boundary\nenclosing rectangle: [0, 1] x [0, 1] units\n\n\n\n\nCode\ntree_ppp_sf &lt;- tree_ppp |&gt; sf::st_as_sf()\ntree_ppp_sf |&gt; ggplot() +\n  geom_sf(aes(fill='gray90')) +\n  geom_sf(data=tree_ppp_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp$window&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp${x,y}&lt;/span&gt;\")) +\n  labs(\n    title = \"&lt;span style='font-family: mono'&gt;sf&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; Result\",\n    x=\"&lt;span style='font-family: mono'&gt;tree_ppp$x&lt;/span&gt;\",\n    y=\"&lt;span style='font-family: mono'&gt;tree_ppp$y&lt;/span&gt;\"\n  ) + \n  guides(fill = guide_legend(order = 1), \n              color = guide_legend(order = 2))",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w08/index.html#references",
    "href": "w08/index.html#references",
    "title": "Week 8: Point Processes: Null Models, Clustering, and Regularity",
    "section": "References",
    "text": "References\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point Patterns: Methodology and Applications with R. CRC Press.\n\n\nCrates, Ross, Naomi Langmore, Louis Ranjard, Dejan Stojanovic, Laura Rayner, Dean Ingwersen, and Robert Heinsohn. 2021. ‚ÄúLoss of Vocal Culture and Fitness Costs in a Critically Endangered Songbird.‚Äù Proceedings of the Royal Society B: Biological Sciences 288 (1947): 20210225.\n\n\nMorinay, Jennifer, Louise Riotte-Lambert, Geert Aarts, Federico De Pascalis, Simona Imperio, Michelangelo Morganti, Carlo Catoni, et al. 2023. ‚ÄúWithin-Colony Segregation of Foraging Areas: From Patterns to Processes.‚Äù Oikos 2023 (8): e09926.\n\n\nSchabenberger, Oliver, and Carol A. Gotway. 2004. Statistical Methods for Spatial Data Analysis. CRC Press.\n\n\nWaller, Lance A., and Carol A. Gotway. 2004. Applied Spatial Statistics for Public Health Data. John Wiley & Sons.",
    "crumbs": [
      "Week 8: Oct 15"
    ]
  },
  {
    "objectID": "w09/slides.html#caveat-2-summary-statistics-like-i-are-not-models",
    "href": "w09/slides.html#caveat-2-summary-statistics-like-i-are-not-models",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!",
    "text": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!\n\nMoran‚Äôs \\(I\\) is to GISers what a thermometer is to doctors\nMeasures symptoms; many possible underlying causes!\nNeed to ask why autocorrelation seems to be present!"
  },
  {
    "objectID": "w09/slides.html#why-do-events-appear-where-they-do",
    "href": "w09/slides.html#why-do-events-appear-where-they-do",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "[] Why Do Events Appear Where They Do?",
    "text": "[] Why Do Events Appear Where They Do?\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6806)\nN &lt;- 60\nlambda &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n# Regularity via Inhibition\nreg_sims &lt;- rMaternI(lambda, r=r_core, win=obs_window)\n# CSR data\ncsr_sims &lt;- rpoispp(N, win=obs_window)\n### Clustered data\nclust_mu &lt;- 10\nclust_sims &lt;- rMatClust(kappa=lambda / clust_mu, scale=2*r_core, mu=10, win=obs_window)\n# Each cluster consist of 10 points in a disc of radius 0.2\nnclust &lt;- function(x0, y0, radius, n) {\n    #print(n)\n    return(runifdisc(10, radius, centre=c(x0, y0)))\n}\ncond_clust_sims &lt;- rNeymanScott(kappa=5, expand=0.0, rclust=nclust, radius=2*r_core, n=10)\ncond_clust_sf &lt;- cond_clust_sims |&gt; sf::st_as_sf()\npines_plot &lt;- cond_clust_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic(base_size=12)\nggsave(\"images/pines.png\", pines_plot)\n# density() calls density.ppp() if the argument is a ppp object\nden &lt;- density(cond_clust_sims, sigma = 0.1)\n#summary(den)\npng(\"images/intensity_plot.png\")\nplot(den, main = \"Intensity Œª(s)\")\ncontour(den, add = TRUE) # contour plot\ndev.off()\n# And Gest / Kest / Lest\n# saveRDS(cond_clust_sims, \"cond_clust_sims.rds\")\npcf_result &lt;- spatstat.explore::pcf.ppp(\n  cond_clust_sims,\n  divisor=\"d\",\n  stoyan=0.25,\n  bw=0.05,\n  r=seq(from=0.0, to=1.0, by=0.001)\n)\npng(\"images/spatstat_pcf.png\")\nplot(pcf_result, xlim=c(0, 1), main=\"pcf\")\ndev.off()\n# kest_result &lt;- Kest(cond_clust_sims, rmax=0.5, correction=\"best\")\n# lest_result &lt;- center_l_function(cond_clust_sims, rmax=0.5)\n# png(\"images/lest.png\")\n# plot(lest_result, main=\"K(h)\")\n# dev.off()\n\n\n\n\n\n\n\n\n\n\n\nFirst-Order\nSecond-Order\n\n\n\n\n\nEvents considered individually \\(\\Rightarrow\\) Intensity function \\(\\lambda(\\mathbf{s})\\)\nEvents considered pairwise \\(\\Rightarrow\\) Pairwise Correlation Function \\(\\textrm{pcf}(\\vec{h})\\)"
  },
  {
    "objectID": "w09/slides.html#the-tree-grid-mystery",
    "href": "w09/slides.html#the-tree-grid-mystery",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "The Tree-Grid Mystery",
    "text": "The Tree-Grid Mystery\nYou‚Äôve been hired as an archaeologist ‚Äì congratulations! Your job: determine whether arrangement of trees formed:\n\nNaturally, via a process of resource competition, or\nArtificially, via an ancient civilization planting in a grid‚Ä¶"
  },
  {
    "objectID": "w09/slides.html#two-possible-histories",
    "href": "w09/slides.html#two-possible-histories",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Two Possible Histories‚Ä¶",
    "text": "Two Possible Histories‚Ä¶\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Art}}\\): Artificial Formation\n\n\n\n\n\nCode (Step 1: Grid Creation)\nha_base &lt;- 28\nsquare_sf &lt;- sf::st_as_sf(spatstat.geom::square(1))\ngrid_sf &lt;- sf::st_as_sf(sf::st_make_grid(square_sf))\ngrid_buffer_sf &lt;- grid_sf |&gt; sf::st_buffer(dist=-0.01, singleSide = TRUE)\ngrid_buffer_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Point Generation)\ngrid_points &lt;- sf::st_sample(grid_buffer_sf, size=rep(1,100))\ngrid_buffer_sf |&gt; ggplot(aes(shape='Cell')) +\n  geom_sf() +\n  geom_sf(data=grid_points) +\n  scale_shape_manual(\"Shape\", values=c('Cell'=19)) +\n  theme_classic(base_size=ha_base) +\n  theme(\n    legend.title = element_blank(),\n    # legend.text = element_text(size=18)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\ngrid_ppp &lt;- as.ppp(grid_points, W=spatstat.geom::square(1))\ngrid_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Nat}}\\): Natural Formation\n\n\n\n\n\nCode (Step 1: Tree Generation)\nhn_base &lt;- 28\nr &lt;- 0.05\npois_ppp &lt;- rpoispp(150)\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Competition)\nage &lt;- runif(npoints(pois_ppp))\npair_dists &lt;- pairdist(pois_ppp)\nclose &lt;- (pair_dists &lt; r)\nlater &lt;- outer(age, age, \"&gt;\")\nkilled &lt;- apply(close & later, 1, any)\nkilled_ppp &lt;- pois_ppp[killed]\nalive_ppp &lt;- pois_ppp[!killed]\npois_window_sf &lt;- pois_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"window\")\npois_killed_sf &lt;- killed_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\npois_alive_sf &lt;- alive_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\nalive_buff_sf &lt;- pois_alive_sf |&gt; sf::st_buffer(r) |&gt; sf::st_union() |&gt; sf::st_intersection(pois_window_sf)\nggplot() +\n  geom_sf(data=pois_window_sf) +\n  geom_sf(data=alive_buff_sf, aes(color='Inhibition', shape='Inhibition'), linetype='dashed') +\n  geom_sf(data=pois_killed_sf, aes(color='Dead', shape='Dead'), size=2, stroke=2) +\n  geom_sf(data=pois_alive_sf, aes(color='Alive', shape='Alive'), size=1, stroke=1) +\n  scale_shape_manual(name=NULL, values=c(\"Alive\"=19, \"Dead\"=4, 'Inhibition'=21), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  scale_color_manual(name=NULL, values=c(\"Alive\"=\"black\", \"Dead\"=cb_palette[1], \"Inhibition\"=\"black\"), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  guides(shape=guide_legend(override.aes=list(fill = \"white\"))) +\n  theme_classic(base_size = hn_base) +\n  theme(plot.margin = unit(c(0,0,0,0), \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\nalive_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)"
  },
  {
    "objectID": "w09/slides.html#why-do-events-appear-where-they-do-1",
    "href": "w09/slides.html#why-do-events-appear-where-they-do-1",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Why Do Events Appear Where They Do?",
    "text": "Why Do Events Appear Where They Do?\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6809)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n### Clustered data\nclust_ppp &lt;- rMatClust(\n  kappa=6,\n  scale=r_core,\n  mu=10\n)\nclust_sf &lt;- clust_ppp |&gt; sf::st_as_sf()\nclust_plot &lt;- clust_sf |&gt;\n  ggplot() +\n  geom_sf(size=2) +\n  theme_classic(base_size=18)\nggsave(\"images/clust_ppp.png\", clust_plot, width=3, height=3)\n# Intensity fn\nclust_intensity &lt;- density(clust_ppp, sigma = 0.1)\npng(\"images/clust_intensity.png\")\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,0,0), cex=2)\nplot(clust_intensity, main=NULL)\ncontour(clust_intensity, add = TRUE)\ndev.off()\n### PCF\nclust_pcf &lt;- spatstat.explore::pcf(\n  clust_ppp, divisor=\"d\",\n  r=seq(from=0.00, to=0.50, by=0.01)\n)\nclust_pcf_plot &lt;- clust_pcf |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  labs(x=\"Distance\", y=\"Density\") +\n  theme_classic(base_size=14)\nggsave(\"images/clust_pcf.png\", clust_pcf_plot, width=3, height=3)\n\n\n\n\n\n\n\n\n\n\nOriginal Data\nFirst-Order\nSecond-Order\n\n\n\n\n\\(N = 60\\) Events\nEvents modeled individually\\(\\Rightarrow\\) Intensity Function \\(\\lambda(\\mathbf{s})\\)\nEvents modeled pairwise \\(\\Rightarrow\\) Pairwise-Corr Function \\(\\textrm{pcf}(\\vec{h})\\)"
  },
  {
    "objectID": "w09/slides.html#what-do-these-functions-detect",
    "href": "w09/slides.html#what-do-these-functions-detect",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "What Do These Functions ‚ÄúDetect‚Äù?",
    "text": "What Do These Functions ‚ÄúDetect‚Äù?\n\n\n\n\nCode (Fixed Points)\nsq_base &lt;- 16\nsq_psize &lt;- 2.5\nobs_window &lt;- square(1)\nr0 &lt;- 0.2\nsq_df &lt;- tibble::tribble(\n  ~x, ~y,\n  0.5-r0,0.5-r0,\n  0.5+r0,0.5+r0,\n  0.5-r0,0.5+r0,\n  0.5+r0,0.5-r0\n)\nsq_sf &lt;- sf::st_as_sf(\n  sq_df,\n  coords = c(\"x\",\"y\")\n)\nsq_ppp &lt;- as.ppp(sq_sf, W=obs_window)\nsq_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,1,0))\nsq_density &lt;- density(sq_ppp)\nplot(sq_density, main=NULL, xaxs='i', yaxs='i')\ncontour(sq_density, xaxs='i', yaxs='i', add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### PCF\npcf_result &lt;- spatstat.explore::pcf(\n  sq_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\npcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode (CSR Points)\ncsr_ppp &lt;- spatstat.random::rpoispp(\n  lambda = 60,\n  win=obs_window\n)\ncsr_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(\n  mar=c(0,0,0,2),\n  las=2,\n  oma=c(0,0,1,0)\n)\ncsr_density &lt;- density(csr_ppp)\nplot(csr_density, main=NULL, xaxs=\"i\", yaxs=\"i\")\ncontour(csr_density, xaxs=\"i\", yaxs=\"i\", add = TRUE, lwd=1.5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_pcf_result &lt;- spatstat.explore::pcf(\n  csr_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\ncsr_pcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)"
  },
  {
    "objectID": "w09/slides.html#poisson-point-processes-csr",
    "href": "w09/slides.html#poisson-point-processes-csr",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Poisson Point Processes (CSR)",
    "text": "Poisson Point Processes (CSR)\nspatstat.random::rpoispp(lambda, win)\n\n \\(N \\sim \\text{Pois}(\\lambda)\\)\n For \\(i \\in \\{1, \\ldots, N\\}\\):\n\nGenerate \\(X_i, Y_i \\sim \\mathcal{U}(\\texttt{win})\\)\n\n\n\n\nCode\nsim_base &lt;- 22\nsim_psize &lt;- 2\nsim_xticks &lt;- seq(from=0.0, to=1.0, by=0.2)\nsim_yticks &lt;- seq(from=0.0, to=1.0, by=0.2)\ngen_pois_df &lt;- function(num_sims=1) {\n  pois_sims &lt;- spatstat.random::rpoispp(\n    lambda = 60, nsim=num_sims\n  )\n  return(tibble::as_tibble(pois_sims))\n}\n#pois_dfs &lt;- gen_pois_df()\n#pois_dfs |&gt; head()\npois_sims &lt;- spatstat.random::rpoispp(\n  lambda = 60, nsim=3\n)\nto_sim_df &lt;- function(cur_sim, sim_name) {\n  cur_df &lt;- tibble::as_tibble(cur_sim) |&gt; mutate(sim=sim_name)\n  return(cur_df)\n}\ncombined_df &lt;- imap(.x=pois_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)"
  },
  {
    "objectID": "w09/slides.html#simple-sequential-inhibition-ssi",
    "href": "w09/slides.html#simple-sequential-inhibition-ssi",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Simple Sequential Inhibition (SSI)",
    "text": "Simple Sequential Inhibition (SSI)\nspatstat.random::rSSI(r, n=Inf, giveup=1000, win)\n\n\\(\\mathbf{S} = \\varnothing\\)\nWhile not done:\n\n Generate \\(\\mathbf{E} = (X, Y) \\sim \\mathcal{U}(\\texttt{win})\\)\n Check if \\(\\mathbf{E}\\) within r units of any existing point in \\(\\mathbf{S}\\)\n\nIf it is, throw \\(\\mathbf{E}\\) away. Otherwise, add \\(\\mathbf{E}\\) to \\(\\mathbf{S}\\)\n\n done=TRUE if \\(\\mathbf{S}\\) has n points OR has been the same for giveup steps\n\n\n\n\nCode\ncapture.output(ssi_sims &lt;- spatstat.random::rSSI(\n  r = 0.05, n=60, nsim=3\n), file=nullfile())\ncombined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=24) +\n  theme(panel.spacing.x = unit(3, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)"
  },
  {
    "objectID": "w09/slides.html#mat√©rn-cluster-process",
    "href": "w09/slides.html#mat√©rn-cluster-process",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Mat√©rn Cluster Process",
    "text": "Mat√©rn Cluster Process\n\n\nspatstat.random::rMatClust(kappa, scale, mu, win)\n\nDocs\n\n\n Generate \\(K(\\kappa)\\) parent points via Poisson Point Process with intensity \\(\\lambda = \\kappa\\)\n For each parent point \\(\\mathbf{s}_i \\in \\left\\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{K(\\kappa)}\\right\\}\\):\n\nGenerate \\(N(\\mu)\\) offspring points via Poisson Point Process with intensity \\(\\lambda = \\mu\\), distributed uniformly within a circle of radius scale centered at \\(\\mathbf{s}_i\\)\n\n Offspring points form the outcome (parent points are thrown away)\n\n\n\nCode\nmatclust_sims &lt;- rMatClust(\n  kappa = 6,\n  scale = 0.075,\n  mu = 10,\n  nsim = 3\n)\nmatclust_df &lt;- imap(.x=matclust_sims, .f=to_sim_df) |&gt; bind_rows()\nmatclust_plot &lt;- matclust_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nmatclust_plot"
  },
  {
    "objectID": "w09/slides.html#mat√©rn-inhibition-process-i-and-ii",
    "href": "w09/slides.html#mat√©rn-inhibition-process-i-and-ii",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Mat√©rn Inhibition Process (I and II)",
    "text": "Mat√©rn Inhibition Process (I and II)\nspatstat.random::rMaternI(kappa, r, win)\nspatstat.random::rMaternII(kappa, r, win)\n\n\n\n\n\n\n\nrMaternI() [Docs]\nrMaternII() [Docs]\n\n\n\n\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\)\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\), plus timestamp \\(t_i \\sim \\mathcal{U}(0,1)\\) for each \\(\\mathbf{s}_i\\)\n\n\n\n\n Delete all pairs of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\) for which \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\)\n\n\n For each pair of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\): if \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\), delete the later point\n\n\n\n\n\n\nCode\nmI_sims &lt;- rMaternI(\n  kappa = 60, r = 0.075, nsim=2\n)\nmII_sims &lt;- rMaternII(\n  kappa = 60, r = 0.075, nsim=2\n)\nmI_combined_df &lt;- imap(.x=mI_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MI \",sim))\nmII_combined_df &lt;- imap(.x=mII_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MII \",sim))\nm_combined_df &lt;- bind_rows(mI_combined_df, mII_combined_df)\nm_plot &lt;- m_combined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nm_plot"
  },
  {
    "objectID": "w09/slides.html#cox-processes-random-intensity-random-events",
    "href": "w09/slides.html#cox-processes-random-intensity-random-events",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Cox Processes: Random Intensity ‚Üí Random Events",
    "text": "Cox Processes: Random Intensity ‚Üí Random Events\n\n\nspatstat.random::rLGCP(model, mu, param, win)\nmodels=c(\"exponential\", \"gauss\", \"stable\", \"gencauchy\", \"matern\")\n\nDocs\n\n\n\nCode\ncox_pcol &lt;- \"black\"\ncox_bg &lt;- \"grey90\"\ncox_pch &lt;- 21\n# inhomogeneous LGCP with Gaussian covariance function\nm &lt;- as.im(function(x, y){\n  5 - 1.5 * (x - 0.5)^2 + 2 * (y - 0.5)^2\n}, W=owin())\nlgcp_sims &lt;- rLGCP(\"gauss\", m, var=0.15, scale =0.5, nsim=3)\n# lgcp_combined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\nplot_lgcp &lt;- function(lgcp_sim) {\n  plot(attr(lgcp_sim, \"Lambda\"), main=NULL)\n  points(lgcp_sim, col=cox_pcol, bg=cox_bg, pch=cox_pch)\n}\npar(mfrow=c(1,3), mar=c(0,0,0,2), oma=c(0,0,0,0), las=2)\nnulls &lt;- lapply(X=lgcp_sims, FUN=plot_lgcp)"
  },
  {
    "objectID": "w09/slides.html#ppp-objects",
    "href": "w09/slides.html#ppp-objects",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "ppp Objects",
    "text": "ppp Objects\n\nThe main datatype used to represent Planar Point Patterns [spatstat book p.¬†41]\nUnlike sf objects, which contain data+geometries for any desired collection of \\(N\\) entities, ppp objects are required to have at least an observation window!\n\n\n\nsf Creation:\n\n\nCode\ntree_df &lt;- tibble::tibble(lon=runif(100,0,1), lat=runif(100,0,1), age=runif(100,0,1))\ntree_sf &lt;- sf::st_as_sf(\n  tree_df,\n  coords = c('lon', 'lat')\n)\ntree_sf |&gt; head(4)\n\n\n\n\n\n\nage\ngeometry\n\n\n\n\n0.8593935\nPOINT (0.5035446 0.05519595)\n\n\n0.9770798\nPOINT (0.2606818 0.3874983)\n\n\n0.9517643\nPOINT (0.5464588 0.8271631)\n\n\n0.0592741\nPOINT (0.7999682 0.5852131)\n\n\n\n\n\n\n\nppp Creation:\n\n\nCode\npois_ppp &lt;- spatstat.random::rpoispp(\n  lambda=100, win=spatstat.geom::square(1)\n)\npois_ppp\n\n\nPlanar point pattern: 93 points\nwindow: rectangle = [0, 1] x [0, 1] units\n\n\nCode\nattributes(pois_ppp)$names\n\n\n[1] \"window\"     \"n\"          \"x\"          \"y\"          \"markformat\"\n\n\nCode\npois_ppp$x |&gt; head(4)\n\n\n[1] 0.51779807 0.62213583 0.84467836 0.05354204"
  },
  {
    "objectID": "w09/slides.html#ppp-leftrightarrow-sf-conversion",
    "href": "w09/slides.html#ppp-leftrightarrow-sf-conversion",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "ppp \\(\\leftrightarrow\\) sf Conversion",
    "text": "ppp \\(\\leftrightarrow\\) sf Conversion\n\n\nppp to sf Conversion:\n\n\nCode\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; head(4)\n\n\n\n\n\n\nlabel\ngeom\n\n\n\n\nwindow\nPOLYGON ((0 0, 1 0, 1 1, 0 ‚Ä¶\n\n\npoint\nPOINT (0.5177981 0.553718)\n\n\npoint\nPOINT (0.6221358 0.3933781)\n\n\npoint\nPOINT (0.8446784 0.8187611)\n\n\n\n\n\n\n\n\nCode\nlibrary(mdthemes) |&gt; suppressPackageStartupMessages()\npois_sf |&gt; ggplot() +\n  geom_sf(data=pois_sf |&gt; filter(label==\"window\"), aes(fill='grey')) +\n  geom_sf(data=pois_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'window'&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'point'&lt;/span&gt;\")) +\n  labs(title = \"&lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;sf&lt;/span&gt; Result\")\n\n\n\n\n\n\n\n\n\n\nsf to ppp Conversion:\n\n\nCode\nsquare_sfc &lt;- sf::st_polygon(list(\n  matrix(c(0,0,1,0,1,1,0,1,0,0), nrow=5, byrow=TRUE)\n)) |&gt; sf::st_sfc()\ntree_ppp &lt;- as.ppp(\n  sf::st_as_sfc(tree_sf),\n  W=as.owin(square_sfc)\n)\ntree_ppp\n\n\nPlanar point pattern: 100 points\nwindow: polygonal boundary\nenclosing rectangle: [0, 1] x [0, 1] units\n\n\n\n\nCode\ntree_ppp_sf &lt;- tree_ppp |&gt; sf::st_as_sf()\ntree_ppp_sf |&gt; ggplot() +\n  geom_sf(aes(fill='gray90')) +\n  geom_sf(data=tree_ppp_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp$window&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp${x,y}&lt;/span&gt;\")) +\n  labs(\n    title = \"&lt;span style='font-family: mono'&gt;sf&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; Result\",\n    x=\"&lt;span style='font-family: mono'&gt;tree_ppp$x&lt;/span&gt;\",\n    y=\"&lt;span style='font-family: mono'&gt;tree_ppp$y&lt;/span&gt;\"\n  ) + \n  guides(fill = guide_legend(order = 1), \n              color = guide_legend(order = 2))"
  },
  {
    "objectID": "w09/slides.html#why-do-events-appear-where-they-do-2",
    "href": "w09/slides.html#why-do-events-appear-where-they-do-2",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Why Do Events Appear Where They Do?",
    "text": "Why Do Events Appear Where They Do?\n\n\nCode\nset.seed(6809)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n### Clustered data\nclust_ppp &lt;- rMatClust(\n  kappa=6,\n  scale=r_core,\n  mu=10\n)\nclust_sf &lt;- clust_ppp |&gt; sf::st_as_sf()\nclust_plot &lt;- clust_sf |&gt;\n  ggplot() +\n  geom_sf(size=2) +\n  theme_classic(base_size=18)\nggsave(\"images/clust_ppp.png\", clust_plot, width=3, height=3)\n# Intensity fn\nclust_intensity &lt;- density(clust_ppp, sigma = 0.1)\npng(\"images/clust_intensity.png\")\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,0,0), cex=2)\nplot(clust_intensity, main=NULL)\ncontour(clust_intensity, add = TRUE)\ndev.off()\n### PCF\nclust_pcf &lt;- spatstat.explore::pcf(\n  clust_ppp, divisor=\"d\",\n  r=seq(from=0.00, to=0.50, by=0.01)\n)\nclust_pcf_plot &lt;- clust_pcf |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  labs(x=\"Distance\", y=\"Density\") +\n  theme_classic(base_size=14)\nggsave(\"images/clust_pcf.png\", clust_pcf_plot, width=3, height=3)\n\n\n\n\n\n\n\n\n\n\nOriginal Data\nFirst-Order\nSecond-Order\n\n\n\n\n\\(N = 60\\) Events\nEvents modeled individually\\(\\implies\\) Intensity function \\(\\lambda(\\mathbf{s})\\)\nEvents modeled pairwise \\(\\implies\\) \\(K\\)-function \\(K(\\vec{h})\\)"
  },
  {
    "objectID": "w09/slides.html#what-do-these-functions-detect-1",
    "href": "w09/slides.html#what-do-these-functions-detect-1",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "What Do These Functions ‚ÄúDetect‚Äù?",
    "text": "What Do These Functions ‚ÄúDetect‚Äù?\n\n\n\n\nCode\nsq_base &lt;- 16\nsq_psize &lt;- 2.5\nobs_window &lt;- square(1)\nr0 &lt;- 0.2\nsq_df &lt;- tibble::tribble(\n  ~x, ~y,\n  0.5-r0,0.5-r0,\n  0.5+r0,0.5+r0,\n  0.5-r0,0.5+r0,\n  0.5+r0,0.5-r0\n)\nsq_sf &lt;- sf::st_as_sf(\n  sq_df,\n  coords = c(\"x\",\"y\")\n)\nsq_ppp &lt;- as.ppp(sq_sf, W=obs_window)\nsq_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,1,0))\nsq_density &lt;- density(sq_ppp)\nplot(sq_density, main=NULL, xaxs='i', yaxs='i')\ncontour(sq_density, xaxs='i', yaxs='i', add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### PCF\npcf_result &lt;- spatstat.explore::pcf(\n  sq_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\npcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_ppp &lt;- spatstat.random::rpoispp(\n  lambda = 60,\n  win=obs_window\n)\ncsr_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(\n  mar=c(0,0,0,2),\n  las=2,\n  oma=c(0,0,1,0)\n)\ncsr_density &lt;- density(csr_ppp)\nplot(csr_density, main=NULL, xaxs=\"i\", yaxs=\"i\")\ncontour(csr_density, xaxs=\"i\", yaxs=\"i\", add = TRUE, lwd=1.5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_pcf_result &lt;- spatstat.explore::pcf(\n  csr_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\ncsr_pcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)"
  },
  {
    "objectID": "w09/slides.html#references",
    "href": "w09/slides.html#references",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "w09/index.html",
    "href": "w09/index.html",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#caveat-2-summary-statistics-like-i-are-not-models",
    "href": "w09/index.html#caveat-2-summary-statistics-like-i-are-not-models",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!",
    "text": "Caveat 2: Summary Statistics Like \\(I\\) are Not Models!\n\nMoran‚Äôs \\(I\\) is to GISers what a thermometer is to doctors\nMeasures symptoms; many possible underlying causes!\nNeed to ask why autocorrelation seems to be present!",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#why-do-events-appear-where-they-do",
    "href": "w09/index.html#why-do-events-appear-where-they-do",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "[] Why Do Events Appear Where They Do?",
    "text": "[] Why Do Events Appear Where They Do?\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6806)\nN &lt;- 60\nlambda &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n# Regularity via Inhibition\nreg_sims &lt;- rMaternI(lambda, r=r_core, win=obs_window)\n# CSR data\ncsr_sims &lt;- rpoispp(N, win=obs_window)\n### Clustered data\nclust_mu &lt;- 10\nclust_sims &lt;- rMatClust(kappa=lambda / clust_mu, scale=2*r_core, mu=10, win=obs_window)\n# Each cluster consist of 10 points in a disc of radius 0.2\nnclust &lt;- function(x0, y0, radius, n) {\n    #print(n)\n    return(runifdisc(10, radius, centre=c(x0, y0)))\n}\ncond_clust_sims &lt;- rNeymanScott(kappa=5, expand=0.0, rclust=nclust, radius=2*r_core, n=10)\ncond_clust_sf &lt;- cond_clust_sims |&gt; sf::st_as_sf()\npines_plot &lt;- cond_clust_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic(base_size=12)\nggsave(\"images/pines.png\", pines_plot)\n# density() calls density.ppp() if the argument is a ppp object\nden &lt;- density(cond_clust_sims, sigma = 0.1)\n#summary(den)\npng(\"images/intensity_plot.png\")\nplot(den, main = \"Intensity Œª(s)\")\ncontour(den, add = TRUE) # contour plot\ndev.off()\n# And Gest / Kest / Lest\n# saveRDS(cond_clust_sims, \"cond_clust_sims.rds\")\npcf_result &lt;- spatstat.explore::pcf.ppp(\n  cond_clust_sims,\n  divisor=\"d\",\n  stoyan=0.25,\n  bw=0.05,\n  r=seq(from=0.0, to=1.0, by=0.001)\n)\npng(\"images/spatstat_pcf.png\")\nplot(pcf_result, xlim=c(0, 1), main=\"pcf\")\ndev.off()\n# kest_result &lt;- Kest(cond_clust_sims, rmax=0.5, correction=\"best\")\n# lest_result &lt;- center_l_function(cond_clust_sims, rmax=0.5)\n# png(\"images/lest.png\")\n# plot(lest_result, main=\"K(h)\")\n# dev.off()\n\n\n\n\n\n\n\n\n\n\n\nFirst-Order\nSecond-Order\n\n\n\n\n\nEvents considered individually \\(\\Rightarrow\\) Intensity function \\(\\lambda(\\mathbf{s})\\)\nEvents considered pairwise \\(\\Rightarrow\\) Pairwise Correlation Function \\(\\textrm{pcf}(\\vec{h})\\)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#the-tree-grid-mystery",
    "href": "w09/index.html#the-tree-grid-mystery",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "The Tree-Grid Mystery",
    "text": "The Tree-Grid Mystery\nYou‚Äôve been hired as an archaeologist ‚Äì congratulations! Your job: determine whether arrangement of trees formed:\n\nNaturally, via a process of resource competition, or\nArtificially, via an ancient civilization planting in a grid‚Ä¶",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#two-possible-histories",
    "href": "w09/index.html#two-possible-histories",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Two Possible Histories‚Ä¶",
    "text": "Two Possible Histories‚Ä¶\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Art}}\\): Artificial Formation\n\n\n\n\n\nCode (Step 1: Grid Creation)\nha_base &lt;- 28\nsquare_sf &lt;- sf::st_as_sf(spatstat.geom::square(1))\ngrid_sf &lt;- sf::st_as_sf(sf::st_make_grid(square_sf))\ngrid_buffer_sf &lt;- grid_sf |&gt; sf::st_buffer(dist=-0.01, singleSide = TRUE)\ngrid_buffer_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Point Generation)\ngrid_points &lt;- sf::st_sample(grid_buffer_sf, size=rep(1,100))\ngrid_buffer_sf |&gt; ggplot(aes(shape='Cell')) +\n  geom_sf() +\n  geom_sf(data=grid_points) +\n  scale_shape_manual(\"Shape\", values=c('Cell'=19)) +\n  theme_classic(base_size=ha_base) +\n  theme(\n    legend.title = element_blank(),\n    # legend.text = element_text(size=18)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\ngrid_ppp &lt;- as.ppp(grid_points, W=spatstat.geom::square(1))\ngrid_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=ha_base)\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis \\(\\mathcal{H}_{\\textsf{Nat}}\\): Natural Formation\n\n\n\n\n\nCode (Step 1: Tree Generation)\nhn_base &lt;- 28\nr &lt;- 0.05\npois_ppp &lt;- rpoispp(150)\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 2: Competition)\nage &lt;- runif(npoints(pois_ppp))\npair_dists &lt;- pairdist(pois_ppp)\nclose &lt;- (pair_dists &lt; r)\nlater &lt;- outer(age, age, \"&gt;\")\nkilled &lt;- apply(close & later, 1, any)\nkilled_ppp &lt;- pois_ppp[killed]\nalive_ppp &lt;- pois_ppp[!killed]\npois_window_sf &lt;- pois_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"window\")\npois_killed_sf &lt;- killed_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\npois_alive_sf &lt;- alive_ppp |&gt; sf::st_as_sf() |&gt; filter(label==\"point\")\nalive_buff_sf &lt;- pois_alive_sf |&gt; sf::st_buffer(r) |&gt; sf::st_union() |&gt; sf::st_intersection(pois_window_sf)\nggplot() +\n  geom_sf(data=pois_window_sf) +\n  geom_sf(data=alive_buff_sf, aes(color='Inhibition', shape='Inhibition'), linetype='dashed') +\n  geom_sf(data=pois_killed_sf, aes(color='Dead', shape='Dead'), size=2, stroke=2) +\n  geom_sf(data=pois_alive_sf, aes(color='Alive', shape='Alive'), size=1, stroke=1) +\n  scale_shape_manual(name=NULL, values=c(\"Alive\"=19, \"Dead\"=4, 'Inhibition'=21), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  scale_color_manual(name=NULL, values=c(\"Alive\"=\"black\", \"Dead\"=cb_palette[1], \"Inhibition\"=\"black\"), labels=c(\"Alive\", \"Dead\", \"Inhibition\")) +\n  guides(shape=guide_legend(override.aes=list(fill = \"white\"))) +\n  theme_classic(base_size = hn_base) +\n  theme(plot.margin = unit(c(0,0,0,0), \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\n\nCode (Step 3: Observed Result)\nalive_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=hn_base)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#why-do-events-appear-where-they-do-1",
    "href": "w09/index.html#why-do-events-appear-where-they-do-1",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Why Do Events Appear Where They Do?",
    "text": "Why Do Events Appear Where They Do?\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6809)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n### Clustered data\nclust_ppp &lt;- rMatClust(\n  kappa=6,\n  scale=r_core,\n  mu=10\n)\nclust_sf &lt;- clust_ppp |&gt; sf::st_as_sf()\nclust_plot &lt;- clust_sf |&gt;\n  ggplot() +\n  geom_sf(size=2) +\n  theme_classic(base_size=18)\nggsave(\"images/clust_ppp.png\", clust_plot, width=3, height=3)\n# Intensity fn\nclust_intensity &lt;- density(clust_ppp, sigma = 0.1)\npng(\"images/clust_intensity.png\")\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,0,0), cex=2)\nplot(clust_intensity, main=NULL)\ncontour(clust_intensity, add = TRUE)\ndev.off()\n### PCF\nclust_pcf &lt;- spatstat.explore::pcf(\n  clust_ppp, divisor=\"d\",\n  r=seq(from=0.00, to=0.50, by=0.01)\n)\nclust_pcf_plot &lt;- clust_pcf |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  labs(x=\"Distance\", y=\"Density\") +\n  theme_classic(base_size=14)\nggsave(\"images/clust_pcf.png\", clust_pcf_plot, width=3, height=3)\n\n\n\n\n\n\n\n\n\n\nOriginal Data\nFirst-Order\nSecond-Order\n\n\n\n\n\\(N = 60\\) Events\nEvents modeled individually\\(\\Rightarrow\\) Intensity Function \\(\\lambda(\\mathbf{s})\\)\nEvents modeled pairwise \\(\\Rightarrow\\) Pairwise-Corr Function \\(\\textrm{pcf}(\\vec{h})\\)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#what-do-these-functions-detect",
    "href": "w09/index.html#what-do-these-functions-detect",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "What Do These Functions ‚ÄúDetect‚Äù?",
    "text": "What Do These Functions ‚ÄúDetect‚Äù?\n\n\n\n\nCode (Fixed Points)\nsq_base &lt;- 16\nsq_psize &lt;- 2.5\nobs_window &lt;- square(1)\nr0 &lt;- 0.2\nsq_df &lt;- tibble::tribble(\n  ~x, ~y,\n  0.5-r0,0.5-r0,\n  0.5+r0,0.5+r0,\n  0.5-r0,0.5+r0,\n  0.5+r0,0.5-r0\n)\nsq_sf &lt;- sf::st_as_sf(\n  sq_df,\n  coords = c(\"x\",\"y\")\n)\nsq_ppp &lt;- as.ppp(sq_sf, W=obs_window)\nsq_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,1,0))\nsq_density &lt;- density(sq_ppp)\nplot(sq_density, main=NULL, xaxs='i', yaxs='i')\ncontour(sq_density, xaxs='i', yaxs='i', add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### PCF\npcf_result &lt;- spatstat.explore::pcf(\n  sq_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\npcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode (CSR Points)\ncsr_ppp &lt;- spatstat.random::rpoispp(\n  lambda = 60,\n  win=obs_window\n)\ncsr_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(\n  mar=c(0,0,0,2),\n  las=2,\n  oma=c(0,0,1,0)\n)\ncsr_density &lt;- density(csr_ppp)\nplot(csr_density, main=NULL, xaxs=\"i\", yaxs=\"i\")\ncontour(csr_density, xaxs=\"i\", yaxs=\"i\", add = TRUE, lwd=1.5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_pcf_result &lt;- spatstat.explore::pcf(\n  csr_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\ncsr_pcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#poisson-point-processes-csr",
    "href": "w09/index.html#poisson-point-processes-csr",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Poisson Point Processes (CSR)",
    "text": "Poisson Point Processes (CSR)\nspatstat.random::rpoispp(lambda, win)\n\n \\(N \\sim \\text{Pois}(\\lambda)\\)\n For \\(i \\in \\{1, \\ldots, N\\}\\):\n\nGenerate \\(X_i, Y_i \\sim \\mathcal{U}(\\texttt{win})\\)\n\n\n\n\nCode\nsim_base &lt;- 22\nsim_psize &lt;- 2\nsim_xticks &lt;- seq(from=0.0, to=1.0, by=0.2)\nsim_yticks &lt;- seq(from=0.0, to=1.0, by=0.2)\ngen_pois_df &lt;- function(num_sims=1) {\n  pois_sims &lt;- spatstat.random::rpoispp(\n    lambda = 60, nsim=num_sims\n  )\n  return(tibble::as_tibble(pois_sims))\n}\n#pois_dfs &lt;- gen_pois_df()\n#pois_dfs |&gt; head()\npois_sims &lt;- spatstat.random::rpoispp(\n  lambda = 60, nsim=3\n)\nto_sim_df &lt;- function(cur_sim, sim_name) {\n  cur_df &lt;- tibble::as_tibble(cur_sim) |&gt; mutate(sim=sim_name)\n  return(cur_df)\n}\ncombined_df &lt;- imap(.x=pois_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#simple-sequential-inhibition-ssi",
    "href": "w09/index.html#simple-sequential-inhibition-ssi",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Simple Sequential Inhibition (SSI)",
    "text": "Simple Sequential Inhibition (SSI)\nspatstat.random::rSSI(r, n=Inf, giveup=1000, win)\n\n\\(\\mathbf{S} = \\varnothing\\)\nWhile not done:\n\n Generate \\(\\mathbf{E} = (X, Y) \\sim \\mathcal{U}(\\texttt{win})\\)\n Check if \\(\\mathbf{E}\\) within r units of any existing point in \\(\\mathbf{S}\\)\n\nIf it is, throw \\(\\mathbf{E}\\) away. Otherwise, add \\(\\mathbf{E}\\) to \\(\\mathbf{S}\\)\n\n done=TRUE if \\(\\mathbf{S}\\) has n points OR has been the same for giveup steps\n\n\n\n\nCode\ncapture.output(ssi_sims &lt;- spatstat.random::rSSI(\n  r = 0.05, n=60, nsim=3\n), file=nullfile())\ncombined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\ncombined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim)) +\n  coord_equal() +\n  theme_classic(base_size=24) +\n  theme(panel.spacing.x = unit(3, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#mat√©rn-cluster-process",
    "href": "w09/index.html#mat√©rn-cluster-process",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Mat√©rn Cluster Process",
    "text": "Mat√©rn Cluster Process\n\n\nspatstat.random::rMatClust(kappa, scale, mu, win)\n\nDocs\n\n\n\n Generate \\(K(\\kappa)\\) parent points via Poisson Point Process with intensity \\(\\lambda = \\kappa\\)\n For each parent point \\(\\mathbf{s}_i \\in \\left\\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{K(\\kappa)}\\right\\}\\):\n\nGenerate \\(N(\\mu)\\) offspring points via Poisson Point Process with intensity \\(\\lambda = \\mu\\), distributed uniformly within a circle of radius scale centered at \\(\\mathbf{s}_i\\)\n\n Offspring points form the outcome (parent points are thrown away)\n\n\n\nCode\nmatclust_sims &lt;- rMatClust(\n  kappa = 6,\n  scale = 0.075,\n  mu = 10,\n  nsim = 3\n)\nmatclust_df &lt;- imap(.x=matclust_sims, .f=to_sim_df) |&gt; bind_rows()\nmatclust_plot &lt;- matclust_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nmatclust_plot",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#mat√©rn-inhibition-process-i-and-ii",
    "href": "w09/index.html#mat√©rn-inhibition-process-i-and-ii",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Mat√©rn Inhibition Process (I and II)",
    "text": "Mat√©rn Inhibition Process (I and II)\nspatstat.random::rMaternI(kappa, r, win)\nspatstat.random::rMaternII(kappa, r, win)\n\n\n\n\n\n\n\nrMaternI() [Docs]\nrMaternII() [Docs]\n\n\n\n\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\)\n\n\n Generate events \\(\\mathbf{S} = \\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_{N(\\lambda)}\\}\\) via Poisson point process with \\(\\lambda = \\kappa\\), plus timestamp \\(t_i \\sim \\mathcal{U}(0,1)\\) for each \\(\\mathbf{s}_i\\)\n\n\n\n\n Delete all pairs of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\) for which \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\)\n\n\n For each pair of points \\(\\mathbf{s}_i\\), \\(\\mathbf{s}_j\\): if \\(\\textsf{dist}(\\mathbf{s}_i, \\mathbf{s}_j) &lt; \\texttt{r}\\), delete the later point\n\n\n\n\n\n\nCode\nmI_sims &lt;- rMaternI(\n  kappa = 60, r = 0.075, nsim=2\n)\nmII_sims &lt;- rMaternII(\n  kappa = 60, r = 0.075, nsim=2\n)\nmI_combined_df &lt;- imap(.x=mI_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MI \",sim))\nmII_combined_df &lt;- imap(.x=mII_sims, .f=to_sim_df) |&gt; bind_rows() |&gt; mutate(sim=paste0(\"MII \",sim))\nm_combined_df &lt;- bind_rows(mI_combined_df, mII_combined_df)\nm_plot &lt;- m_combined_df |&gt; ggplot(aes(x=x, y=y)) +\n  geom_point(size=sim_psize) +\n  facet_wrap(vars(sim), nrow=1) +\n  coord_equal() +\n  theme_classic(base_size=sim_base) +\n  theme(panel.spacing.x = unit(2, \"lines\")) +\n  scale_x_continuous(breaks=sim_xticks) +\n  scale_y_continuous(breaks=sim_yticks)\nm_plot",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#cox-processes-random-intensity-random-events",
    "href": "w09/index.html#cox-processes-random-intensity-random-events",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Cox Processes: Random Intensity ‚Üí Random Events",
    "text": "Cox Processes: Random Intensity ‚Üí Random Events\n\n\nspatstat.random::rLGCP(model, mu, param, win)\nmodels=c(\"exponential\", \"gauss\", \"stable\", \"gencauchy\", \"matern\")\n\nDocs\n\n\n\n\nCode\ncox_pcol &lt;- \"black\"\ncox_bg &lt;- \"grey90\"\ncox_pch &lt;- 21\n# inhomogeneous LGCP with Gaussian covariance function\nm &lt;- as.im(function(x, y){\n  5 - 1.5 * (x - 0.5)^2 + 2 * (y - 0.5)^2\n}, W=owin())\nlgcp_sims &lt;- rLGCP(\"gauss\", m, var=0.15, scale =0.5, nsim=3)\n\n\nWarning: 32750 out of 65536 terms (50%) in FFT calculation of matrix square\nroot were negative, and were set to zero. Range: [-2.96, 1910]\n\n\nCode\n# lgcp_combined_df &lt;- imap(.x=ssi_sims, .f=to_sim_df) |&gt; bind_rows()\nplot_lgcp &lt;- function(lgcp_sim) {\n  plot(attr(lgcp_sim, \"Lambda\"), main=NULL)\n  points(lgcp_sim, col=cox_pcol, bg=cox_bg, pch=cox_pch)\n}\npar(mfrow=c(1,3), mar=c(0,0,0,2), oma=c(0,0,0,0), las=2)\nnulls &lt;- lapply(X=lgcp_sims, FUN=plot_lgcp)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#ppp-objects",
    "href": "w09/index.html#ppp-objects",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "ppp Objects",
    "text": "ppp Objects\n\nThe main datatype used to represent Planar Point Patterns [spatstat book p.¬†41]\nUnlike sf objects, which contain data+geometries for any desired collection of \\(N\\) entities, ppp objects are required to have at least an observation window!\n\n\n\nsf Creation:\n\n\nCode\ntree_df &lt;- tibble::tibble(lon=runif(100,0,1), lat=runif(100,0,1), age=runif(100,0,1))\ntree_sf &lt;- sf::st_as_sf(\n  tree_df,\n  coords = c('lon', 'lat')\n)\ntree_sf |&gt; head(4)\n\n\n\n\n\n\nage\ngeometry\n\n\n\n\n0.8593935\nPOINT (0.5035446 0.05519595)\n\n\n0.9770798\nPOINT (0.2606818 0.3874983)\n\n\n0.9517643\nPOINT (0.5464588 0.8271631)\n\n\n0.0592741\nPOINT (0.7999682 0.5852131)\n\n\n\n\n\n\n\nppp Creation:\n\n\nCode\npois_ppp &lt;- spatstat.random::rpoispp(\n  lambda=100, win=spatstat.geom::square(1)\n)\npois_ppp\n\n\nPlanar point pattern: 93 points\nwindow: rectangle = [0, 1] x [0, 1] units\n\n\nCode\nattributes(pois_ppp)$names\n\n\n[1] \"window\"     \"n\"          \"x\"          \"y\"          \"markformat\"\n\n\nCode\npois_ppp$x |&gt; head(4)\n\n\n[1] 0.51779807 0.62213583 0.84467836 0.05354204",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#ppp-leftrightarrow-sf-conversion",
    "href": "w09/index.html#ppp-leftrightarrow-sf-conversion",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "ppp \\(\\leftrightarrow\\) sf Conversion",
    "text": "ppp \\(\\leftrightarrow\\) sf Conversion\n\n\nppp to sf Conversion:\n\n\nCode\npois_sf &lt;- pois_ppp |&gt; sf::st_as_sf()\npois_sf |&gt; head(4)\n\n\n\n\n\n\nlabel\ngeom\n\n\n\n\nwindow\nPOLYGON ((0 0, 1 0, 1 1, 0 ‚Ä¶\n\n\npoint\nPOINT (0.5177981 0.553718)\n\n\npoint\nPOINT (0.6221358 0.3933781)\n\n\npoint\nPOINT (0.8446784 0.8187611)\n\n\n\n\n\n\n\n\nCode\nlibrary(mdthemes) |&gt; suppressPackageStartupMessages()\npois_sf |&gt; ggplot() +\n  geom_sf(data=pois_sf |&gt; filter(label==\"window\"), aes(fill='grey')) +\n  geom_sf(data=pois_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'window'&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;label == 'point'&lt;/span&gt;\")) +\n  labs(title = \"&lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;sf&lt;/span&gt; Result\")\n\n\n\n\n\n\n\n\n\n\nsf to ppp Conversion:\n\n\nCode\nsquare_sfc &lt;- sf::st_polygon(list(\n  matrix(c(0,0,1,0,1,1,0,1,0,0), nrow=5, byrow=TRUE)\n)) |&gt; sf::st_sfc()\ntree_ppp &lt;- as.ppp(\n  sf::st_as_sfc(tree_sf),\n  W=as.owin(square_sfc)\n)\ntree_ppp\n\n\nPlanar point pattern: 100 points\nwindow: polygonal boundary\nenclosing rectangle: [0, 1] x [0, 1] units\n\n\n\n\nCode\ntree_ppp_sf &lt;- tree_ppp |&gt; sf::st_as_sf()\ntree_ppp_sf |&gt; ggplot() +\n  geom_sf(aes(fill='gray90')) +\n  geom_sf(data=tree_ppp_sf |&gt; filter(label != \"window\"), aes(color='black')) +\n  md_theme_classic(base_size=26) +\n  scale_fill_manual(name=NULL, values=c(\"gray90\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp$window&lt;/span&gt;\")) +\n  scale_color_manual(name=NULL, values=c(\"black\"), labels=c(\"&lt;span style='font-family: mono'&gt;tree_ppp${x,y}&lt;/span&gt;\")) +\n  labs(\n    title = \"&lt;span style='font-family: mono'&gt;sf&lt;/span&gt; &rarr; &lt;span style='font-family: mono'&gt;ppp&lt;/span&gt; Result\",\n    x=\"&lt;span style='font-family: mono'&gt;tree_ppp$x&lt;/span&gt;\",\n    y=\"&lt;span style='font-family: mono'&gt;tree_ppp$y&lt;/span&gt;\"\n  ) + \n  guides(fill = guide_legend(order = 1), \n              color = guide_legend(order = 2))",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#why-do-events-appear-where-they-do-2",
    "href": "w09/index.html#why-do-events-appear-where-they-do-2",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "Why Do Events Appear Where They Do?",
    "text": "Why Do Events Appear Where They Do?\n\n\nCode\nset.seed(6809)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n### Clustered data\nclust_ppp &lt;- rMatClust(\n  kappa=6,\n  scale=r_core,\n  mu=10\n)\nclust_sf &lt;- clust_ppp |&gt; sf::st_as_sf()\nclust_plot &lt;- clust_sf |&gt;\n  ggplot() +\n  geom_sf(size=2) +\n  theme_classic(base_size=18)\nggsave(\"images/clust_ppp.png\", clust_plot, width=3, height=3)\n# Intensity fn\nclust_intensity &lt;- density(clust_ppp, sigma = 0.1)\npng(\"images/clust_intensity.png\")\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,0,0), cex=2)\nplot(clust_intensity, main=NULL)\ncontour(clust_intensity, add = TRUE)\ndev.off()\n### PCF\nclust_pcf &lt;- spatstat.explore::pcf(\n  clust_ppp, divisor=\"d\",\n  r=seq(from=0.00, to=0.50, by=0.01)\n)\nclust_pcf_plot &lt;- clust_pcf |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  labs(x=\"Distance\", y=\"Density\") +\n  theme_classic(base_size=14)\nggsave(\"images/clust_pcf.png\", clust_pcf_plot, width=3, height=3)\n\n\n\n\n\n\n\n\n\n\nOriginal Data\nFirst-Order\nSecond-Order\n\n\n\n\n\\(N = 60\\) Events\nEvents modeled individually\\(\\implies\\) Intensity function \\(\\lambda(\\mathbf{s})\\)\nEvents modeled pairwise \\(\\implies\\) \\(K\\)-function \\(K(\\vec{h})\\)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#what-do-these-functions-detect-1",
    "href": "w09/index.html#what-do-these-functions-detect-1",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "What Do These Functions ‚ÄúDetect‚Äù?",
    "text": "What Do These Functions ‚ÄúDetect‚Äù?\n\n\n\n\nCode\nsq_base &lt;- 16\nsq_psize &lt;- 2.5\nobs_window &lt;- square(1)\nr0 &lt;- 0.2\nsq_df &lt;- tibble::tribble(\n  ~x, ~y,\n  0.5-r0,0.5-r0,\n  0.5+r0,0.5+r0,\n  0.5-r0,0.5+r0,\n  0.5+r0,0.5-r0\n)\nsq_sf &lt;- sf::st_as_sf(\n  sq_df,\n  coords = c(\"x\",\"y\")\n)\nsq_ppp &lt;- as.ppp(sq_sf, W=obs_window)\nsq_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mar=c(0,0,0,2), las=2, oma=c(0,0,1,0))\nsq_density &lt;- density(sq_ppp)\nplot(sq_density, main=NULL, xaxs='i', yaxs='i')\ncontour(sq_density, xaxs='i', yaxs='i', add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### PCF\npcf_result &lt;- spatstat.explore::pcf(\n  sq_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\npcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_ppp &lt;- spatstat.random::rpoispp(\n  lambda = 60,\n  win=obs_window\n)\ncsr_ppp |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf(size=sq_psize) +\n  theme_classic(base_size=sq_base)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(\n  mar=c(0,0,0,2),\n  las=2,\n  oma=c(0,0,1,0)\n)\ncsr_density &lt;- density(csr_ppp)\nplot(csr_density, main=NULL, xaxs=\"i\", yaxs=\"i\")\ncontour(csr_density, xaxs=\"i\", yaxs=\"i\", add = TRUE, lwd=1.5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncsr_pcf_result &lt;- spatstat.explore::pcf(\n  csr_ppp,\n  divisor=\"d\",\n  r=seq(from=0.00, to=0.8, by=0.01)\n)\ncsr_pcf_result |&gt; ggplot(aes(x=r, y=iso)) +\n  geom_hline(yintercept=1, linetype='dashed', linewidth=1.5) +\n  geom_area(color='black', fill=cb_palette[1], alpha=0.75) +\n  scale_x_continuous(breaks=seq(from=0.0, to=1.0, by=0.1)) +\n  theme_classic(base_size=sq_base)",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "w09/index.html#references",
    "href": "w09/index.html#references",
    "title": "Week 9: Evaluating Spatial Hypotheses I: Point Data",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 9: Oct 22"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PPOL 6805 / DSAN 6750: Geographic Information Systems (GIS) for Spatial Data Science",
    "section": "",
    "text": "Welcome to the homepage for PPOL 6805 / DSAN 6750: Geographic Information Systems (GIS) for Spatial Data Science, Fall 2025, at Georgetown University! The course takes place on Wednesdays from 6:30 to 9:00pm in Healy 105. More details are provided on the syllabus.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\n\nDate\n\n\n\n\n\n\n\n\nWeek 1: Introduction to GIS\n\n\nAug 27\n\n\n\n\n\n\nWeek 2: How Do Maps Work?\n\n\nSep 3\n\n\n\n\n\n\nWeek 3: Vector and Raster Representations\n\n\nSep 11\n\n\n\n\n\n\nWeek 4: Unary Operations\n\n\nSep 17\n\n\n\n\n\n\nWeek 5: Binary Operations and DE-9IM\n\n\nSep 25\n\n\n\n\n\n\nWeek 6: Spatial Joins and Areal-Weighted Interpolation\n\n\nOct 2\n\n\n\n\n\n\nWeek 7: Spatial Data Science: Three Forms of Spatial Autocorrelation\n\n\nOct 9\n\n\n\n\n\n\nWeek 8: Point Processes: Null Models, Clustering, and Regularity\n\n\nOct 15\n\n\n\n\n\n\nWeek 9: Evaluating Spatial Hypotheses I: Point Data\n\n\nOct 22\n\n\n\n\n\n\nWeek 10: Evaluating Spatial Hypotheses II: Areal Data\n\n\nOct 29\n\n\n\n\n\n\nWeek 11: In-Class Midterm\n\n\nNov 5\n\n\n\n\n\n\nWeek 12: Tools for Final Projects\n\n\nNov 12\n\n\n\n\n\n\nWeek 13: In-Class Office Hours\n\n\nNov 20\n\n\n\n\n\n\nWeek 14: Final Project Poster Session\n\n\nDec 4\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "<i class='bi bi-house pe-1'></i> Home"
    ]
  },
  {
    "objectID": "w11/index.html",
    "href": "w11/index.html",
    "title": "Week 11: In-Class Midterm",
    "section": "",
    "text": "Midterm\n\nThe midterm will be available on Positron from 6:30pm to 9:30pm on Wednesday, November 5th, 2025.",
    "crumbs": [
      "Week 11: Nov 5"
    ]
  },
  {
    "objectID": "writeups/data-sources/index.html",
    "href": "writeups/data-sources/index.html",
    "title": "Finding GIS Data",
    "section": "",
    "text": "This collection of ‚Äúcore‚Äù data sources draws heavily on Chapter 6: ‚ÄúR packages to download open spatial data‚Äù, in Moraga (2018), Spatial Statistics for Data Science: Theory and Practice with R"
  },
  {
    "objectID": "writeups/data-sources/index.html#country-boundaries",
    "href": "writeups/data-sources/index.html#country-boundaries",
    "title": "Finding GIS Data",
    "section": "Country Boundaries",
    "text": "Country Boundaries\nKey package: rnaturalearth\n\n\nCode\nlibrary(rnaturalearth)\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(ggplot2)\nlibrary(viridis) |&gt; suppressPackageStartupMessages()\nlibrary(patchwork)\nde_national_map &lt;- ne_countries(type = \"countries\", country = \"Germany\", scale = \"medium\", returnclass = \"sf\")\nde_states_map &lt;- rnaturalearth::ne_states(\"Germany\", returnclass = \"sf\")\n(ggplot(de_national_map) + geom_sf()) + (ggplot(de_states_map) + geom_sf())"
  },
  {
    "objectID": "writeups/data-sources/index.html#climate-data",
    "href": "writeups/data-sources/index.html#climate-data",
    "title": "Finding GIS Data",
    "section": "Climate Data",
    "text": "Climate Data\nKey package: geodata\n\n\nCode\nlibrary(geodata)\n\n\nLoading required package: terra\n\n\nterra 1.8.60\n\n\n\nAttaching package: 'terra'\n\n\nThe following object is masked from 'package:patchwork':\n\n    area\n\n\nCode\njamaica_tmin &lt;- worldclim_country(\n  country = \"Jamaica\",\n  var = \"tmin\",\n  path = tempdir()\n)\nterra::plot(\n  mean(jamaica_tmin),\n  plg = list(title = \"Min. temperature (C)\")\n)"
  },
  {
    "objectID": "writeups/data-sources/index.html#elevation",
    "href": "writeups/data-sources/index.html#elevation",
    "title": "Finding GIS Data",
    "section": "Elevation",
    "text": "Elevation\nKey packages: rnaturalearth + elevatr\n\n\nCode\nlibrary(rnaturalearth)\nlibrary(elevatr)\n\n\nelevatr v0.99.0 NOTE: Version 0.99.0 of 'elevatr' uses 'sf' and 'terra'.  Use \nof the 'sp', 'raster', and underlying 'rgdal' packages by 'elevatr' is being \ndeprecated; however, get_elev_raster continues to return a RasterLayer.  This \nwill be dropped in future versions, so please plan accordingly.\n\n\nCode\nlibrary(terra)\nswitz_sf &lt;- ne_countries(\n  type = \"countries\",\n  country = \"Switzerland\",\n  scale = \"medium\",\n  returnclass = \"sf\"\n)\n# Special weird case with Georgetown's SaxaNet wifi... This if statement just\n# tells the R library curl that SaxaNet is indeed a valid wifi connection\nif (!curl::has_internet()) {\n  assign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\n}\nswitz_raster &lt;- get_elev_raster(\n  locations = switz_sf, z = 9, clip = \"locations\"\n)\n\n\nMosaicing & Projecting\n\n\nClipping DEM to locations\n\n\nNote: Elevation units are in meters.\n\n\nCode\nterra::plot(\n  rast(switz_raster),\n  plg = list(title = \"Elevation (m)\")\n)"
  },
  {
    "objectID": "writeups/data-sources/index.html#street-maps",
    "href": "writeups/data-sources/index.html#street-maps",
    "title": "Finding GIS Data",
    "section": "Street Maps",
    "text": "Street Maps\nKey package: osmdata\n\n\nCode\nlibrary(osmdata) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet)\nplacebb &lt;- getbb(\"Barcelona\")\nhospitals &lt;- placebb |&gt;\n  opq() |&gt;\n  add_osm_feature(key = \"amenity\", value = \"hospital\") |&gt;\n  osmdata_sf()\nassign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\nmotorways &lt;- placebb |&gt;\n  opq() |&gt;\n  add_osm_feature(\n    key = \"highway\",\n    value = \"motorway\"\n  ) |&gt;\n  osmdata_sf()\nleaflet() |&gt;\n  addTiles() |&gt;\n  addPolylines(\n    data = motorways$osm_lines,\n    color = \"black\"\n  ) |&gt;\n  addPolygons(\n    data = hospitals$osm_polygons,\n    label = hospitals$osm_polygons$name\n  )"
  },
  {
    "objectID": "writeups/data-sources/index.html#world-bank-dataverse",
    "href": "writeups/data-sources/index.html#world-bank-dataverse",
    "title": "Finding GIS Data",
    "section": "World Bank Dataverse",
    "text": "World Bank Dataverse\nKey package: wbstats\n\n\nCode\nlibrary(wbstats)\nd &lt;- wb_data(\n  indicator = \"MO.INDEX.HDEV.XQ\",\n  start_date = 2011, end_date = 2011\n)\nlibrary(rnaturalearth)\nlibrary(mapview)\nmap &lt;- ne_countries(\n  continent = \"Africa\", returnclass = \"sf\"\n)\nmap &lt;- dplyr::left_join(\n  map, d, by = c(\"iso_a3\" = \"iso3c\")\n)\nmapview(map, zcol = \"MO.INDEX.HDEV.XQ\")"
  },
  {
    "objectID": "writeups/data-sources/index.html#additional-data-sources-raindrop.io-bookmarks",
    "href": "writeups/data-sources/index.html#additional-data-sources-raindrop.io-bookmarks",
    "title": "Finding GIS Data",
    "section": "Additional Data Sources (Raindrop.io Bookmarks)",
    "text": "Additional Data Sources (Raindrop.io Bookmarks)"
  },
  {
    "objectID": "writeups/sfdep/index.html",
    "href": "writeups/sfdep/index.html",
    "title": "Unambiguous Neighborhoods with sfdep",
    "section": "",
    "text": "library(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nlibrary(rnaturalearth) |&gt; suppressPackageStartupMessages()\nlibrary(spdep) |&gt; suppressPackageStartupMessages()\n\n\nRelevant Moraga\nRelevant Pebesma"
  },
  {
    "objectID": "writeups/sfdep/index.html#initialization-code",
    "href": "writeups/sfdep/index.html#initialization-code",
    "title": "Unambiguous Neighborhoods with sfdep",
    "section": "",
    "text": "library(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nlibrary(rnaturalearth) |&gt; suppressPackageStartupMessages()\nlibrary(spdep) |&gt; suppressPackageStartupMessages()\n\n\nRelevant Moraga\nRelevant Pebesma"
  },
  {
    "objectID": "writeups/sfdep/index.html#finding-neighbors-in-asia",
    "href": "writeups/sfdep/index.html#finding-neighbors-in-asia",
    "title": "Unambiguous Neighborhoods with sfdep",
    "section": "Finding Neighbors in Asia",
    "text": "Finding Neighbors in Asia\n\nasia_countries_sf &lt;- ne_countries(continent = \"Asia\", scale=50)\nmapview(asia_countries_sf, label=\"geounit\")\n\n\n\n\n\n\nlibrary(spdep)\nasia_countries_nb &lt;- asia_countries_sf |&gt;\n  spdep::poly2nb(\n    queen = TRUE,\n    row.names=asia_countries_sf$geounit\n  )\nasia_countries_nb\n\nNeighbour list object:\nNumber of regions: 53 \nNumber of nonzero links: 164 \nPercentage nonzero weights: 5.838377 \nAverage number of links: 3.09434 \n7 regions with no links:\nTaiwan Sri Lanka Singapore Philippines Japan Bahrain Indian Ocean\nTerritories\n9 disjoint connected subgraphs\n\n\n\nnb_cents &lt;- sf::st_point_on_surface(asia_countries_sf) |&gt;\n  sf::st_as_sf()\n\nWarning: st_point_on_surface assumes attributes are constant over geometries\n\n\nWarning in st_point_on_surface.sfc(st_geometry(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\nnb_lines &lt;- spdep::nb2lines(\n  asia_countries_nb,\n  coords=st_coordinates(nb_cents),\n  as_sf=TRUE\n)\nnb_lines$edgelabel &lt;- paste0(nb_lines$i_ID, \"-\", nb_lines$j_ID)\nmapview(nb_cents, label=\"geounit\") + mapview(nb_lines, label=\"edgelabel\")\n\n\n\n\n\n\nprint(asia_countries_nb)\n\nNeighbour list object:\nNumber of regions: 53 \nNumber of nonzero links: 164 \nPercentage nonzero weights: 5.838377 \nAverage number of links: 3.09434 \n7 regions with no links:\nTaiwan Sri Lanka Singapore Philippines Japan Bahrain Indian Ocean\nTerritories\n9 disjoint connected subgraphs\n\n\n\nasia_nb_names &lt;- attributes(asia_countries_nb)$region.id\nafg_index &lt;- which(asia_nb_names == \"Afghanistan\")\nasia_countries_sf$neighbors &lt;- \"other\"\nasia_countries_sf$neighbors[afg_index] &lt;- \"area\"\nasia_countries_sf$neighbors[asia_countries_nb[[afg_index]]] &lt;- \"neighbors\"\nafg_sf &lt;- asia_countries_sf |&gt; filter(neighbors != \"other\")\nggplot(afg_sf) +\n  geom_sf(aes(fill = neighbors)) +\n  theme_bw() +\n  scale_fill_manual(\n    values = c(\"gray30\", \"gray\", \"white\")\n  )\n\n\n\n\n\n\n\n\n\nmapview(afg_sf, zcol=\"neighbors\", label=\"geounit\")\n\n\n\n\n\n\nnb_weights &lt;- asia_countries_nb |&gt;\n  spdep::nb2listw(zero.policy=TRUE)\n\n\nafg_df &lt;- tibble(\n  nb_name=asia_countries_sf$geounit[nb_weights$neighbours[[afg_index]]],\n  nb_index=nb_weights$neighbours[[afg_index]],\n  nb_weight=nb_weights$weights[[afg_index]]\n)\nafg_df\n\n\n\n\n\nnb_name\nnb_index\nnb_weight\n\n\n\n\nUzbekistan\n3\n0.1666667\n\n\nTurkmenistan\n5\n0.1666667\n\n\nTajikistan\n9\n0.1666667\n\n\nPakistan\n18\n0.1666667\n\n\nIran\n34\n0.1666667\n\n\nChina\n40\n0.1666667\n\n\n\n\n\n\n\nnb_dist_weights &lt;- asia_countries_nb |&gt;\n  spdep::nb2listwdist(nb_cents, zero.policy=TRUE)\n\n\nafg_dist_df &lt;- tibble(\n  nb_name=asia_countries_sf$geounit[nb_dist_weights$neighbours[[afg_index]]],\n  nb_index=nb_dist_weights$neighbours[[afg_index]],\n  nb_weight=nb_dist_weights$weights[[afg_index]]\n)\nafg_dist_df\n\n\n\n\n\nnb_name\nnb_index\nnb_weight\n\n\n\n\nUzbekistan\n3\n0.1306825\n\n\nTurkmenistan\n5\n0.1251905\n\n\nTajikistan\n9\n0.1321491\n\n\nPakistan\n18\n0.1657872\n\n\nIran\n34\n0.0890133\n\n\nChina\n40\n0.0298321"
  },
  {
    "objectID": "writeups/working-with-crs/index.html",
    "href": "writeups/working-with-crs/index.html",
    "title": "Working with Coordinate Reference Systems (CRS)",
    "section": "",
    "text": "The sf library documentation can be a bit vague about how exactly it handles different Coordinate Reference Systems (CRS). The most important pieces of info, though, can be found in the ‚ÄúValues‚Äù section within the page for the st_crs() function.\nLet‚Äôs look at what that part says, in the context of HW2, to see what‚Äôs happening ‚Äúunder the hood‚Äù when we convert from one CRS to another!"
  },
  {
    "objectID": "writeups/working-with-crs/index.html#hw2-question-1.5",
    "href": "writeups/working-with-crs/index.html#hw2-question-1.5",
    "title": "Working with Coordinate Reference Systems (CRS)",
    "section": "HW2 Question 1.5",
    "text": "HW2 Question 1.5\nOnce you complete Question 1.1 to 1.4 on HW1, you will have an object called africa_longlines_sf containing, for each country, the longest LINESTRING out of all of its borders.\nRecall how rnaturalearth represents country geometries as MULTIPOLYGONs, since countries like Cape Verde can be made up of multiple POLYGONs! The longest LINESTRING for Cape Verde is therefore just the border around whichever of its islands has the longest coastline, which happens to be Santiago, where its capital city Praia is located.\nSo, given that definition of the ‚Äúmain‚Äù LINESTRING for each country, using mapview to plot your africa_longlines_sf object should produce a map that looks as follows (you can zoom in on Cape Verde, off the coast of Senegal in West Africa, to see the LINESTRING around Santiago):\n\nset.seed(6805)\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nif (!(getwd() |&gt; endsWith(\"working-with-crs\"))) {\n  setwd(\"./writeups/working-with-crs\")\n}\nafrica_longlines_sf &lt;- readRDS(\"data/africa_longlines_sf.rds\")\nafrica_longlines_map &lt;- mapview(\n  africa_longlines_sf,\n  label='geounit'\n)\nafrica_longlines_map"
  },
  {
    "objectID": "writeups/working-with-crs/index.html#getting-crs-information",
    "href": "writeups/working-with-crs/index.html#getting-crs-information",
    "title": "Working with Coordinate Reference Systems (CRS)",
    "section": "Getting CRS Information",
    "text": "Getting CRS Information\nJust looking at that map, there‚Äôs not really any easy way to tell what CRS the LINESTRINGs are projected into. The easiest way to get this information is to use the st_crs() function from the sf library! In the following cell we store the result of st_crs() into a variable named africa_longlines_crs, and examine what class this object has:\n\nafrica_longlines_crs &lt;- sf::st_crs(africa_longlines_sf)\nclass(africa_longlines_crs)\n\n[1] \"crs\"\n\n\nThis tells us that st_crs() produces an object of type crs. Which, it turns out, sf does not provide much documentation on, as mentioned above. However, from the page linked above, we can figure out that objects of this crs class will have two pieces of information that we can extract from it: an attribute named input and an attribute named wkt. We can also see this by expanding the africa_longlines_crs entry within the Variables Pane in the bottom-right of Positron‚Äôs interface:\n\n\n\n\n\nWe can therefore use print(), or for a way easier-to-read output we can use writeLines() as in the following cell, to display the WKT string for the CRS, that is, all of the information that sf has about the CRS being used:\n\nwriteLines(africa_longlines_crs$wkt)\n\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nFrom this output we can see, at the very bottom, the 4-digit EPSG code for our CRS! If we‚Äôd like, we can then use EPSG‚Äôs Web API to find even more information about this CRS, by going to https://epsg.io/4326."
  },
  {
    "objectID": "writeups/working-with-crs/index.html#the-problem-with-4326",
    "href": "writeups/working-with-crs/index.html#the-problem-with-4326",
    "title": "Working with Coordinate Reference Systems (CRS)",
    "section": "The Problem with 4326",
    "text": "The Problem with 4326\nNow, if we ask sf to give us a randomly-sampled point along each border as-is, we‚Äôll get an error:\n\nafrica_longlines_sf |&gt; sf::st_line_sample(n=1)\n\nError in sf::st_line_sample(africa_longlines_sf, n = 1): st_line_sample for longitude/latitude not supported; use st_segmentize?\n\n\nWhy is this happening? It‚Äôs because (sadly) sf doesn‚Äôt support randomly-sampling points from LINESTRINGs which have been projected into the ‚Äústandard‚Äù 4326 CRS.\nHowever, this is an issue specific to the 4326 CRS ‚Äì if we can re-project each of the geometries in our geom column into a CRS for which sf does support sampling across LINESTRINGs, then we can proceed with our pipeline!"
  },
  {
    "objectID": "writeups/working-with-crs/index.html#the-1984-2020-updated-crs",
    "href": "writeups/working-with-crs/index.html#the-1984-2020-updated-crs",
    "title": "Working with Coordinate Reference Systems (CRS)",
    "section": "The 1984 ‚Üí 2020 Updated CRS",
    "text": "The 1984 ‚Üí 2020 Updated CRS\nIt turns out that, as was vaguely mentioned in class, there is another CRS with code 3857 which is slightly more amenable to GIS operations. While the 4326 CRS was created in the 1980s for early GPS systems, the 3857 CRS is regularly updated (most recently in 2020) for ease-of-use with web mapping systems like Google Maps. And, sf can indeed sample points along a LINESTRING if that LINESTRING is projected in CRS 3857.\nSo, let‚Äôs re-project our africa_longlines_sf object into the 3857 CRS, and re-try! We‚Äôll store the result of the st_line_sample() call into a variable named africa_border_points, then we‚Äôll write the last line of our code cell as just africa_border_points so that R outputs the contents of this object as the result of running the cell:\n\nafrica_longlines_sf &lt;- africa_longlines_sf |&gt;\n  sf::st_transform(3857)\nafrica_border_points &lt;- africa_longlines_sf |&gt;\n  sf::st_line_sample(n=1)\nafrica_border_points\n\nGeometry set for 54 features \nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: -2645872 ymin: -4074508 xmax: 5619598 ymax: 4276805\nProjected CRS: WGS 84 / Pseudo-Mercator\nFirst 5 geometries:\n\n\nMULTIPOINT ((-189469.2 2627672))\n\n\nMULTIPOINT ((1437119 -1458796))\n\n\nMULTIPOINT ((313588.9 1389121))\n\n\nMULTIPOINT ((2472813 -3048061))\n\n\nMULTIPOINT ((-471616.7 1484662))\n\n\nBam. We can see that, for each of the 54 LINESTRING geometries in our africa_longlines_sf object, it has sampled a single point along this line1.\nWe can use mapview() here to generate a quick preview of where each sampled point falls relative to the map of Africa‚Äôs borders, to confirm that it has indeed only sampled points along these borders:\n\nafrica_points_map &lt;- mapview(\n  africa_border_points\n)\nafrica_longlines_map + africa_points_map\n\n\n\n\n\nNotice how, when you hover your mouse over the points, the popup tooltip just displays a number‚Ä¶ that‚Äôs because africa_border_points is literally just a bunch of points, indexed by the order in which they were created: Point 1, Point 2, etc. As of now, mapview has no way of knowing that in fact each point is related to a country in africa_longlines_sf! As far as it‚Äôs concerned, it is just plotting two unrelated collections of geometries onto the base map of Africa.\nSo, once you‚Äôve completed Q1.1 through Q1.4, and once you‚Äôve re-projected the LINESTRING geometries within africa_longlines_sf into the 3857 CRS, your remaining task in Q1.5 is to take this africa_border_points object ‚Äì right now an sfg object2 ‚Äì and add it to africa_longlines_sf as a new column (rather than its own separate object)."
  },
  {
    "objectID": "writeups/working-with-crs/index.html#footnotes",
    "href": "writeups/working-with-crs/index.html#footnotes",
    "title": "Working with Coordinate Reference Systems (CRS)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote how it creates MULTIPOINT geometries rather than just POINT geometries ‚Äì this is because sf::st_line_sample() is meant to support sampling any number of points from the line. Thus it always produces a MULTIPOINT geometry, where the number of points within that geometry will be exactly the n parameter we provide to the function. Since we provided n=1, however, the MULTIPOINT only contains a single point, and thus we could safely convert it from MULTIPOINT to POINT without any loss of information (which would also be more memory-efficient, since the sf object would now know that it only has to keep track of a single point for each row!)‚Ü©Ô∏é\nAs briefly mentioned in class, an sfg object is like sf‚Äôs version of a ‚Äúgeometric vector‚Äù: it is a column that could go into a data.frame or tibble for example, but it also has the special property that it contains WKT-encoded geometries, so that it could also go into an sf object and be used as that sf object‚Äôs special geometry column!‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/hw1-guide/index.html",
    "href": "writeups/hw1-guide/index.html",
    "title": "HW1 Hints",
    "section": "",
    "text": "There are a few points in HW1 which may be tricky if you haven‚Äôt used R before, so this guide is here to provide you with some sample code that you can hopefully adapt for use in Questions 2 and 3!"
  },
  {
    "objectID": "writeups/hw1-guide/index.html#question-2-creating-sfg-sf-geometry-objects",
    "href": "writeups/hw1-guide/index.html#question-2-creating-sfg-sf-geometry-objects",
    "title": "HW1 Hints",
    "section": "Question 2: Creating sfg (sf Geometry) Objects",
    "text": "Question 2: Creating sfg (sf Geometry) Objects\nHere, the trickiest part is probably figuring out exactly what format the sf library wants you to use when creating these geometry objects: the sf representations of POINT, LINESTRING, and POLYGON.\nSo, each subsection here will provide you with code explaining how to construct each of these three types of sfg objects out of three basic R data structures: vector, matrix, and list.\n\nCreating POINT objects with sf_point()\nThe syntax for creating POINT objects is the simplest of the three: since a POINT object in the WKT schema is literally just two numbers, we just need a way to ‚Äúbundle together‚Äù two numbers and then provide this ‚Äúbundle‚Äù to the sf library.\nSo, as was discussed in class and in the Coding Workshop, we can use the c() function from Base R to bundle together any number of objects (as long as they‚Äôre all of the same type) into a vector:\n\n\nCode\n(my_numeric_vec &lt;- c(1, 2, 3))\n\n\n[1] 1 2 3\n\n\nCode\n(my_character_vec &lt;- c(\"a\", \"b\", \"c\"))\n\n\n[1] \"a\" \"b\" \"c\"\n\n\nCode\n(my_logical_vec &lt;- c(TRUE, FALSE, TRUE))\n\n\n[1]  TRUE FALSE  TRUE\n\n\nWith this knowledge, along with the fact that the sf library documentation says that the st_point() function takes in a vector as input, let‚Äôs create a POINT object in R!\nSince we also linked the Wikipedia page on WKT geometry representations above, let‚Äôs use the examples from that page. Their example for a POINT looks like:\n\n\n\nPOINT\n\nPOINT (30 10)\n\n\n\nAnd, the way we would create this POINT object in R (in a way that we could thus plot it or apply our unary/binary operations to it) looks as follows:\n\n\nCode\n# Load the sf library functions into R's memory\nlibrary(sf)\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\nCode\n# Create a numeric vector containing the two coordinates\nmy_point_coords &lt;- c(30, 10)\n# Print out the contents of this numeric vector\nprint(my_point_coords)\n\n\n[1] 30 10\n\n\nCode\n# Print out the *class* (the datatype) of this vector, how it is stored in R\nclass(my_point_coords)\n\n\n[1] \"numeric\"\n\n\nCode\n# Use the numeric vector as the *argument* to st_point(), to tell sf we want a POINT with these coordinates\nmy_point &lt;- st_point(my_point_coords)\n# Print out the *class* of this object, to see how sf has created an sfg (sf geometry) object\nclass(my_point)\n\n\n[1] \"XY\"    \"POINT\" \"sfg\"  \n\n\nWe could also use plot() to plot an ultra-basic visual representation of this POINT we just created, my_point. It won‚Äôt be very interesting, however, since the plot() function for sfg objects is meant to just quickly provide an as-simple-as-possible visual representation:\n\n\nCode\nplot(my_point)\n\n\n\n\n\n\n\n\n\nIf we want to visualize the point in its context (in this case, in the context of the ‚Äústandard‚Äù Cartesian \\(xy\\)-plane), we can turn to ggplot2, the Tidyverse data-visualization library, which will allow us to show the point within the broader \\(xy\\)-plane:\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nmy_point |&gt; ggplot() +\n  geom_sf() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nMuch better! We can now see, using the information along the \\(x\\) and \\(y\\) axes, that this sfg object my_point specifically represents a POINT object with \\(x\\) coordinate of 30 and a \\(y\\) coordinate of 10!\n\n\nCreating LINESTRING Objects with st_linestring()\nNext up is LINESTRING, which sf allows us to create using the constructor function st_linestring(). The example in the Wikipedia article in this case looks like:\n\n\n\n\n\n\n\n\nLINESTRING\n\nLINESTRING (30 10, 10 30, 40 40)\n\n\n\nAnd from the WKT string on the right side, we can see how representing this type of geometry is going to require a slightly more complex data structure than the more simple vector we used above to represent the two coordinates of a single POINT.\nIn this case, looking at the sf documentation, we can see that the st_linestring() constructor function requires a matrix, a datatype we haven‚Äôt seen yet but which actually builds straightforwardly on top of the vector type that we have seen!\nThe matrix datatype in R is, I think, easiest to understand by looking at an example. Let‚Äôs say we want to represent the matrix\n\\[\n\\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}\n\\]\nwithin R. Above we saw how, to represent a vector like \\((1, 2)\\), we used the c() function in R: c(1, 2). To represent a matrix, it turns out that we will still use this c() function! The syntax of matrix takes a vector as input, then transforms it into matrix form as follows:\n\nFirst we use c() to write out all elements of the matrix, row by row, as a single ‚Äúflat‚Äù vector\nThen we tell R how it should ‚Äúsplit‚Äù this flat vector into rows and columns\n\nSo, to represent the example matrix \\(A\\) given above, in R, we implement these two steps as follows:\n\n\nCode\n# First we use c() to construct a *vector* containing all\n# elements of the matrix in a single row (a \"flattened\" representation)\nflattened_matrix &lt;- c(1, 2, 3, 4, 5, 6)\nflattened_matrix\n\n\n[1] 1 2 3 4 5 6\n\n\nCode\n# Then we provide this \"flattened\" vector to the matrix()\n# constructor function, along with instructions for R on how\n# to split it into rows and columns\nexample_matrix &lt;- matrix(\n  flattened_matrix,\n  byrow = TRUE,\n  nrow=2, ncol=3\n)\nexample_matrix\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\n\nAnd there‚Äôs our example matrix from above, now encoded as an object of type matrix in R!\nSo, returning to our example from the Wikipedia article, since this LINESTRING consists of 3 coordinates connected by straight lines, we now need to construct a matrix with 3 rows, where each row contains the coordinates of one point in the LINESTRING. We can do this as follows, using the same syntax as in the previous code cell:\n\n\nCode\nmy_linestring_matrix_flat &lt;- c(30, 10, 10, 30, 40, 40)\nmy_linestring_matrix &lt;- matrix(\n  my_linestring_matrix_flat,\n  byrow = TRUE,\n  nrow=3, ncol=2\n)\nmy_linestring_matrix\n\n\n     [,1] [,2]\n[1,]   30   10\n[2,]   10   30\n[3,]   40   40\n\n\nAnd now we have a matrix object in the form that sf requires for constructing an st_linestring object! All that‚Äôs left is to plug this linestring_matrix object into the st_linestring() constructor function, as follows:\n\n\nCode\nmy_linestring_sf &lt;- st_linestring(my_linestring_matrix)\nmy_linestring_sf\n\n\nLINESTRING (30 10, 10 30, 40 40)\n\n\nAnd we‚Äôve successfully encoded the Wikipedia example into the sf library‚Äôs LINESTRING representation! We can plot it quickly using plot() as we did earlier with the st_point object:\n\n\nCode\nplot(my_linestring_sf)\n\n\n\n\n\n\n\n\n\nAnd obtain a more interesting plot, showing our coordinate system, using ggplot2:\n\n\nCode\nmy_linestring_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nCreating Simple POLYGON Objects with st_polygon()\nThis is the final boss! And, just as the increased complexity from POINT to LINESTRING required us to move from vectors to matrices, here the increased complexity from LINESTRING to POLYGON requires us to move from matrices to lists, as can be seen once again in the sf documentation.\nTaking our example one final time from the Wikipedia article on WKT, their first example POLYGON (the ‚Äúsimple‚Äù POLYGON, without any holes) looks as follows:\n\n\n\n\n\n\n\n\nPOLYGON\n\nPOLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))\n\n\n\nSo, as discussed earlier in class, a simple POLYGON like this (without any holes) is actually quite similar to a LINESTRING: looking solely at the coordinates, we can see how a (simple) POLYGON is defined using just a series of connected points, as in a LINESTRING, with the additional constraint that the last point in the series is the same as the first point. So, we already know how to construct the data structure (a matrix) needed for defining a LINESTRING‚Ä¶ let‚Äôs start with that here:\n\n\nCode\nmy_polygon_flat &lt;- c(30, 10, 40, 40, 20, 40, 10, 20, 30, 10)\nmy_polygon_matrix &lt;- matrix(\n  my_polygon_flat,\n  byrow = TRUE,\n  nrow = 5, ncol=2\n)\nmy_polygon_matrix\n\n\n     [,1] [,2]\n[1,]   30   10\n[2,]   40   40\n[3,]   20   40\n[4,]   10   20\n[5,]   30   10\n\n\nIf we were just trying to create an st_linestring object, we could now complete the task by just plugging this matrix we created into the st_linestring() constructor function!\nBut, from the documentation we see that the st_polygon() constructor function won‚Äôt accept a matrix ‚Äì we need to provide a list instead (we‚Äôll see why in a second!). So, in this case where we have a simple POLYGON without any holes, our list is going to feel silly: it will be a list with only one element, namely, the matrix we just created!\n\n\nCode\nmy_polygon_list &lt;- list(my_polygon_matrix)\nmy_polygon_list\n\n\n[[1]]\n     [,1] [,2]\n[1,]   30   10\n[2,]   40   40\n[3,]   20   40\n[4,]   10   20\n[5,]   30   10\n\n\nAnd, we complete our task by just plugging this list object into the st_polygon() constructor function:\n\n\nCode\nmy_polygon_sf &lt;- st_polygon(my_polygon_list)\nmy_polygon_sf\n\n\nPOLYGON ((30 10, 40 40, 20 40, 10 20, 30 10))\n\n\nAnd plotting in two ways like before:\n\n\nCode\nplot(my_polygon_sf)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmy_polygon_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nCreating Complex POLYGON Objects (POLYGONs with Holes) with st_polygon()\n‚Ä¶So, why exactly does st_polygon() require a list, when all we did in the last section was to ‚Äúwrap‚Äù our one matrix object into this list, as its only element? The answer comes from the fact that we need to represent complex POLYGONs as well: POLYGONs with holes in them! And, to achieve this, st_polygon() requires a list and then interprets all elements after the first element as describing the holes within the POLYGON!\nSo, as our final hint for this question, let‚Äôs take the complex POLYGON example from the Wikipedia article:\n\n\n\n\n\n\n\n\nPOLYGON\n\nPOLYGON ((35 10, 45 45, 15 40, 10 20, 35 10),(20 30, 35 35, 30 20, 20 30))\n\n\n\nAnd let‚Äôs now set up our list so that its first element represents the coordinates of the outer boundary of this POLYGON (in counterclockwise order), while its second element represents the boundary of the hole (in reversed, clockwise order):\n\n\nCode\nouter_flat &lt;- c(35,10,45,45,15,40,10,20,35,10)\nouter_matrix &lt;- matrix(\n  outer_flat,\n  byrow = TRUE,\n  nrow = 5, ncol=2\n)\nouter_matrix\n\n\n     [,1] [,2]\n[1,]   35   10\n[2,]   45   45\n[3,]   15   40\n[4,]   10   20\n[5,]   35   10\n\n\nCode\ninner_flat &lt;- c(20,30,35,35,30,20,20,30)\ninner_matrix &lt;- matrix(\n  inner_flat,\n  byrow = TRUE,\n  nrow=4, ncol=2\n)\ninner_matrix\n\n\n     [,1] [,2]\n[1,]   20   30\n[2,]   35   35\n[3,]   30   20\n[4,]   20   30\n\n\nAnd now we can finally understand why the st_polygon() constructor function requires a list argument: it‚Äôs what now allows us to ‚Äúencode‚Äù this POLYGON-with-hole within sf!\n\n\nCode\ncomplex_poly_list &lt;- list(outer_matrix, inner_matrix)\ncomplex_poly_list\n\n\n[[1]]\n     [,1] [,2]\n[1,]   35   10\n[2,]   45   45\n[3,]   15   40\n[4,]   10   20\n[5,]   35   10\n\n[[2]]\n     [,1] [,2]\n[1,]   20   30\n[2,]   35   35\n[3,]   30   20\n[4,]   20   30\n\n\nCode\ncomplex_poly_sf &lt;- st_polygon(complex_poly_list)\ncomplex_poly_sf\n\n\nPOLYGON ((35 10, 45 45, 15 40, 10 20, 35 10), (20 30, 35 35, 30 20, 20 30))\n\n\nAnd we can plot in two ways as usual:\n\n\nCode\nplot(complex_poly_sf)\n\n\n\n\n\n\n\n\n\n\n\nCode\ncomplex_poly_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic()"
  },
  {
    "objectID": "writeups/hw1-guide/index.html#question-3-plotting-raster-data-with-tidyterra",
    "href": "writeups/hw1-guide/index.html#question-3-plotting-raster-data-with-tidyterra",
    "title": "HW1 Hints",
    "section": "Question 3: Plotting Raster Data with tidyterra",
    "text": "Question 3: Plotting Raster Data with tidyterra\nThis is even more important than the Question 2 help, only because, I failed to provide any examples using tidyterra in the slides this year üò®\nSo, here is an example, showing especially how important it is to use the interpolate=FALSE option to prevent tidyterra from ‚Äúsmoothing‚Äù the individual pixels in your plot together into a hideous blob.\nFirst let‚Äôs use terra to construct a \\(2 \\times 3\\) raster grid (similar to Gridtopia, but, now as a rectangle rather than a square!)\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(terra) |&gt; suppressPackageStartupMessages()\nlibrary(tidyterra) |&gt; suppressPackageStartupMessages()\nrectville &lt;- terra::rast(\n  nrows = 2, ncols = 3,\n  xmin = 0, xmax = 2, ymin = 0, ymax = 1,\n  vals = sample(1:6)\n)\nplot(rectville)\ntext(\n  rectville,\n  halo=TRUE, hc=\"black\", col=\"white\", hw=0.2\n)\n\n\n\n\n\n\n\n\n\nAnd, like we‚Äôve seen a few times now, we should try to use ggplot2 rather than the plot() function from Base R since the ggplot2 library provides a full-on Grammar of Graphics (GG) engine (plot() makes a lot of assumptions and guesses as to how we want things displayed, whereas ggplot2 allows us to control each facet of the plot in a systematic way):\n\n\nCode\nrectville |&gt; ggplot2::ggplot() +\n  tidyterra::geom_spatraster(data=rectville) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::theme_classic()\n\n\n\n\n\n\n\n\n\nNotice however that, in this case, since we only have one piece of information (one number) for each cell in the raster grid, ggplot2 fills in the colors of the grid using the viridis color scale discussed in class.\nIn GIS contexts, when we are working with and plotting raster data, we almost always have more than one piece of information for each cell. For example, if we‚Äôre working with remote sensing data like photos taken from an airplane or satellite, we will in fact have three values for each pixel: the red intensity, the green intensity, and the blue intensity.\nSince this three-number RGB representation of pixels is so common (in general, since it‚Äôs how the pixels on our computer screens show color, but also in GIS specifically), tidyterra provides a special version of the geom_spatraster() function we used above solely for this case: geom_spatraster_rgb().\nIf we look at the documentation for this function, we can see that in fact the only required argument we need to provide is the data argument. Every other argument to this function (including interpolate, which we‚Äôll see below) is optional, so that if we don‚Äôt provide a specific value when we call geom_spatraster_rgb(), the library will use the default values specified in the documentation.\nSo, let‚Äôs now construct a new RGB-ified version of rectville, this time with three layers instead of just one, where the values in each layer will correspond to red, blue, and green intensity respectively:\n\n\nCode\nrgbville &lt;- terra::rast(\n  nrows = 2, ncols = 3,\n  xmin = 0, xmax = 2, ymin = 0, ymax = 1,\n  vals = sample(1:255, 6)\n) |&gt; mutate(\n  lyr.2 = sample(1:255, 6),\n  lyr.3 = sample(1:255, 6)\n)\nrgbville |&gt; ggplot2::ggplot() +\n  tidyterra::geom_spatraster_rgb(\n    data=rgbville\n  ) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::theme_classic()\n\n\n\n\n\n\n\n\n\nWhat happened?!? If we squint when looking at this plot, we can see how it‚Äôs almost plotting the cells of rgbville as six discrete colors, but that at the edges the colors of the cells are blending into one another‚Ä¶ This, it turns out, is the expected behavior of geom_spatraster_rgb() in this case!\nIt has to do with the fact that the default value for the interpolate argument is TRUE. Since this function is usually used to plot photos taken from airplanes or satellites, the individual pixels in the photo are usually treated as essentially ‚Äúapproximations‚Äù of the ‚Äútrue‚Äù even-higher-resolution thing that we‚Äôre taking a photo of (like, down to the atomic level eventually). And so, in this scenario, smoothly drawing each pixel so that their colors gradually transition into one another turns out to make a much smoother and more natural/realistic-looking overall picture, since the ‚Äúborders‚Äù between one pixel and the next don‚Äôt actually exist in real life!\nWith all that said, in this special case where we‚Äôve constructed the raster grid from scratch, and we just want to see each color individually without this cross-grid ‚Äúblending‚Äù, we should instead override the default TRUE value for the interpolate parameter:\n\n\nCode\nrgbville |&gt; ggplot2::ggplot() +\n  tidyterra::geom_spatraster_rgb(\n    data=rgbville,\n    interpolate=FALSE\n  ) +\n  ggplot2::scale_fill_viridis_c() +\n  ggplot2::theme_classic()\n\n\n\n\n\n\n\n\n\nAnd we‚Äôve successfully plotted the six cells of our raster grid as intended! Note how now, when we use geom_spatraster_rgb() instead of geom_spatraster(), there is no legend in the generated image. This is again on purpose! Whereas with geom_spatraster() ggplot2 needed to tell the viewer of the image how exactly it chose the different colors for the different cells, here we have manually specified each color as a triple of \\((r, g, b)\\) values. This again makes sense if we think about the ‚Äústandard‚Äù case of photos taken from an airplane or satellite: we don‚Äôt need a legend telling us the RGB values for each pixel, since, we can just look at the pixels with our eyes and put them together into a full-on picture of the landscape we‚Äôve photographed!"
  },
  {
    "objectID": "writeups/why-poisson/index.html",
    "href": "writeups/why-poisson/index.html",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "",
    "text": "I fumbled this concept towards the end of the Week 8 lecture, since I was rushing to try and get to intensity functions and pair correlation functions. As we know, this kind of guilt will weigh on Jeff‚Äôs mind until he creates a writeup where he can slow down and walk through it with the proper attention to detail‚Ä¶ so here we are!\nThe reason we worry so much about the ‚Äúproper‚Äù null model to use when we want to test spatial hypotheses (and the reason for creating a full-on Writeup about it), is that certain intuitions we may have developed in our standard (non-spatial) statistics courses fail to generalize easily to our current two-dimensional spatial setting! So, let‚Äôs:\n\nStart by looking at what may be in our heads from these earlier classes when we hear the term ‚Äúnull model‚Äù (Part 1), then\nDescribe the trouble we run into if we try to haphazardly take the one-dimensional statistical notion of independent and identically distributed (i.i.d.) random variables and just ‚Äúlift‚Äù it into two dimensions (Part 2),\nStart more slowly, building up from the simplest possible point process to see where exactly this na√Øve approach goes wrong (Part 3, and finally\nConclude with the less-rushed version of what I said in class: that the Poisson Point Process model ‚Äúsaves us‚Äù by avoiding these troubles (Part 4)"
  },
  {
    "objectID": "writeups/why-poisson/index.html#overview",
    "href": "writeups/why-poisson/index.html#overview",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "",
    "text": "I fumbled this concept towards the end of the Week 8 lecture, since I was rushing to try and get to intensity functions and pair correlation functions. As we know, this kind of guilt will weigh on Jeff‚Äôs mind until he creates a writeup where he can slow down and walk through it with the proper attention to detail‚Ä¶ so here we are!\nThe reason we worry so much about the ‚Äúproper‚Äù null model to use when we want to test spatial hypotheses (and the reason for creating a full-on Writeup about it), is that certain intuitions we may have developed in our standard (non-spatial) statistics courses fail to generalize easily to our current two-dimensional spatial setting! So, let‚Äôs:\n\nStart by looking at what may be in our heads from these earlier classes when we hear the term ‚Äúnull model‚Äù (Part 1), then\nDescribe the trouble we run into if we try to haphazardly take the one-dimensional statistical notion of independent and identically distributed (i.i.d.) random variables and just ‚Äúlift‚Äù it into two dimensions (Part 2),\nStart more slowly, building up from the simplest possible point process to see where exactly this na√Øve approach goes wrong (Part 3, and finally\nConclude with the less-rushed version of what I said in class: that the Poisson Point Process model ‚Äúsaves us‚Äù by avoiding these troubles (Part 4)"
  },
  {
    "objectID": "writeups/why-poisson/index.html#part-1-the-null-model-from-introductory-statistics",
    "href": "writeups/why-poisson/index.html#part-1-the-null-model-from-introductory-statistics",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "Part 1: The Null Model from Introductory Statistics",
    "text": "Part 1: The Null Model from Introductory Statistics\nIn standard ‚Äúone-dimensional‚Äù statistics, when we start building up our conceptual/methodological toolbox towards the goal of developing a set of statistical hypothesis tests, we usually start with the notion of a collection \\(X_1, X_2, \\ldots, X_n\\) of \\(N\\) independent and identically distributed (i.i.d.) Random Variables.\nThe reason this odd term ‚Äúindependent and identically distributed‚Äù is so important is because is exactly this i.i.d. property that underlies the two key theorems of statistical sampling theory: the Law of Large Numbers (LLN) and the Central Limit Theorem (CLT).\nSay we have a goal of figuring out the average height of Georgetown students, in centimeters. We don‚Äôt have any way to instantaneously ‚Äúdivine‚Äù this information from out of nowhere, however, so instead we decide to start sampling students from campus. We let \\(X_1\\) be the Random Variable corresponding to the height of the first person we sample, \\(X_2\\) be the Random Variable corresponding to the height of the second person we sample, and so on, up to \\(X_n\\), the Random Variable corresponding to the height of the final person we sample.\n\nWe make the assumption that the Random Variables in this series \\(\\{X_1, X_2, \\ldots, X_n\\}\\) are independent, since we believe that learning the height of any one person doesn‚Äôt give us any information about the height of other people.\nWe make the assumption that the Random Variables in this series \\(\\{X_1, X_2, \\ldots, X_n\\}\\) are identically distributed because we believe there is some underlying distribution (perhaps a Normal distribution) describing the population of Georgetown students, and that each of our samples is a single draw from this (assumed) underlying population distribution.\n\nThe second assumption (that \\(\\{X_1, X_2, \\ldots, X_n\\}\\) are identically distributed) is super important for the wording of the LLN and CLT. To see exactly why these theorems are useful, we‚Äôll add one more piece of information to this assumption, namely, that the underlying population distribution we‚Äôve assumed has some well-defined mean \\(\\mu\\)1. We actually don‚Äôt need to assume anything more than this, but for the sake of making a picture let‚Äôs also assume a well-defined standard deviation \\(\\sigma\\).\nThese assumptions now allow us to visualize the population distribution of height, the distribution of the heights of all possible Georgetown students in the past, present, and future:\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(latex2exp) |&gt; suppressPackageStartupMessages()\nset.seed(6807)\nmu_label &lt;- TeX(\"$\\\\mu$\")\ncb_palette &lt;- c(\n  \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\",\n  \"#0072B2\", \"#D55E00\", \"#CC79A7\"\n)\nheight_dist &lt;- function(x) dnorm(x, mean = 170, sd = 10)\nxlim_df &lt;- tibble(x=c(135, 205))\nbase_pop_plot &lt;- xlim_df |&gt; ggplot(aes(x=x)) +\n  geom_area(\n    stat = \"function\",\n    fun = height_dist,\n    color = \"black\",\n    fill = cb_palette[1],\n    alpha = 0.75\n  ) +\n  theme_classic(base_size=16) +\n  theme(plot.title = element_text(hjust=0.5)) +\n  labs(\n    y=\"Density\"\n  )\nbase_pop_plot +\n  scale_x_continuous(\n    breaks=seq(from=140, to=200, by=10),\n    labels=c(\"Œº-3œÉ\",\"Œº-2œÉ\",\"Œº-œÉ\",\"Œº\",\"Œº+œÉ\",\"Œº+2œÉ\",\"Œº+3œÉ\")\n  ) +\n  labs(\n    title=\"Hypothesized Population Distribution: N(Œº,œÉ)\"\n  )\n\n\n\n\n\n\n\n\n\nWe won‚Äôt have any way of knowing the actual values \\(\\mu\\) and \\(\\sigma\\) in practice (if we did, we wouldn‚Äôt need to use this whoe sampling thing in the first place), but to make our visualization a little more concrete, let‚Äôs assume that this abstract population mean height is \\(\\mu = 170\\text{cm}\\) and population mean SD is \\(\\sigma = 10\\text{cm}\\). Then the above visualization becomes:\n\n\nCode\n(pop_plot &lt;- base_pop_plot +\n  labs(\n    title=\"Hypothesized Population Distribution: N(170, 10)\"\n  )\n)\n\n\n\n\n\n\n\n\n\nIf our goal is to estimate this now-assumed underling \\(\\mu\\) value, we can frame the LLN and CLT for our sample of size \\(N\\), \\(\\{X_1, X_2, \\ldots, X_n\\}\\) as follows. Consider the mean of these i.i.d. RVs, \\[\n\\overline{X}_{N} = \\frac{1}{N}(X_1 + X_2 + \\cdots + X_n).\n\\]\nNotice how this RV \\(\\overline{X}_N\\) is itself a Random Variable, with some distribution! We can actually use R again to visualize this separate distribution, of the number we get when we compute the mean of \\(N\\) samples:\n\n\nCode\nsample_from_pop &lt;- function(N = 5) {\n  return(rnorm(n=N, mean=170, sd=10))\n}\nfor (i in 1:3) {\n  cur_sample &lt;- sample_from_pop()\n  sample_str &lt;- paste0(round(cur_sample, 2), collapse=\", \")\n  writeLines(paste0(\"Sample #\",i,\": \",sample_str))\n  cur_sample_mean &lt;- mean(cur_sample)\n  writeLines(paste0(\"Mean = \",round(cur_sample_mean,2)))\n}\n\n\nSample #1: 162.51, 151.24, 166.77, 163.45, 161.84\nMean = 161.16\nSample #2: 175.28, 165.1, 182.1, 168.89, 179.84\nMean = 174.24\nSample #3: 159.99, 164.23, 159.36, 163.04, 167.38\nMean = 162.8\n\n\nAnd if we repeat this 999 times, we‚Äôll get 999 different sample means: that is, 999 different realized values of \\(\\overline{X}_N\\) (here we display only the first 100 of these realized values, for brevity):\n\n\nCode\nsample_means &lt;- replicate(999, mean(sample_from_pop()))\nsample_means[1:100]\n\n\n  [1] 178.7393 171.1233 170.8265 173.7785 172.8961 173.4400 170.2095 174.4979\n  [9] 169.0981 167.7625 166.0616 171.3933 171.1436 165.5095 172.4817 171.9988\n [17] 170.2733 172.0060 172.4475 167.4049 164.9856 164.4329 170.5725 164.8725\n [25] 176.3991 165.4975 172.3969 179.7432 167.3862 169.4150 165.4437 173.4964\n [33] 163.7278 171.0691 168.2547 178.5336 172.8489 170.5232 160.4038 169.8794\n [41] 174.5240 172.5725 171.4840 164.3483 172.5593 165.5066 171.2156 177.5725\n [49] 171.8485 180.4162 180.8225 166.3356 169.2979 169.1465 165.2127 173.3863\n [57] 173.8254 170.3274 171.5981 171.5182 159.0368 169.3380 167.0772 166.0056\n [65] 173.4332 164.0346 176.2426 171.7977 173.2400 169.3358 167.2296 161.8195\n [73] 169.7620 169.8450 163.3599 167.1167 167.6754 165.3986 159.8650 166.5547\n [81] 165.6406 163.0572 170.4247 173.8195 175.9887 173.3378 163.3578 165.9197\n [89] 159.6700 169.7303 172.2333 171.3272 165.2502 165.3463 171.4613 167.9019\n [97] 169.6259 174.1383 169.7894 166.5657\n\n\nIf we plot the distribution of these values, we get a different distribution from the above. This time, it‚Äôs a sampling distribution! It‚Äôs a distribution of the averages we get when we sample from the population distribution:\n\n\nCode\nsample_mean_df &lt;- tibble(x=sample_means)\nsample_plot &lt;- sample_mean_df |&gt; ggplot(aes(x=x)) +\n  geom_histogram(\n    binwidth=0.5,\n    fill=cb_palette[2],\n    alpha=0.75\n  ) +\n  theme_classic(base_size=15) +\n  labs(title=\"Distribution of 999 Means from Samples of Size N = 5\") +\n  theme(plot.title = element_text(hjust=0.5))\nsample_plot\n\n\n\n\n\n\n\n\n\nBy overlaying this sampling distribution on top of the population distribution (though remember, again, that in the real world we‚Äôre never going to be able to discover this ‚Äútrue‚Äù population distribution), we can start to see what‚Äôs going on:\n\n\nCode\nggplot() +\n  geom_area(\n    data = xlim_df,\n    mapping = aes(x=x),\n    stat = \"function\",\n    fun = height_dist,\n    color = \"black\",\n    fill = cb_palette[1],\n    alpha = 0.75\n  ) +\n  geom_histogram(\n    data = sample_mean_df,\n    mapping = aes(x=x),\n    stat = \"density\",\n    binwidth = 0.5,\n    fill = cb_palette[2],\n    alpha = 0.75\n  ) +\n  theme_classic(base_size=15) +\n  labs(title=\"Sampling (Blue) vs. Population (Orange) Dists (N = 5)\")\n\n\n\n\n\n\n\n\n\nThe values we‚Äôre getting for the sample mean, in blue here, vary around the true mean that we‚Äôre trying to estimate. And, intuitively, if we have the resources to take bigger samples (e.g., more time to ask more than \\(N = 5\\) people), this should give us even more accurate estimates of the population mean, which is what we indeed find in our simulation:\n\n\nCode\nsample_sizes &lt;- c(5, 30, 100, 500)\nsample_means_df &lt;- tibble(N = numeric(), xbar=numeric())\nfor (cur_sample_size in sample_sizes) {\n  cur_sample_means &lt;- replicate(\n    1000,\n    sample_from_pop(cur_sample_size) |&gt; mean()\n  )\n  cur_sm_df &lt;- tibble(\n    N = cur_sample_size,\n    xbar=cur_sample_means\n  )\n  sample_means_df &lt;- bind_rows(sample_means_df, cur_sm_df)\n}\nsample_means_df |&gt; head()\n\n\n\n\n\n\nN\nxbar\n\n\n\n\n5\n179.5180\n\n\n5\n169.3783\n\n\n5\n177.2945\n\n\n5\n179.8101\n\n\n5\n167.2210\n\n\n5\n167.8652\n\n\n\n\n\n\nCode\nsample_means_df |&gt; ggplot() +\n  geom_area(\n    data = xlim_df,\n    mapping = aes(x=x),\n    stat = \"function\",\n    fun = height_dist,\n    color = \"black\",\n    fill = cb_palette[1],\n    alpha = 0.75\n  ) +\n  geom_histogram(\n    data = sample_means_df,\n    mapping = aes(x=xbar),\n    stat = \"density\",\n    binwidth = 0.5,\n    alpha = 0.5,\n    fill=cb_palette[2]\n  ) +\n  facet_wrap(vars(N), nrow=2, ncol=2, scales=\"free_y\") +\n  theme_classic() +\n  labs(title=\"Sampling (Blue) vs. Population (Orange) Distributions for Increasing N\") +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\nThe two key theorems of sampling theory therefore describe (along with formal mathematical proofs) what we can see intuitively from the four plots above: that is, what happens to this RV as \\(N\\) gets bigger and bigger (goes towards \\(\\infty\\)):\n\nThe Law of Large Numbers tells us that the middle of the blue sampling distribution will converge to the population mean \\(\\mu\\).\n\nIt says in essence that we can pick any really small value \\(\\varepsilon\\), and then, regardless of what particular small value we pick, the probability that \\(\\overline{X}\\) is more than \\(\\varepsilon\\) away from the (assumed) ‚Äútrue‚Äù mean value \\(\\mu\\) goes to 0 as we take more and more samples: \\(\\Pr\\left(|\\overline{X} - \\mu| &gt; \\varepsilon\\right) \\rightarrow 0\\) as \\(N \\rightarrow \\infty\\).\n\nThe Central Limit Theorem gives us more specifics about the shape of the blue sampling distribution, and about how quickly the convergence guaranteed by the LLN will proceed.\n\nIt says that the blue sampling distribution will specifically be a Normal distribution, whose mean will be \\(\\mu\\) and whose standard deviation will be \\(\\sigma / \\sqrt{N}\\). In symbols: \\(\\overline{X}_{N} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{N}}\\right)\\). The presence of \\(N\\) in the standard deviation is why we see the blue sampling distribution getting thinner and thinner above: as we raise \\(N\\), \\(\\sigma\\) stays the same but \\(\\sqrt{N}\\) gets bigger and bigger, which makes the overall standard deviation term get smaller and smaller!\n\n\nHaving built up to these two key theorems, we can now perform statistical hypothesis testing! Because, we can:\n\nTake any specific sample we happen to have, \\(\\{X_1 = x_1, X_2 = x_2, \\ldots, X_n = x_n\\}\\), and\nCompare it to the expected shape of the sampling distribution under some hypothesis!\n\nContinuing our above example, if we think that the ‚Äútrue‚Äù mean height of Georgetown students is \\(\\mu = 170\\text{cm}\\), we can take a sample of \\(N\\) Georgetown students and compare the mean height value of this particular sample with the distribution of mean height values that a population distribution with \\(\\mu = 170\\text{cm}\\) would generate.\nFor example, if we take a sample of \\(N = 30\\) Georgetown students, and find that the mean height of these 30 students is 160cm, we can ‚Äútest‚Äù how likely it is that this particular mean height value would arise relative to our working hypothesis that the ‚Äútrue‚Äù population mean is \\(\\mu = 170\\text{cm}\\)‚Ä¶ just take the blue distribution from the \\(N = 30\\) plot above, and check where 160cm falls relative to this distribution! Here‚Äôs what this looks like:\n\n\nCode\nn30_df &lt;- sample_means_df |&gt;\n  filter(N == 30)\nn30_df |&gt; ggplot() +\n  geom_histogram(\n    mapping = aes(x = xbar),\n    fill = cb_palette[2],\n    binwidth = 0.5\n  ) +\n  geom_vline(\n    xintercept = 160,\n    linetype = \"dashed\",\n    linewidth = 0.75,\n    color = cb_palette[3]\n  ) +\n  theme_classic(base_size = 15) +\n  labs(title=\"Observed Mean (160cm) vs. 1000 Simulated Means\") +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\nThe vertical (dashed) green line in this plot is the mean we actually obtained from our sample of 30 students. The blue histogram represents all of the means we got when we simulated taking a sample of size \\(N = 30\\) from the hypothesized population distribution \\(\\mathcal{N}(170, 10)\\)‚Ä¶ and what it tells us is that the mean we actually observed is not very likely to arise from our hypothesized population‚Ä¶ Meaning, in turn, that we decrease our confidence in our hypothesis, relative to whatever our confidence was before we collected this sample!"
  },
  {
    "objectID": "writeups/why-poisson/index.html#part-2-na√Øvely-generalizing-to-the-spatial-statistical-setting",
    "href": "writeups/why-poisson/index.html#part-2-na√Øvely-generalizing-to-the-spatial-statistical-setting",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "Part 2: ‚ÄúNa√Øvely‚Äù Generalizing to the Spatial-Statistical Setting",
    "text": "Part 2: ‚ÄúNa√Øvely‚Äù Generalizing to the Spatial-Statistical Setting\nThe next idea is that, if we want to statistically test hypotheses about observed spatial distributions, we‚Äôd like an equivalent to the above normal distribution for the two-dimensional spatial settings (Random Fields) we analyze in this course!\nIn the same way that we just tested our observed mean of \\(160\\text{cm}\\) against the range of means we would expect to see under some hypothesis, we‚Äôd like to test observed point patterns against some range of expected point patterns under some hypothesis. In this case, rather than a hypothesis about the mean \\(\\mu\\), let‚Äôs start with a hypothesis about the first spatial statistic we learned in Week 7, namely, Moran‚Äôs \\(I\\)! Let‚Äôs say we think there is a propensity for points to cluster together very tightly, so that although the specific cluster patterns may vary slightly from year to year, we think that the underlying population autocorrelation \\(I\\) is close to \\(1.0\\).\nThe reason for ‚Äúoverthinking‚Äù the Poisson process at this point is, we‚Äôre going to need to think about how we might falsify this hypothesis2.\nLike we did above for the simpler ‚Äúone-dimensional‚Äù hypothesis about the population mean height, we‚Äôll subject our hypothesis \\(\\mathcal{H} = [I \\approx 1]\\) to falsification testing by developing a ‚Äúnull model‚Äù: a model of what a world where our hypothesis is wrong would look like.\nWith this ‚Äúnull model‚Äù in hand, we can then simulate what not-high spatial autocorrelation would look like within the same spatial domain. In fact, since the null model is a generative model, we can use it to generate as many worlds-where-my-hypothesis-is-false as we‚Äôd like! Above we arbitrarily chose to stop after we had generated 999 such worlds, and we‚Äôll do the same for most examples in this course.\nOnce we have these 999 simulated null-world patterns, we can compute a Moran‚Äôs \\(I\\) value for each, producing \\(\\{I_1, I_2, \\ldots, I_{999}\\}\\), which we call the ‚Äúnull distribution‚Äù of our ‚Äútest statistic‚Äù \\(I\\). We then compare \\(I_{\\text{obs}}\\) with these 999 simulated \\(I\\) values:\n\nIf we find that the observed autocorrelation value \\(I_{\\text{obs}}\\), calculated with respect to the point pattern we actually saw, is sufficiently different from the range of \\(I\\) values \\(\\{I_1, I_2, \\ldots, I_{999}\\)} that we calculated from the simulated patterns, we should3 increase our confidence in the idea that the underlying spatial pattern is indeed one with high autocorrelation (relative to our confidence before carrying out this test)\nIf we find that the observed autocorrelation value \\(I_{\\text{obs}}\\), calculated with respect to the point pattern we actually saw, is not very different from the range of \\(I\\) values \\(\\{I_1, I_2, \\ldots, I_{999}\\)} that we calculated from the simulated patterns, we should decrease our confidence in the idea that the underlying spatial pattern is indeed one with high autocorrelation (relative to our confidence before carrying out this test)\n\nSo, if we observed (say) \\(N_{\\text{obs}} = 60\\) points in some region, and we‚Äôre hypothesizing that the underlying micro-level process generating these points is one with the property of high autocorrelation‚Ä¶ our instinct may very reasonably be: ‚ÄúCool! Let‚Äôs go generate 999 point patterns, each with \\(N = 60\\) points spread randomly across the same region!‚Äù\nThere is, unfortunately, a big red flag inherent in this approach that we need to train our brains to notice. The issue with this approach, that makes it inappropriate as a null model for most spatial data analyses, is extremely subtle but extremely important as we move forward with our spatial data analysis unit! It boils down to where exactly we think the ‚Äúrandomness‚Äù is happening in the ‚Äúrandom spatial process‚Äù.\nTo move from the above intuitive-but-deficient approach to the notion of Complete Spatial Randomness (CSR) that is the ‚Äústandard‚Äù null model for spatial data, let‚Äôs follow Sections 5.2 and 5.3 (pages 128 to 137) of Baddeley, Rubak, and Turner (2015) by moving slowly, starting from the simplest possible point process."
  },
  {
    "objectID": "writeups/why-poisson/index.html#part-3-what-kinds-of-spatial-randomness-do-we-want-to-model",
    "href": "writeups/why-poisson/index.html#part-3-what-kinds-of-spatial-randomness-do-we-want-to-model",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "Part 3: What Kind(s) of Spatial Randomness Do We Want to Model?",
    "text": "Part 3: What Kind(s) of Spatial Randomness Do We Want to Model?\n\nModel üòê: Uniform Point Process\nTo start, consider the simplest possible point process we can imagine: just taking some 2D shape like a (unit) square and placing a single point randomly within it. If we place our unit square in the first quadrant of the Cartesian plane, then to generate a random point \\(\\mathbf{s}_0\\) within this square we literally just need to generate a random \\(x\\) coordinate \\(X \\sim \\mathcal{U}[0,1]\\) and a random \\(y\\) coordinate \\(Y \\sim \\mathcal{U}[0,1]\\), as in the following plot:\n\n\nCode\nlibrary(latex2exp)\nset.seed(6862)\nx_coords &lt;- runif(n = 4, min = 0, max = 1) |&gt;\n  round(2)\ny_coords &lt;- runif(n = 4, min = 0, max = 1) |&gt;\n  round(2)\nrand_point_df &lt;- tibble::tibble(\n  index=1:4,\n  x=x_coords,\n  y=y_coords\n)\nrand_point_df &lt;- rand_point_df |&gt; mutate(\n  point_tex_str = paste0(\n    '$s_',\n    index,\n    '$'\n  ),\n  point_prob_tex_str = paste0(\n    '$\\\\Pr(s=s_',\n    index,\n    ') = 0$'\n  ),\n  label_tex_str = paste0(\n    point_tex_str,\n    ' = (',\n    x,\n    \", \",\n    y,\n    \")\"\n  )\n)\nrand_point_df$point_tex &lt;- as.list(TeX(rand_point_df$point_tex_str))\nrand_point_df$point_prob_tex &lt;- as.list(TeX(rand_point_df$point_prob_tex_str))\nrand_point_df |&gt; select(index, x, y, point_tex_str)\n\n\n\n\n\n\nindex\nx\ny\npoint_tex_str\n\n\n\n\n1\n0.54\n0.45\n\\(s_1\\)\n\n\n2\n0.27\n0.26\n\\(s_2\\)\n\n\n3\n0.28\n0.85\n\\(s_3\\)\n\n\n4\n0.75\n0.19\n\\(s_4\\)\n\n\n\n\n\n\n\n\nCode\nappender &lt;- function(s) {\n  return(TeX(s))\n}\ntex_labeller = as_labeller(\n  appender,\n  default = label_parsed\n)\nbase_point_plot &lt;- rand_point_df |&gt;\n  ggplot(aes(x=x, y=y)) +\n  # xlim(0, 1) + ylim(0, 1) +\n  expand_limits(\n    x=c(-0.05, 1.05),\n    y=c(-0.05, 1.05)\n  ) +\n  scale_x_continuous(\n    breaks=c(0, 0.5, 1.0),\n    labels=c(0, 0.5, 1.0)\n  ) +\n  scale_y_continuous(\n    breaks=c(0, 0.5, 1.0),\n    labels=c(0, 0.5, 1.0)\n  ) +\n  theme_classic(base_size=15) +\n  coord_equal() +\n  theme(plot.title=element_text(hjust=0.5))\nbase_point_plot +\n  geom_point(size=2.5) +\n  geom_segment(\n    mapping = aes(\n      yend=-Inf\n    ),\n    linewidth=0.5,\n    linetype='dashed'\n  ) +\n  geom_segment(\n    mapping = aes(\n      xend=-Inf\n    ),\n    linewidth=0.5,\n    linetype='dashed'\n  ) +\n  facet_wrap(\n    vars(label_tex_str), nrow=2, ncol=2,\n    labeller=tex_labeller,\n    # scales='free_x'\n  ) +\n  labs(title=\"Four Realizations of the Uniform Point Process\")\n\n\n\n\n\nTest\n\n\n\n\nNow, if we take this and try to generalize it into a probabilistic model, we should at minimum be able to ask a question like, what‚Äôs the probability of getting this particular point (or any other point in the unit square, but, we have a specific example above we can work with for concreteness). From previous probability and statistics courses you might know that the answer is‚Ä¶ zero! When working in continuous spaces like the unit square, we actually can‚Äôt compute probabilities for individual, infinitesimally-small points.\nSo, given this limitation, when we are working with probabilities in continuous spaces we employ a simple but powerful ‚Äútrick‚Äù that ends up unlocking the whole world of continuous probability distributions: we shift away from thinking about probabilities of points and instead think about probabilities of areas: unlike the question\n\n‚ÄúWhat is the probability that a randomly-generated point \\(\\mathbf{s}\\) in \\(D\\) appears at the exact coordinates \\((x,y) \\in D\\)?‚Äù,\n\nwhich always has the answer 0, we instead ask\n\n‚ÄúWhat is the probability that a randomly-generated point \\(\\mathbf{s}\\) in \\(D\\) appears within some area \\(A \\subseteq D\\)?‚Äù,\n\nwhich has a well-formed, meaningful answer! An answer that we can therefore use, for example, to identify subregions of \\(D\\) with higher and lower densities of points (the thing we‚Äôve been hoping to do all along, since these subregions represent areas with clusters of points!)\nFor example, the following plot illustrates how we can meaningfully ask the question\n\n‚ÄúWhat is the probability that a randomly-generated point in \\(D\\) appears in the right half of \\(D\\)?‚Äù,\n\nto obtain the answer \\(\\frac{1}{2}\\), as the proportion of the area covered by \\(A\\) to the total area of our working domain \\(D\\) (in this case, the total area of the unit square, which is 1).\n\n\nCode\nlibrary(latex2exp)\narea_label &lt;- TeX('$A \\\\subseteq D$')\narea_prob_label &lt;- TeX('$\\\\Pr(s \\\\in A) = \\\\frac{1}{2}$')\nbase_point_plot +\n  geom_rect(\n    xmin=0.5, xmax=1.0,\n    ymin=0.0, ymax=1.0,\n    fill=cb_palette[1],\n    alpha=0.5\n  ) +\n  geom_point(size=2) +\n  geom_segment(\n    x=0.5,\n    y=-Inf,\n    yend=Inf,\n    linetype=\"dashed\"\n  ) +\n  facet_wrap(\n    vars(label_tex_str), nrow=2, ncol=2,\n    labeller=tex_labeller,\n    # scales='free_x'\n  ) +\n  geom_text(\n    x=0.75, y=0.9,\n    label=area_label,\n    size=4\n  ) +\n  geom_text(\n    x=0.75, y=0.7,\n    label=area_prob_label,\n    size=2.5\n  ) +\n  geom_text(\n    # x = 0.75, y=0.3,\n    mapping = aes(label=point_prob_tex),\n    # label=point_prob_label,\n    size=3,\n    nudge_y = -0.1,\n    nudge_x = -0.1,\n    parse = TRUE\n  ) +\n  geom_text(\n    mapping = aes(label=point_tex),\n    size=4,\n    nudge_x = -0.09,\n    nudge_y = 0.06,\n    parse = TRUE\n  ) +\n  labs(title=\"Point vs. Area Probabilities\")\n\n\n\n\n\n\n\n\n\nThis notion, that we can only meaningfully ask about the probability of a point falling within some area, is key to why the next model (which is in fact the ‚Äúintuitive‚Äù model from earlier) fails as a workable null model for spatial data science.\n\n\nModel ü§î: Binomial Point Process\nNow, if we want to develop a process which can generate more than one point, a natural approach might be to just run the above process \\(N\\) times. That is, we might fix a number of points \\(N\\) in advance, and then generate coordinates for each of the \\(N\\) points uniformly within \\(D\\)‚Ä¶ Does that sound familiar? That is exactly the ‚Äúintuitive‚Äù null model we came up with above, as a way of testing the ‚Äúrandomness‚Äù (as opposed to ‚Äúclustered-ness‚Äù or ‚Äúregular-ness‚Äù) of some observed collection of points!\nThe following figure generates four point patterns using this process, with \\(N\\) set to be \\(60\\):\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\nwindow_to_sf &lt;- function(ppp_obj) {\n  window_sf &lt;- sf::st_as_sf(ppp_obj) |&gt;\n    filter(label == \"window\")\n  return(window_sf)\n}\npoints_to_sf &lt;- function(ppp_obj) {\n  points_sf &lt;- sf::st_as_sf(ppp_obj) |&gt;\n    filter(label == \"point\")\n  return(points_sf)\n}\nsim_points_to_sf &lt;- function(ppp_obj, sim_index, label_num_points=FALSE) {\n  # Extract points from ppp object\n  points_sim_sf &lt;- points_to_sf(ppp_obj)\n  # Add *sim_index* as an additional column. If\n  # label_num_points is TRUE, also add the number\n  # of generated points to the sim column labels\n  sim_label &lt;- ifelse(\n    label_num_points,\n    paste0(sim_index, \": N = \", nrow(points_sim_sf)),\n    sim_index\n  )\n  points_sim_sf &lt;- points_sim_sf |&gt;\n    mutate(\n      sim_label = sim_label,\n      sim_N = nrow(points_sim_sf)\n    )\n  return(points_sim_sf)\n}\nsim_list_points_to_sf &lt;- function(ppp_list_obj, label_num_points=FALSE) {\n  # This produces a *list* of sf objects\n  points_sf_list &lt;- imap(\n    ppp_list_obj,\n    \\(x, idx) sim_points_to_sf(x, idx, label_num_points)\n  )\n  # And this concatenates the list elements (by row)\n  # together to produce a single combined sf object\n  all_points_sf &lt;- bind_rows(points_sf_list)\n  return(all_points_sf)\n}\nset.seed(6805)\nbinom_ppp_sims &lt;- spatstat.random::rpoint(60, nsim=4)\nwin_sf &lt;- window_to_sf(binom_ppp_sims[[1]])\npoints_sf &lt;- sim_list_points_to_sf(binom_ppp_sims)\nggplot() +\n  geom_sf(\n    data=win_sf\n  ) +\n  geom_sf(\n    data=points_sf,\n    size=1.5\n  ) +\n  theme_classic() +\n  facet_wrap(\n    vars(sim_label),\n    nrow=2, ncol=2\n  )\n\n\n\n\n\n\n\n\nFigure¬†1: Four individual realizations of the Binomial Point Process described in this section\n\n\n\n\n\nWhy is it called the Binomial Point Process? Recall our above intuition, that we can only obtain meaningful probabilities if we ask about the likelihood of points falling within areas. This means that any probabilistic point model where points are generated within a continuous space \\(D\\) must provide answers to the question ‚ÄúGiven some area \\(A \\subseteq D\\), What is the probability that a point appears in \\(A\\)?‚Äù So, if we ask this question after running our Uniform Point Process from earlier a bunch of times (producing point patterns like those plotted in Figure¬†1) fixing some region \\(A\\), we end up with the Binomial PDF:\n\\[\n\\Pr(\\mathbf{s} \\in A) = \\binom{N}{k}p^{k}(1-p)^{N-k}\n\\]\nFor visual intuition of why we arrive at this formula, we can re-run the process four times as we did above, but this time consider asking the question of how many points we expect to see within a specific shaded (orange) region \\(A\\), constructed and visualized on its own in the following figure:\n\n\nCode\nlibrary(sf) |&gt; suppressPackageStartupMessages()\n# One circle with large radius at (0.5, 0.7), plus\n# a circle with smaller radius at (0.25, 0.5)\ncent_df &lt;- tibble::tribble(\n  ~x, ~y, ~r,\n  0.5, 0.7, 0.225,\n  0.25, 0.5, 0.15,\n)\n# Convert from df to sf\ncent_sf &lt;- sf::st_as_sf(\n  cent_df,\n  coords=c('x','y')\n)\n# Use st_buffer to \"transform\" from points to circles\n# with desired radii\nbuf_sf &lt;- sf::st_buffer(\n  cent_sf,\n  dist=cent_sf$r\n)\n# Compute the *union* of the two circles\nunion_sf &lt;- sf::st_union(buf_sf)\n# Transform into a single combined shape via st_convex_hull\nhull_sf &lt;- sf::st_convex_hull(union_sf)\n# Print out the area of this final shape\nprint(sf::st_area(hull_sf))\n\n\n[1] 0.2381532\n\n\nCode\n# And plot it in the Cartesian plane\nggplot() +\n  geom_sf(\n    data=hull_sf,\n    fill=cb_palette[1],\n    linewidth=1,\n    alpha=0.5\n  ) +\n  xlim(0, 1) + ylim(0, 1) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nAnd then overlaid with the points from our Binomial patterns generated earlier:\n\n\nCode\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\nggplot() +\n  # Window\n  geom_sf(\n    data=win_sf\n  ) +\n  # Shaded region\n  geom_sf(\n    data=hull_sf,\n    fill=cb_palette[1],\n    alpha=0.5,\n    linewidth=1\n  ) +\n  geom_sf(\n    data=points_sf,\n    size=1.5\n  ) +\n  theme_classic() +\n  facet_wrap(\n    vars(sim_label),\n    nrow=2, ncol=2\n  )\n\n\n\n\n\n\n\n\nFigure¬†2: The same four realizations of the Binary Point Process in Figure¬†1, but where the goal is now to model the probability (for each \\(k\\) between 0 and 60) that exactly \\(k\\) out of the \\(N\\) generated points lie within the shaded subregion \\(A\\). The mathematical formula for this probability turns out to be precisely the probability mass function (pmf) of the Binomial distribution, \\(\\Pr(K = k) = \\binom{N}{k}p^k(1-p)^{N-k}\\).Intuitively, since the area of \\(A\\) is about \\(0.238\\), while the area of \\(D\\) is \\(1\\), the probability that a randomly (uniformly) generated point within \\(D\\) will fall within \\(A\\) is \\(p = \\frac{|A|}{|D|} = \\frac{0.238}{1} = 0.238\\), which thus serves as our value for \\(p\\) in this binomial pmf. This linkage with the Binomial distribution also means that we expect \\(\\mathbb{E}[K] = Np = N \\cdot \\frac{|A|}{|D|}\\) points to lie within \\(A\\). Since \\(N = 60\\) here, we expect \\(60 \\cdot \\frac{0.238}{1} \\approx 14.28\\) points within this particular shaded region.\n\n\n\n\n\nThis is almost what we want, in order to have a null model for 2D spatial data that mirrors the null model for ‚Äú1D‚Äù data we saw above in Part 1.\nHowever, there is one thing wrong with this Binomial Point Process model, which we didn‚Äôt encounter with the Normal distribution above: namely, that for the points-appearing-in-areas-probabilities to be completely random, we need the property that\n\nFor any two disjoint regions \\(R_1 \\subseteq D\\) and \\(R_2 \\subseteq D\\), the probability \\(\\Pr(K_R = k)\\) that we‚Äôre aiming to model ‚Äì in words, the probability that \\(k\\) points appear in region \\(R\\) ‚Äì should be independent!\n\nIf we rephrase this to focus on what ‚Äúindependence‚Äù means for Random Variables: learning that there are \\(k_1\\) points in a region \\(R_1\\) (that is, learning that the random variable \\(K_1\\) has been realized as the integer \\(k_1\\)) should not give us any information about how many points are in \\(R_2\\).\nBut, unfortunately for us, we only need to pick one subregion \\(R\\) of \\(D\\) to immediately see why the Binomial Point Process violates this independence property:\n\nIf we learn that there are \\(k_1\\) points in a subregion \\(R_1\\), we actually immediately learn something about another subregion: \\(D \\setminus R_1\\), the remaining portion of \\(D\\) that is not within \\(R_1\\)!\n\nUsing our grey square \\(D\\) and orange blob region \\(A\\) from above, for example, if we learn (for a given realization) that 50 of the 60 total points are contained within the orange-shaded region, then we‚Äôve actually immediately learned with certainty that there are exactly 10 points in the region outside of \\(A\\)!\nWhat we‚Äôd really like, for a model of random and independent appearances of events (as spatial points within a larger domain \\(D\\)), is a model with the property that learning the number of points in one portion of the domain does not provide any information about the number of points in other portions. Is this even possible? Are we perhaps doomed by some fact of geometry, so that any point process we can think of will have this dependence property? The answer, thankfully, is no! We can come up with a point process which, though it looks similar to the Binomial Point Process at first glance, in fact does satisfy the independence property we are looking for. And that magical point process is the Poisson Point Process ü•≥\n\n\n\n\n\n\nWarningQuick But Important Disclaimer: The ‚ÄòRight‚Äô Null Model for What?\n\n\n\nHere, now that we see the main issue with the Binomial Point Process, and before we move on to its resolution via the Poisson distribution, it‚Äôs important to note one ‚Äúcorner case‚Äù:\nIf the phenomenon you‚Äôre trying to model actually does involve exactly \\(N\\) points moving around in an enclosed space ‚Äì meaning, you have a case where no matter how many time the process is run, you always end up with \\(N\\) points (e.g., a 1-meter-by-1-meter box where rats are trapped and each realization is a measurement of the rats‚Äô positions after \\(t\\) seconds) ‚Äì then the Binomial Point Process is the proper null model!\nHowever, excepting this very specific case, the Poisson Point Process is almost always the null model you want to use, for reasons described in the next section! (e.g., if the 1-by-1 rat-box example is modified so that rats can leave or enter the box between one realization and the next, then you‚Äôre back to a case where the PPP is likely the null model you want to use)"
  },
  {
    "objectID": "writeups/why-poisson/index.html#part-4-saved-by-the-poisson-distribution",
    "href": "writeups/why-poisson/index.html#part-4-saved-by-the-poisson-distribution",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "Part 4: Saved by the Poisson Distribution!",
    "text": "Part 4: Saved by the Poisson Distribution!\nThe gist, the core property that illustrates why the Poisson Point Process magically ‚Äúfixes‚Äù the issues with the Binomial Point Process mentioned above, is simply the following:\n\nThe probability of finding \\(k\\) points within a chosen region \\(R\\) will now be modeled as a random process that depends only on the area of \\(R\\) relative to the larger domain \\(D\\).\n\nThis approach, at first, probably sounds horrifically complex ‚Äì at a high level it feels like we‚Äôd have to figure out some fancy fractal-based way to ‚Äúscale‚Äù the Binomial distribution probabilities for randomly-chosen regions \\(R\\) up and down based on the ratio of \\(|R|\\) to \\(|D|\\).\nIn fact, however, this French guy already wrestled with precisely this issue in the early 1800s, and worked out the scary math ‚Äúunder the hood‚Äù so that today we get to just use the resulting distribution that‚Äôs named after him, the Poisson Distribution!\n\nModel ü§©: Poisson Point Process\nThe intuition for the Poisson distribution (before we apply it to come up with a point process) is just that, as you may have learned in an earlier stats class, it is a probabilistic model of the number of ‚Äúsuccesses‚Äù in an extremely large number of independent trials, each of which has an extremely low success probability.\nIn other words (as you may have learned in a slightly-more-intense statistics class), the Poisson distribution can be thought of as the limiting distribution that you get if you start with the Binomial distribution but take the limit as the number of trials \\(N \\rightarrow \\infty\\) while simultaneously the probability of success \\(p \\rightarrow 0\\).\nWhy does this help us model subregions of \\(D\\) independently from one another? The following diagram, from page 134 of Baddeley, Rubak, and Turner (2015), visualizes how an ‚Äúindependent set of trials with rare success probability‚Äù might appear in a spatial setting: if we treat each infinitesimally-small grid cell here as a ‚Äútrial‚Äù, with a \\(1\\) in the grid cell in the very rare case that an event occurs within that cell, and a \\(0\\) otherwise, the Poisson distribution then ‚Äúemerges‚Äù as the probabilistic model of the number of points \\(k\\) appearing in \\(R\\) if we know that events happen across the domain \\(D\\) at a rate of \\(\\lambda\\) points per unit area. In particular, since we‚Äôre modeling the random appearance of points in a subregion \\(R \\subseteq D\\) as being proportional to the area of \\(R\\), we‚Äôve arrived at the Poisson Point Process with the rate parameter \\(\\lambda\\) set to be the portion of \\(D\\)‚Äôs total area that is taken up by \\(R\\): \\(\\lambda = \\frac{|R|}{|D|}\\)!\n\n\n\n\n\nSo, equipped with this new ability that the Poisson distribution gives us ‚Äì the ability to model the rate of event occurrence within a region \\(R\\) as being proportional to the area of \\(R\\) ‚Äì we can now use the rpoispp() function from spatstat to implement the (in most cases) ‚Äúappropriate‚Äù null model for a spatial process, wherein events (points) occur in a given area in a manner that is independent of the occurrence of events in other areas. Four realizations of this final Poisson Point Process model are given below, though you will generate many more throughout your adventures in spatial hypothesis testing!\n\n\nCode\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\nset.seed(6805)\npois_ppp_list &lt;- spatstat.random::rpoispp(\n  lambda=60, nsim=4\n)\npois_win_sf &lt;- window_to_sf(pois_ppp_list[[1]])\npois_points_sf &lt;- sim_list_points_to_sf(\n  pois_ppp_list,\n  label_num_points=TRUE\n)\n# Compute the mean number of points across the four\n# realizations\nmean_N &lt;- pois_points_sf |&gt;\n  sf::st_drop_geometry() |&gt;\n  group_by(sim_label) |&gt;\n  summarize(first_N = first(sim_N)) |&gt;\n  summarize(mean_N = mean(first_N))\nggplot() +\n  geom_sf(\n    data=pois_win_sf\n  ) +\n  geom_sf(\n    data=pois_points_sf\n  ) +\n  theme_classic(base_size=14) +\n  facet_wrap(\n    vars(sim_label),\n    nrow=2, ncol=2\n  ) +\n  labs(\n    title=paste0(\n      \"Poisson Realizations (Mean N = \",\n      mean_N,\n      \")\"\n    )\n  ) +\n  theme(plot.title = element_text(hjust=0.5))"
  },
  {
    "objectID": "writeups/why-poisson/index.html#references",
    "href": "writeups/why-poisson/index.html#references",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "References",
    "text": "References\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point Patterns: Methodology and Applications with R. CRC Press.\n\n\nJaynes, Edwin T. 2002. Probability Theory: The Logic of Science. Cambridge University Press."
  },
  {
    "objectID": "writeups/why-poisson/index.html#footnotes",
    "href": "writeups/why-poisson/index.html#footnotes",
    "title": "Why Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn slightly more detail, in the context we‚Äôve set up, this assumption of a ‚Äúwell-defined‚Äù mean \\(\\mu\\) is saying that \\(\\mathbb{E}[X_i] = \\mu\\), i.e., that the most likely value, the specific numeric value we most ‚Äúexpect‚Äù to see when \\(X_i\\) is realized, is the value \\(\\mu\\).‚Ü©Ô∏é\nThis is not specific to spatial statistics, or even statistics in general ‚Äì it‚Äôs the foundation of the so-called ‚ÄúPopperian‚Äù scientific method, which Jeff needs to not rant about here üòú‚Ü©Ô∏é\nThe word ‚Äúshould‚Äù might feel weird here, as a normative/prescriptive term suddenly appearing in the middle of a descriptive statistical procedure ‚Äì in Bayesian statistics, though, we actually have a good reason for using ‚Äúshould‚Äù: any other rule we might use for evaluating hypotheses is provably ‚Äúsub-optimal‚Äù, at least in the narrow sense that we‚Äôll make worse predictions in the future. This is true, sadly, even for the ‚Äústandard‚Äù hypothesis test setup you may have learned, where you ‚Äúreject‚Äù or ‚Äúfail to reject‚Äù the null hypothesis: we can do better in terms of future predictions by converting ‚Äúreject‚Äù into ‚Äúdecrease my belief by an amount determined by Bayes‚Äô Rule‚Äù and ‚Äúfail to reject‚Äù into ‚Äúincrease my belief by an amount determined by Bayes‚Äô Rule‚Äù! You can find proofs and applications and etc. in Jaynes (2002)‚Ü©Ô∏é"
  },
  {
    "objectID": "assignments/mt-practice/index.html",
    "href": "assignments/mt-practice/index.html",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "",
    "text": "Code\nset.seed(6805)\ncb_palette &lt;- c(\n  \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\",\"#0072B2\", \"#D55E00\", \"#CC79A7\"\n)\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\nlibrary(concaveman) |&gt; suppressPackageStartupMessages()\nmc_sims &lt;- 499\n\n\nWelcome to the midterm practice problems! As was mentioned during class, here we provide you with a set of tools for comparing the first-order and/or second-order properties of spatial data, and your job is to use them to explore and assess the evidence for different hypotheses.\nSince these problems aren‚Äôt graded, the structure will look like the homeworks you‚Äôve done, except in the place of public tests will be the actual solutions for each question. However, I recommend you try solving them yourself before looking at the solutions!\n(For students enrolled in the course, this will be copied into your home directory on Positron! So, you should access it via the Midterm_Guide folder within Positron, so that you can edit the code cells and work on the individual problems at your own pace!)"
  },
  {
    "objectID": "assignments/mt-practice/index.html#initialization-code",
    "href": "assignments/mt-practice/index.html#initialization-code",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "",
    "text": "Code\nset.seed(6805)\ncb_palette &lt;- c(\n  \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\",\"#0072B2\", \"#D55E00\", \"#CC79A7\"\n)\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\nlibrary(concaveman) |&gt; suppressPackageStartupMessages()\nmc_sims &lt;- 499\n\n\nWelcome to the midterm practice problems! As was mentioned during class, here we provide you with a set of tools for comparing the first-order and/or second-order properties of spatial data, and your job is to use them to explore and assess the evidence for different hypotheses.\nSince these problems aren‚Äôt graded, the structure will look like the homeworks you‚Äôve done, except in the place of public tests will be the actual solutions for each question. However, I recommend you try solving them yourself before looking at the solutions!\n(For students enrolled in the course, this will be copied into your home directory on Positron! So, you should access it via the Midterm_Guide folder within Positron, so that you can edit the code cells and work on the individual problems at your own pace!)"
  },
  {
    "objectID": "assignments/mt-practice/index.html#overview-the-spread-of-protestantism-in-16th-century-europe",
    "href": "assignments/mt-practice/index.html#overview-the-spread-of-protestantism-in-16th-century-europe",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Overview: The Spread of Protestantism in 16th-Century Europe",
    "text": "Overview: The Spread of Protestantism in 16th-Century Europe\nIn this case, we‚Äôll explore two different hypotheses regarding the Protestant Reformation, specifically as it had affected towns throughout the so-called Holy Roman Empire‚Äîwhich we‚Äôll shorten to HRE from now onwards‚Äîby 1546 AD:\n\nDid Protestantism spread to areas with high population density, beyond what would be expected on the basis of the density itself? This can be stated a bit more clearly in terms of null and alternative hypotheses:\n\n\nThe null hypothesis here is:\n\n\\(\\mathcal{H}_0\\): The likelihood that a Protestant church (a church which abolished the Catholic Mass) appears at a location \\(\\mathbf{s}_i\\) is directly proportional to the population density at that point.\n\nThen, the alternative hypothesis is:\n\n\\(\\mathcal{H}_A\\): There exists some population density threshold \\(p^*\\) such that Protestant churches appear at locations \\(\\mathbf{s}_i^*\\) with population density greater than \\(p^*\\) more often than would be expected solely on the basis of this population density.\n\n\nThe reason this hypothesis is stated somewhat laboriously like this is because we want to see whether there are network effects in the nascent towns and cities of the HRE: whether ideas spread at an accelerated rate as population density increases (a key hypothesis in the literature on diffusion of innovations).\n\nWas the abolition of the Catholic Mass more likely for churches closer to Luther‚Äôs home in Wittenberg, Germany?\n\nHere the null and alternative hypotheses can be operationalized more simply than in the previous case: we just want to know whether the mean distance of the Protestant churches from Lutherhaus is significantly lower than the mean distance we would see if the Protestant churches were distributed solely on the basis of population density."
  },
  {
    "objectID": "assignments/mt-practice/index.html#initial-loading",
    "href": "assignments/mt-practice/index.html#initial-loading",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Initial Loading",
    "text": "Initial Loading\n\ntown_data_url &lt;- \"https://raw.githubusercontent.com/jpowerj/dsan-content/refs/heads/main/2024-fall-ppol6805/protestant_1546.csv\"\ntown_df &lt;- read_csv(town_data_url, show_col_types = FALSE)\ntown_df &lt;- town_df |&gt; mutate(\n  protestant = factor(protestant)\n)\ntown_df |&gt; head()\n\n\n\n\n\nid\nlatitude\nlongitude\nprotestant\npop\n\n\n\n\n1101021001\n54.50000\n21.20000\n1\n9962\n\n\n1101022002\n53.78333\n20.48333\n0\n8501\n\n\n1101023003\n54.40000\n22.01667\n1\n5325\n\n\n1101024004\n54.21670\n21.75000\n1\n7787\n\n\n1101025005\n53.80560\n21.94580\n1\n5152\n\n\n1101025006\n54.21667\n21.35000\n1\n7042"
  },
  {
    "objectID": "assignments/mt-practice/index.html#initial-mapping",
    "href": "assignments/mt-practice/index.html#initial-mapping",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Initial Mapping",
    "text": "Initial Mapping\nPosit.Cloud doesn‚Äôt respond very well to a plot of the entire dataset, so instead the following cell takes a sample of size \\(N = 200\\) towns and generates a plot of:\n\nTheir protestant status (represented by the color of each circle), and\nTheir population (represented by the size of each circle).\n\nYou can run it a few times to get a feel for what the sample looks like.\n\ntown_sf &lt;- town_df |&gt; sf::st_as_sf(\n  coords=c(\"longitude\",\"latitude\"),\n  crs=4326\n) |&gt; sf::st_transform(3857)\nN &lt;- 200\ntown_sample_sf &lt;- town_sf |&gt; sample_n(N) |&gt; mutate(\n  label = paste0(\"Population: \",pop,\" | Protestant: \",protestant)\n)\nmapview(town_sample_sf, zcol=\"protestant\", cex=\"pop\", label=\"label\")\n\n\n\n\n\nIf you‚Äôre wondering why the points don‚Äôt really line up with modern-day countries, it‚Äôs because Luther‚Äôs campaign was carried out across the Holy Roman Empire, which broke apart to form several of the countries which now exist in Europe, but was mostly comprised of a bunch of Kingdoms across modern-day Germany. The following two maps show the main extent in 1550, and then the ‚Äúedge‚Äù facing the Ottoman Empire in 1570, respectively (courtesy of TA Christy!!!)\n\n\n\n\n\n\n\n\n\n\nThe protestant variable for the data we‚Äôre using is based on a survey conducted in 1546, so this map showing the extent of the Holy Roman Empire circa 1555 gives a good picture of the regions within which these points were measured.\nHere, since we care in particular about the cities which adopted protestantism, our point pattern will represent churches which had abolished the Catholic Mass by 1546, and we will evaluate our two hypotheses on the basis of these points, relative to the overall population distribution of the Holy Roman Empire (as measured by the pop variable across all observations, regardless of protestant status).\nAs the following output shows, this will give us a ppp object with \\(N = 1236\\) points:\n\ntown_sf |&gt; count(protestant)\n\n\n\n\n\nprotestant\nn\ngeometry\n\n\n\n\n0\n964\nMULTIPOINT ((679048.9 65801‚Ä¶\n\n\n1\n1236\nMULTIPOINT ((742129.9 70916‚Ä¶"
  },
  {
    "objectID": "assignments/mt-practice/index.html#question-1-constructing-the-observation-window",
    "href": "assignments/mt-practice/index.html#question-1-constructing-the-observation-window",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Question 1: Constructing the Observation Window",
    "text": "Question 1: Constructing the Observation Window\nFor the first time, rather than the convex hull operation we‚Äôve used in previous homeworks, here we‚Äôll instead construct a concave hull of all points to form our observation window. This is mainly because, unlike many of the previous cases, here the Holy Roman Empire had important concavities, relating mainly to the fact that the Kingdoms of Poland and Lithuania were sovereign from the HRE. This means that if we use the convex hull, we would include a large land mass with no points in it, not because there were no towns there, but because these two Kingdoms are not included in our observation area.\nSo, our observation window construction will proceed as follows:\n\nUse the concaveman() function from the concaveman library, with a concavity value of 3, to construct the concave hull of the MULTIPOINT geometry from the previous step\nDue to rounding issues, spatstat will reject 5 of our points unless we add a buffer of 5 meters around the concave hull constructed in Step 1. So, take the result of Step 1 and add a 5 meter buffer around it, to complete the observation window construction!\n\nOnce you have constructed hull_sf, use the plot() function from Base R to display the shape of the observation window.\nResponse:\n\nhull_sf &lt;- NULL # Replace with concave hull + 5m buffer\n# And plot the shape of hull_sf\n# Your code here\n\nSolution:\n\nhull_sf &lt;- town_sf |&gt;\n  # This would work if Posit.Cloud had a post-2020 version of GEOS...\n  #sf::st_concave_hull(ratio=0.2) |&gt;\n  concaveman::concaveman(concavity=3) |&gt;\n  sf::st_buffer(dist=5)\nplot(hull_sf)"
  },
  {
    "objectID": "assignments/mt-practice/index.html#question-2-comparing-population-densities-with-point-based-densities",
    "href": "assignments/mt-practice/index.html#question-2-comparing-population-densities-with-point-based-densities",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Question 2: Comparing Population Densities with Point-Based Densities",
    "text": "Question 2: Comparing Population Densities with Point-Based Densities\nHere, on the basis of prot_sf, the sf object wherein each observation is a town, we will construct two different ppp objects:\n\nA ‚Äúplain‚Äù unmarked ppp object called town_ppp, wherein each point corresponds to the location of a town in our sample, and\nA marked ppp object called pop_ppp, where each of the points in town_ppp is associated with a mark, in this case the numeric population of the town.\n\nHowever, you don‚Äôt need to worry too much about this part, since on the actual midterm you will not need to worry about marked point processes, just ‚Äúplain‚Äù (non-marked) ppp objects. The purpose of this part is just to show how, if we use only the distribution of points itself, without the population data, we get an estimated population intensity quite close to the ‚Äúreal‚Äù population intensity function.\n\nQuestion 2.1: The Unmarked ppp Object\nFor this question, use the as.ppp() function from spatstat to construct an unmarked ppp object called town_ppp, wherein each point simply represents one of the towns in our dataset. Then, use R‚Äôs built-in plot() function to display the distribution of points in town_ppp:\nResponse:\n\ntown_ppp &lt;- NULL # Replace with call to as.ppp()\n# Then plot the constructed town_ppp object\n# Your code here\n\nSolution:\n\ntown_sfc &lt;- town_sf |&gt; sf::st_as_sfc()\ntown_ppp &lt;- as.ppp(town_sfc, W=as.owin(hull_sf))\n\nWarning: data contain duplicated points\n\nplot(town_ppp)\n\n\n\n\n\n\n\n\n\n\nQuestion 2.2: The Marked ppp Object\nNow, since the towns don‚Äôt all have equal population, your instinct may be that we should not construct a population-density intensity function solely on the basis of this unmarked ppp object. To get a more accurate estimation of population density, here construct a new ppp object called pop_ppp where each point is now marked with the population of the town at that point.\nAs a big hint: if you plug an sf object with only one data attribute into spatstat‚Äôs as.ppp() function, it will use that one data attribute as the mark for each point.\nResponse:\n\n# Your code here\n\nSolution:\n\npop_sf &lt;- town_sf |&gt; select(pop)\npop_ppp &lt;- as.ppp(pop_sf, W=as.owin(hull_sf))\n\nWarning: data contain duplicated points\n\nplot(pop_ppp)\n\n\n\n\n\n\n\n\n\n\nQuestion 2.3: Comparing Estimated Intensity Functions\nNow, using the density() and plot() functions, plot the estimated intensity functions from these two ppp objects‚Ä¶ Do they differ enough to justify the more ‚Äúadvanced‚Äù approach using the marked point process?\nResponse:\n\ntown_int &lt;- NULL # Replace with estimation of intensity from non-marked points\npop_int &lt;- NULL # Replace with estimation of intensity from population-marked points\n# And plot the two estimated intensity functions using plot()\n# Your code here\n\nSolution:\n\n# Town intensity\ntown_int &lt;- density(town_ppp)\nplot(town_int)\n\n\n\n\n\n\n\n# And population-weighted intensity\npop_int &lt;- density(pop_ppp, weights=pop_ppp$marks)\nplot(pop_int)"
  },
  {
    "objectID": "assignments/mt-practice/index.html#question-3-protestantism-by-population-density",
    "href": "assignments/mt-practice/index.html#question-3-protestantism-by-population-density",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Question 3: Protestantism by Population Density",
    "text": "Question 3: Protestantism by Population Density\nI mentioned in class how the Earth Mover‚Äôs Distance takes way too long on Posit.Cloud. So, for this part, we‚Äôre going to use quadrat counts instead. An advantage of using quadrat counts is that, though the square-by-square comparisons I mentioned in class are the ‚Äúdefault‚Äù behavior in spatstat, the spatstat book (on page 178) also provides code for splitting a polygon into meaningful regions rather than just squares. So, here we‚Äôll use this code to find a split of the entire HRE region into a high-population region and a low-population region. Then, our quadrat comparisons become both more simple and more meaningful: we can compare the observed count of protestant towns in high-population regions with simulated counts of protestant towns in the same high-population regions, across \\(N_{\\text{MC}}\\) simulations.\n\nnum_regions &lt;- 3\nregion_labels &lt;- c(\"Low\", \"Medium\", \"High\")\npop_vals &lt;- pop_int\npop_quant &lt;- quantile(pop_vals, probs=(0:num_regions)/num_regions, na.rm=TRUE)\npop_cut &lt;- cut(pop_vals, breaks=pop_quant, labels=region_labels)\npop_areas &lt;- tess(image=pop_cut)\nplot(pop_areas)\n\n\n\n\n\n\n\n\nSo, with these three equal-area regions in hand, let‚Äôs count how many of the observed protestant churches fell within low, middle, and high-population areas!\n\nQuestion 3.1: Quadrat Counts for Observed Protestant Churches\nNow that we‚Äôve used the population data to construct a ppp object representing the population distribution, which we then used to split the entire Holy Roman Empire into low, middle, and high-population subregions, let‚Äôs construct a ppp object called protestant_ppp representing just the locations of the protestant towns. In other words, this will be similar to the ppp object creation above, but we want to use only the towns where protestant == 1.\nOnce the ppp object is constructed, use the Base R plot() function to display the points and observation window for protestant_ppp.\nResponse:\n\nprot_sf &lt;- NULL # Construct sf object containing only protestant towns\nprot_ppp &lt;- NULL # Use prot_sf to construct a ppp object for protestant towns\n# And plot the prot_ppp object\n# Your code here\n\nSolution:\n\nprot_sf &lt;- town_sf |&gt; filter(protestant == 1)\nprot_sfc &lt;- prot_sf |&gt; sf::st_as_sfc()\nprot_ppp &lt;- as.ppp(prot_sfc, Window(pop_ppp))\n\nWarning: data contain duplicated points\n\nplot(prot_ppp)\n\n\n\n\n\n\n\n\n\n\nQuestion 3.2: Low, Medium, and High-Population Counts\nThis is where the beautiful of the quadratcount() function comes in. Whereas above we used a somewhat-complicated procedure to construct our low, middle, and high-population regions, now that we have that on hand, we can simply provide it as the tess argument to quadratcount(), and it will automatically give us counts for the number of points in each region!\nSo, use the pop_areas object constructed above as the tess argument to quadratcount to obtain counts for the number of points in each region, and store these counts as a named vector called obs_prot_counts, where the entries have names \"Low\", \"Medium\", and \"High\", respectively. In the last line of your code cell, display the obs_prot_counts vector.\nResponse:\n\nobs_prot_counts &lt;- NULL # Replace with call to quadratcount()\n# And display the contents of obs_prot_counts\n# Your code here\n\nSolution:\n\nobs_prot_counts &lt;- quadratcount(prot_ppp, tess=pop_areas) |&gt; as.vector()\nnames(obs_prot_counts) &lt;- region_labels\nobs_prot_counts\n\n   Low Medium   High \n   171    262    803"
  },
  {
    "objectID": "assignments/mt-practice/index.html#question-4-monte-carlo-simulation",
    "href": "assignments/mt-practice/index.html#question-4-monte-carlo-simulation",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Question 4: Monte Carlo Simulation",
    "text": "Question 4: Monte Carlo Simulation\nWhat does this distribution of counts ‚Äúmean‚Äù? Do we have a greater-than-expected proportion of protestant towns in high-population regions? The key way to find out, that we‚Äôve discussed in class, is to simulate the placement of protestant churches across the Holy Roman Empire, under the null hypothesis that protestantism ‚Äúappeared‚Äù in direct proportion to population density, and then compare our observed test statistics to test statistics obtained via simulation.\nIn this case, since our hypothesis concerns the spread of protestantism to high-population areas of the Holy Roman Empire, our test statistic will simply be the number of protestant churches appearing in the ‚ÄúHigh‚Äù region, among the three regions computed above and stored in pop_areas.\n\nQuestion 4.1: Simulating a Single Point Pattern of Protestant Churches\nBefore computing the full set of \\(N_{\\text{MC}}\\) simulations, it‚Äôs usually helpful to just try and compute one simulation. Once you know that your simulation code is correct, you can then feel confident running it in a loop \\(N_{\\text{MC}}\\) times!\nSo, for this question, write a function called gen_sim_ppp() which creates a ppp object simulating the placement of \\(N = 1236\\) protestant churches across the HRE if this placement followed the population distribution (which we estimated above and stored as pop_int):\nResponse:\n\nset.seed(6805)\ngen_sim_ppp &lt;- function() {\n  # Your code here: generate a number of points equal to the number of rows\n  # in prot_sf, but with intensity function given by pop_int\n  return(NULL)\n}\nsim_prot_ppp &lt;- gen_sim_ppp()\nif (!all(is.null(sim_prot_ppp))) {\n  plot(sim_prot_ppp)\n}\n\nSolution:\n\nset.seed(6805)\ngen_sim_ppp &lt;- function() {\n  prot_sim &lt;- spatstat.random::rpoint(\n    n = nrow(prot_sf),\n    f = pop_int\n  )\n  return(prot_sim)\n}\nsim_prot_ppp &lt;- gen_sim_ppp()\nplot(sim_prot_ppp)\n\n\n\n\n\n\n\n\n\n\nQuestion 4.2: Quadrat Counts for the Simulated Points\nThis simulated map of protestant churches is interesting to look at, but it doesn‚Äôt help us answer our question yet. We now need to count how many of our simulated points fall within low, medium, and high-population regions of the HRE! For this question, write a function called compute_quadrat_counts() which takes in a ppp object and produces a named vector representing the counts for the \"Low\", \"Medium\", and \"High\" areas. In other words, it should produce output in the same format as in Question 3.2 above (so that we can directly compare the observed counts computed in that question with the simulated count vectors produced in this question!).\nResponse:\n\ncompute_quadrat_counts &lt;- function(sim_ppp) {\n  # Your code here\n  return(NULL)\n}\ncompute_quadrat_counts(sim_prot_ppp)\n\nNULL\n\n\nSolution:\n\ncompute_quadrat_counts &lt;- function(sim_ppp) {\n  sim_counts &lt;- quadratcount(sim_ppp, tess=pop_areas) |&gt; as.vector()\n  names(sim_counts) &lt;- region_labels\n  return(sim_counts)\n}\ncompute_quadrat_counts(sim_prot_ppp)\n\n   Low Medium   High \n   167    381    688 \n\n\n\n\nQuestion 4.3: Full Monte Carlo Simulation\nNow that all the pieces of our Monte Carlo Simulation pipeline are ready to go, generate \\(N_{\\text{MC}}\\) simulations under the null hypothesis, computing the quadrat counts for each, and store the results in an \\(N_{\\text{MC}}\\)-row df object named full_count_df. You may use the provided gen_sims_ppp() function to efficiently generate a list containing \\(N_{\\text{MC}}\\) ppp objects.\nResponse:\n\nset.seed(6805)\ngen_sims_ppp &lt;- function(num_sims) {\n  prot_sims &lt;- spatstat.random::rpoint(\n    n = nrow(prot_sf),\n    f = pop_int,\n    nsim = num_sims\n  )\n  return(prot_sims)\n}\nfull_count_df &lt;- NULL # Your code here\n\nSolution:\n\nset.seed(6805)\ngen_sims_ppp &lt;- function(num_sims) {\n  prot_sims &lt;- spatstat.random::rpoint(\n    n = nrow(prot_sf),\n    f = pop_int,\n    nsim = num_sims\n  )\n  return(prot_sims)\n}\nfull_sims_list &lt;- gen_sims_ppp(num_sims = mc_sims)\nfull_sim_area_counts &lt;- lapply(X=full_sims_list, FUN=compute_quadrat_counts)\nfull_count_df &lt;- as_tibble(full_sim_area_counts) |&gt; t() |&gt; as_tibble()\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\n‚Ñπ Using compatibility `.name_repair`.\n\ncolnames(full_count_df) &lt;- region_labels\nfull_count_df |&gt; head()\n\n\n\n\n\nLow\nMedium\nHigh\n\n\n\n\n167\n381\n688\n\n\n146\n387\n703\n\n\n188\n383\n665\n\n\n172\n370\n694\n\n\n158\n401\n677\n\n\n132\n413\n691\n\n\n\n\n\n\n\n\nQuestion 4.4: Plotting Test Statistic Values\nNow that you have both the observed test statistic values in obs_prot_counts and the simulated test statistic values in full_count_df, combine them and plot their distribution using ggplot2‚Äôs geom_density() function, then superimpose the obseved test statistic value on this distribution using geom_vline():\nResponse:\n\nmc_df &lt;- NULL # Replace with code combining full_count_df and obs_prot_counts\n# And plot using ggplot\n# Your code here\n\nSolution:\n\nmc_df &lt;- bind_rows(full_count_df, obs_prot_counts)\nfull_count_df |&gt; ggplot(aes(x=High)) +\n  #geom_bar(stat='count') +\n  geom_density(fill=cb_palette[2], alpha=0.5) +\n  geom_vline(xintercept = obs_prot_counts[\"High\"], linetype=\"dashed\", color=cb_palette[1]) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nQuestion 4.5: Proportion of Sims with More Extreme Test Stat Value\nHere, even though we can see what the answer will be by looking at the plot above, you will sometimes be asked to compute something akin to a \\(p\\)-value‚Ä¶ So, compute this \\(p\\)-value by calculating what proportion of the simulated test statistics have a value greater than or equal to our observed test statistic value (the number of Protestant churches within the High population regions).\nResponse:\n\nq4_prop_more_extreme &lt;- NULL # Replace with calculation\nq4_prop_more_extreme\n\nNULL\n\n\nSolution:\n\nq4_more_extreme_df &lt;- mc_df[mc_df$High &gt;= obs_prot_counts[\"High\"],]\nq4_prop_more_extreme &lt;- nrow(q4_more_extreme_df) / nrow(mc_df)\nq4_prop_more_extreme\n\n[1] 0.002\n\n\nOn the midterm there may be one additional question asking you to interpret this result‚Äîthe main point is writing the code that can get you to the result! So, for the response to the midterm question, you can just write a one-sentence conclusion like:\nSince none of our \\(N_{\\text{MC}}\\) simulations contained a count of Protestant churches in High-population regions as high as the observed count of Protestant churches in High-population regions, we can increase our confidence in the alternative hypothesis, that Protestant churches appeared in High-population regions even above what would be expected on the basis of these regions‚Äô population densities."
  },
  {
    "objectID": "assignments/mt-practice/index.html#question-5-distance-from-lutherhaus",
    "href": "assignments/mt-practice/index.html#question-5-distance-from-lutherhaus",
    "title": "Midterm Practice Problems 1: Point Data",
    "section": "Question 5: Distance from Lutherhaus",
    "text": "Question 5: Distance from Lutherhaus\nRun the following code to construct a new sf object called luther_sf, which contains just the point within the HRE where Luther‚Äôs home was located for most of his life. The cell will also plot this point, so you can see that it lies directly on the building!\n\nluther_coords &lt;- c(51.86403006496275, 12.652425271164175)\nluther_df &lt;- tibble(name=c(\"Lutherhaus\"), lat=luther_coords[1], lon=luther_coords[2])\nluther_sf &lt;- sf::st_as_sf(\n  luther_df,\n  coords=c(\"lon\", \"lat\"),\n  crs=4326\n) |&gt; sf::st_transform(3857)\nmapview(luther_sf)\n\n\n\n\n\n\nQuestion 5.1: Observed Mean Distance\nIn the following code cell, use the st_distance() function from sf to compute the distance from each point in prot_sf to the Lutherhaus. Then use mean() and as.numeric() from Base R to compute the mean distance as a ‚Äúplain‚Äù numeric variable (as.numeric() will remove the unit‚Äîmeters‚Äîfrom the value, which will make it easier to plot using ggplot() at the very end).\nResponse:\n\nall_distances &lt;- NULL # Replace with computation of pointwise distances\nobs_mean_dist &lt;- NULL # Replace with computation of mean distance, with units removed\n# And display the observed mean distance value\n# Your code here\n\nSolution:\n\nall_distances &lt;- prot_sf |&gt; sf::st_distance(luther_sf)\nobs_mean_dist &lt;- as.numeric(mean(all_distances))\nobs_mean_dist\n\n[1] 416187.4\n\n\n\n\nQuestion 5.2: Interpreting the Observed Mean Distance\nIs this‚Ä¶ a high mean distance? A low mean distance? We have no way of knowing unless we compare it with a distribution of mean distances from Lutherhaus, which we can compute using the full_sims_list object we constructed in Question 4. So, in this cell:\n\nWrite a function compute_mean_dist() which takes in a ppp object and computes the mean distance from each point in the object to the Lutherhaus. Then\nUse the lapply() function from Base R to call your compute_mean_dist() function on each of the simulated point patterns in full_sims_list\n\nNote that, because st_distance() is fairly slow, this code cell will take way longer to run than any of the other cells in the notebook. So, make sure everything looks right, or perform some sanity checks (on smaller datasets, perhaps) before running the full code!\nResponse:\n\ncompute_mean_dist &lt;- function(sim_ppp) {\n  # Your code here\n  return(NULL) # Replace with mean distance from points in sim_ppp to Lutherhaus\n}\n#compute_mean_dist(sims_list[[1]])\nsim_dists &lt;- NULL # Replace with call to lapply()\nsim_dists |&gt; head()\n\nNULL\n\n\nSolution:\n\ncompute_mean_dist &lt;- function(sim_ppp) {\n  sim_prot_sf &lt;- sim_ppp |&gt;\n    sf::st_as_sf() |&gt;\n    sf::st_set_crs(3857) |&gt;\n    filter(label == \"point\")\n  sim_dists &lt;- sim_prot_sf |&gt;\n    sf::st_distance(luther_sf)\n  return(mean(as.numeric(sim_dists)))\n}\n#compute_mean_dist(sims_list[[1]])\nsim_dists &lt;- lapply(X=full_sims_list, FUN=compute_mean_dist)\nsim_dists |&gt; head()\n\n$`Simulation 1`\n[1] 473330.2\n\n$`Simulation 2`\n[1] 468955.7\n\n$`Simulation 3`\n[1] 476480.5\n\n$`Simulation 4`\n[1] 479429.8\n\n$`Simulation 5`\n[1] 474743.8\n\n$`Simulation 6`\n[1] 463398.7\n\n\n\n\nQuestion 5.3: Plotting the Observed Test Statistic\nNow that you have (a) the observed mean distance from Lutherhaus, and (b) \\(N_{\\text{MC}}\\) simulated mean distances from Lutherhaus, all that‚Äôs left is to plot the simulated distances in order to see whether our observed mean is lower than the simulated observed means, which would lend support to our alternative hypothesis! In the following code cell, use the geom_density() function from ggplot2 to plot the density of mean distances across the \\(N_{\\text{MC}}\\) simulations, then use geom_vline() to superimpose the observed mean distance on top of this distribution:\nResponse:\n\n# Your code here\n\nSolution:\n\nsim_dist_df &lt;- unlist(sim_dists) |&gt; as_tibble()\nobs_dist_df &lt;- tibble(value = obs_mean_dist)\nmc_dist_df &lt;- bind_rows(sim_dist_df, obs_dist_df)\nmc_dist_df |&gt; ggplot(aes(x=value)) +\n  geom_density(fill=cb_palette[2], alpha=0.5) +\n  geom_vline(xintercept = obs_mean_dist, linetype=\"dashed\", color=cb_palette[1]) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nQuestion 5.4: Proportion of Sims with More Extreme Test Stat Value\nAs you did in Question 4.4 above, here compute the proportion of simulations for which the mean distance was ‚Äúmore extreme‚Äù than (in this case, lower than) the observed mean distance:\nResponse:\n\nq5_prop_more_extreme &lt;- NULL # Replace with calculation\n\nSolution:\n\nq5_more_extreme_df &lt;- mc_dist_df[mc_dist_df$value &lt;= obs_mean_dist,]\nq5_more_extreme_prop &lt;- nrow(q5_more_extreme_df) / nrow(mc_dist_df)\nq5_more_extreme_prop\n\n[1] 0.002\n\n\nAnd, on the midterm there may be one additional question which simply asks you to interpret this plot in terms of the second hypothesis listed at the beginning of the assignment. Here, we see that the observed mean distance from Lutherhaus is pretty significantly smaller than any of the distances which were observed under the null hypothesis, so that we also have evidence that proximity to Lutherhaus had an effect on the likelihood of adopting Protestantism beyond what would be expected if this spread was just proportional to population density!"
  },
  {
    "objectID": "w02/slides.html#helpful-feedback",
    "href": "w02/slides.html#helpful-feedback",
    "title": "Week 2: How Do Maps Work?",
    "section": "Helpful Feedback!",
    "text": "Helpful Feedback!\n\nSry for machine-gunning words/concepts at you last week\n\n\\(\\leadsto\\) Talking more slowly!\n\\(\\leadsto\\) Less colloquial language!\nPls give me grace as I enact this video in reverse\n\nMore importantly: weekly coding workshops!\n\nNot only will they ‚Äúcancel out‚Äù my too-fast DC-slang-poisoned pace, but also‚Ä¶\nFocus will be on specific blocks of code rather than higher-level concepts [but see also: ‚Äúforgetting curve‚Äù diagram a few slides ahead]"
  },
  {
    "objectID": "w02/slides.html#pedagogical-principles",
    "href": "w02/slides.html#pedagogical-principles",
    "title": "Week 2: How Do Maps Work?",
    "section": "Pedagogical Principles",
    "text": "Pedagogical Principles\n\nThere‚Äôs literally no such thing as ‚Äúintelligence‚Äù\nAnyone is capable of learning anything (neural plasticity)\nGrowth mindset: ‚ÄúI can‚Äôt do this‚Äù \\(\\leadsto\\) ‚ÄúI can‚Äôt do this yet!‚Äù\nThe point of a class is learning: understanding something about the world, either (a) For its own sake (end in itself) or (b) Because it‚Äôs relevant to something you care about (means to an end)\n\n\n\nOur teaching should be governed, not by a desire to make students learn things, but by the endeavor to keep burning within them that light which is called curiosity. (Montessori 1916)"
  },
  {
    "objectID": "w02/slides.html#chatgpt-and-whatnot",
    "href": "w02/slides.html#chatgpt-and-whatnot",
    "title": "Week 2: How Do Maps Work?",
    "section": "ChatGPT and Whatnot",
    "text": "ChatGPT and Whatnot\n\nIf you feel like ChatGPT will help you learn something in the course, then use it!\nIf you feel like you‚Äôre using it as a ‚Äúcrutch‚Äù, try to hold yourself accountable for not using it!\n\n\n\n\n\n\n\n\nTake the time/energy you're using to worry about...\nUse it instead to worry about...\n\n\n\n\n\nChatGPT\nCollaboration Policies\nPlagiarism\n\nLearning GIS"
  },
  {
    "objectID": "w02/slides.html#on-not-worrying-about-prereqs",
    "href": "w02/slides.html#on-not-worrying-about-prereqs",
    "title": "Week 2: How Do Maps Work?",
    "section": "On Not Worrying About Prereqs",
    "text": "On Not Worrying About Prereqs\n\nI genuinely believe that I can make the course accessible to you, meeting you wherever you‚Äôre at, no matter what!\nEveryone learns at their own pace (who says 14 weeks is ‚Äúcorrect‚Äù amount of time to learn GIS?), and I structure my courses as best as I possibly can to adapt to your pace\n\\(\\Rightarrow\\) Assessments (HW, Midterm) valuable in two ways:\n[Valuable for you] As an accountability mechanism to make sure you‚Äôre learn the material (how do we know when we‚Äôve learned something? When we can answer questions about it / use it to accomplish things!)\n[Valuable for me] For assessing and updating pace"
  },
  {
    "objectID": "w02/slides.html#r-andor-python-andor-js",
    "href": "w02/slides.html#r-andor-python-andor-js",
    "title": "Week 2: How Do Maps Work?",
    "section": "R and/or Python and/or JS",
    "text": "R and/or Python and/or JS\n\nMy Geometry vs.¬†Algebra Rant‚Ä¶ Euclid‚Äôs Elements, Book VI, Proposition 28.\nThe problem: Divide a given straight line so that the rectangle contained by its segments may be equal to a given area, not exceeding the square of half the line.\n\n\n\nGeometers solved w/geometry (300 BC)‚Ä¶\n\n\n\n\n\n\n‚Ä¶Algebraists solved w/algebra (2000 BC)‚Ä¶\n\\[\n\\begin{align*}\n&ax^2 + bx + c = 0 \\\\\n\\Rightarrow \\; & x_+ = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}\n\\end{align*}\n\\]\n‚Ä¶From 1637 onwards, whichever is easier! ü§Øü§Øü§Ø (Isomorphism)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Circle with radius 1? Or \\((x,y)\\) satisfying \\(x^2 + y^2 = 1\\)?"
  },
  {
    "objectID": "w02/slides.html#learning-how-to-learn",
    "href": "w02/slides.html#learning-how-to-learn",
    "title": "Week 2: How Do Maps Work?",
    "section": "Learning How To Learn",
    "text": "Learning How To Learn\n\n\n\n\n\n\nFigure¬†2: From The Carter (Documentary)"
  },
  {
    "objectID": "w02/slides.html#hes-literally-extremely-correct",
    "href": "w02/slides.html#hes-literally-extremely-correct",
    "title": "Week 2: How Do Maps Work?",
    "section": "He‚Äôs Literally Extremely Correct!",
    "text": "He‚Äôs Literally Extremely Correct!\n\nFrom Elsevier Osmosis: Spaced Repetition"
  },
  {
    "objectID": "w02/slides.html#our-first-map-polygons",
    "href": "w02/slides.html#our-first-map-polygons",
    "title": "Week 2: How Do Maps Work?",
    "section": "Our First Map: Polygons!",
    "text": "Our First Map: Polygons!\n(Quick demo adapted from Sherry Xie‚Äôs R Consortium Workshop: Analyzing Geospatial Data in R, using DC rather than Philadelphia open data.)\n\n\nCode\nlibrary(sf)\n# Load DC tracts data\ndc_sf_fpath &lt;- \"data/DC_Census_2020/Census_Tracts_in_2020.shp\"\ndc_sf &lt;- st_read(dc_sf_fpath);\n\n\nReading layer `Census_Tracts_in_2020' from data source \n  `/Users/jpj/gtown-local/ppol6805/w02/data/DC_Census_2020/Census_Tracts_in_2020.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 206 features and 315 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8584933 ymin: 4691871 xmax: -8561515 ymax: 4721078\nProjected CRS: WGS 84 / Pseudo-Mercator\n\n\nCode\ncols_to_keep &lt;- c(\"OBJECTID\", \"TRACT\", \"GEOID\", \"ALAND\", \"AWATER\", \"STUSAB\", \"SUMLEV\", \"GEOCODE\", \"STATE\", \"NAME\", \"POP100\", \"HU100\", \"geometry\")\ndc_sf &lt;- dc_sf |&gt; select(cols_to_keep)"
  },
  {
    "objectID": "w02/slides.html#sf-objects",
    "href": "w02/slides.html#sf-objects",
    "title": "Week 2: How Do Maps Work?",
    "section": "sf Objects",
    "text": "sf Objects\ndc_sf is an object of type sf (short for ‚Äúsimple feature‚Äù), which extends data.frame, and contains features which have type POLYGON\n\n\nCode\nclass(dc_sf)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nCode\nhead(dc_sf)\n\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8577962 ymin: 4708107 xmax: -8572564 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n  OBJECTID  TRACT       GEOID  ALAND AWATER STUSAB SUMLEV     GEOCODE STATE\n1        1 002002 11001002002 849376      0     DC    140 11001002002    11\n2        2 002101 11001002101 600992      0     DC    140 11001002101    11\n3        3 002102 11001002102 725975      0     DC    140 11001002102    11\n4        4 002201 11001002201 415173      0     DC    140 11001002201    11\n5        5 002202 11001002202 698895    566     DC    140 11001002202    11\n6        6 000101 11001000101 199776   5261     DC    140 11001000101    11\n                NAME POP100 HU100                       geometry\n1 Census Tract 20.02   4072  1532 POLYGON ((-8575655 4714476,...\n2 Census Tract 21.01   5687  2335 POLYGON ((-8574745 4715676,...\n3 Census Tract 21.02   5099  2221 POLYGON ((-8573824 4715684,...\n4 Census Tract 22.01   3485  1229 POLYGON ((-8574654 4714781,...\n5 Census Tract 22.02   3339  1454 POLYGON ((-8573792 4714811,...\n6  Census Tract 1.01   1406   999 POLYGON ((-8577962 4708867,..."
  },
  {
    "objectID": "w02/slides.html#working-with-sf-objects",
    "href": "w02/slides.html#working-with-sf-objects",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\nWith some rare but important exceptions (which we‚Äôll learn!), can be used just like a data.frame / tibble:\n\n\nCode\nstr(dc_sf)   # view structure\n\n\nClasses 'sf' and 'data.frame':  206 obs. of  13 variables:\n $ OBJECTID: int  1 2 3 4 5 6 7 8 9 10 ...\n $ TRACT   : chr  \"002002\" \"002101\" \"002102\" \"002201\" ...\n $ GEOID   : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ ALAND   : int  849376 600992 725975 415173 698895 199776 1706484 505004 776435 1042157 ...\n $ AWATER  : int  0 0 0 0 566 5261 516665 0 439661 2305 ...\n $ STUSAB  : chr  \"DC\" \"DC\" \"DC\" \"DC\" ...\n $ SUMLEV  : int  140 140 140 140 140 140 140 140 140 140 ...\n $ GEOCODE : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ STATE   : int  11 11 11 11 11 11 11 11 11 11 ...\n $ NAME    : chr  \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\" \"Census Tract 22.01\" ...\n $ POP100  : int  4072 5687 5099 3485 3339 1406 3417 4108 4672 6161 ...\n $ HU100   : int  1532 2335 2221 1229 1454 999 2053 11 2169 2845 ...\n $ geometry:sfc_POLYGON of length 206; first list element: List of 1\n  ..$ : num [1:155, 1:2] -8575655 -8575655 -8575655 -8575655 -8575655 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:12] \"OBJECTID\" \"TRACT\" \"GEOID\" \"ALAND\" ..."
  },
  {
    "objectID": "w02/slides.html#working-with-sf-objects-1",
    "href": "w02/slides.html#working-with-sf-objects-1",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf)  # view first several rows\n\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8577962 ymin: 4708107 xmax: -8572564 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n  OBJECTID  TRACT       GEOID  ALAND AWATER STUSAB SUMLEV     GEOCODE STATE\n1        1 002002 11001002002 849376      0     DC    140 11001002002    11\n2        2 002101 11001002101 600992      0     DC    140 11001002101    11\n3        3 002102 11001002102 725975      0     DC    140 11001002102    11\n4        4 002201 11001002201 415173      0     DC    140 11001002201    11\n5        5 002202 11001002202 698895    566     DC    140 11001002202    11\n6        6 000101 11001000101 199776   5261     DC    140 11001000101    11\n                NAME POP100 HU100                       geometry\n1 Census Tract 20.02   4072  1532 POLYGON ((-8575655 4714476,...\n2 Census Tract 21.01   5687  2335 POLYGON ((-8574745 4715676,...\n3 Census Tract 21.02   5099  2221 POLYGON ((-8573824 4715684,...\n4 Census Tract 22.01   3485  1229 POLYGON ((-8574654 4714781,...\n5 Census Tract 22.02   3339  1454 POLYGON ((-8573792 4714811,...\n6  Census Tract 1.01   1406   999 POLYGON ((-8577962 4708867,..."
  },
  {
    "objectID": "w02/slides.html#working-with-sf-objects-2",
    "href": "w02/slides.html#working-with-sf-objects-2",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\ndim(dc_sf)   # view dimensions\n\n\n[1] 206  13\n\n\nCode\ndc_sf[1,]    # select first row\n\n\nSimple feature collection with 1 feature and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8575656 ymin: 4713958 xmax: -8574562 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n  OBJECTID  TRACT       GEOID  ALAND AWATER STUSAB SUMLEV     GEOCODE STATE\n1        1 002002 11001002002 849376      0     DC    140 11001002002    11\n                NAME POP100 HU100                       geometry\n1 Census Tract 20.02   4072  1532 POLYGON ((-8575655 4714476,..."
  },
  {
    "objectID": "w02/slides.html#working-with-sf-objects-3",
    "href": "w02/slides.html#working-with-sf-objects-3",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf$NAME)  # select column by name  \n\n\n[1] \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\"\n[4] \"Census Tract 22.01\" \"Census Tract 22.02\" \"Census Tract 1.01\" \n\n\nCode\nhead(dc_sf[,4])         # select column by number\n\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8577962 ymin: 4708107 xmax: -8572564 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n   ALAND                       geometry\n1 849376 POLYGON ((-8575655 4714476,...\n2 600992 POLYGON ((-8574745 4715676,...\n3 725975 POLYGON ((-8573824 4715684,...\n4 415173 POLYGON ((-8574654 4714781,...\n5 698895 POLYGON ((-8573792 4714811,...\n6 199776 POLYGON ((-8577962 4708867,..."
  },
  {
    "objectID": "w02/slides.html#and-actually-displaying-the-map",
    "href": "w02/slides.html#and-actually-displaying-the-map",
    "title": "Week 2: How Do Maps Work?",
    "section": "And‚Ä¶ Actually Displaying the Map!",
    "text": "And‚Ä¶ Actually Displaying the Map!\n\n\nCode\n# We can extract the geometry with the st_geometry function\ndc_geo &lt;- st_geometry(dc_sf)\n#pt_geo\n\n# Plot the geometry with base R's plot() function\nplot(dc_geo)"
  },
  {
    "objectID": "w02/slides.html#and-with-ggplot",
    "href": "w02/slides.html#and-with-ggplot",
    "title": "Week 2: How Do Maps Work?",
    "section": "And with ggplot!",
    "text": "And with ggplot!\n\n\nCode\ndc_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic()"
  },
  {
    "objectID": "w02/slides.html#raster-data",
    "href": "w02/slides.html#raster-data",
    "title": "Week 2: How Do Maps Work?",
    "section": "Raster Data",
    "text": "Raster Data\n\nEach DC Census Tract has its own (odd) shape, which can be described by discrete coordinates forming a POLYGON\nFor geospatial analysis, however, we often need to compute over evenly-spaced grids rather than this odd collection of shapes\n\nMost common example: photos taken from an airplane/satellite! [Remote sensing]\n\nPOLYGONs may make sense for demographers, but how about someone studying air pollution in DC? (Smog, for example, does not confine itself to census tracts!)"
  },
  {
    "objectID": "w02/slides.html#step-1-union-of-all-tracts",
    "href": "w02/slides.html#step-1-union-of-all-tracts",
    "title": "Week 2: How Do Maps Work?",
    "section": "Step 1: Union of All Tracts",
    "text": "Step 1: Union of All Tracts\n\n\nCode\ndc_union_sf &lt;- sf::st_union(dc_sf)\ndc_union_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic()"
  },
  {
    "objectID": "w02/slides.html#step-2-rasterize-terra",
    "href": "w02/slides.html#step-2-rasterize-terra",
    "title": "Week 2: How Do Maps Work?",
    "section": "Step 2: Rasterize (terra)",
    "text": "Step 2: Rasterize (terra)\n\n\nCode\nlibrary(terra)\ndc_SpatVector &lt;- terra::vect(dc_union_sf)\nrast_template &lt;- rast(ext(dc_SpatVector), resolution = 1000, crs = crs(dc_SpatVector))\ndc_SpatRaster &lt;- terra::rasterize(dc_SpatVector, rast_template)\ndim(dc_SpatRaster)\n\n\n[1] 29 23  1\n\n\nCode\nplot(dc_SpatRaster)"
  },
  {
    "objectID": "w02/slides.html#rasters-from-scratch",
    "href": "w02/slides.html#rasters-from-scratch",
    "title": "Week 2: How Do Maps Work?",
    "section": "Rasters From Scratch",
    "text": "Rasters From Scratch\nWelcome to Gridtown!\n\n\n\nCode\nset.seed(6805)\nlibrary(terra)\ngridtown &lt;- terra::rast(\n  nrows = 4, ncols = 4,\n  xmin = 0, xmax = 4, ymin = 0, ymax = 4,\n  vals = sample(1:16)\n)\nplot(gridtown)\ntext(\n  gridtown,\n  labels=1:16,\n  halo=TRUE, hc=\"black\", col=\"white\", hw=0.2\n)\n\n\n\n\n\n\n\n\n\nFigure¬†3: Gridtown Indices\n\n\n\n\n\n\nRaster indices vs.¬†values: The above plot displays indices for each cell: since a raster is a regular grid, can achieve memory-efficient representation with a single index (rather than, e.g., \\((x, y)\\) coords). But what we really care about are‚Ä¶"
  },
  {
    "objectID": "w02/slides.html#raster-layer-values",
    "href": "w02/slides.html#raster-layer-values",
    "title": "Week 2: How Do Maps Work?",
    "section": "Raster Layer Values",
    "text": "Raster Layer Values\n\n\nCode\nplot(gridtown)\ntext(gridtown, halo=TRUE, hc=\"black\", col=\"white\", hw=0.2)\n\n\n\n\nFigure¬†4: Gridtown Values"
  },
  {
    "objectID": "w02/slides.html#references",
    "href": "w02/slides.html#references",
    "title": "Week 2: How Do Maps Work?",
    "section": "References",
    "text": "References\n\n\nMontessori, Maria. 1916. Spontaneous Activity in Education: A Basic Guide to the Montessori Methods of Learning in the Classroom. Lulu Press."
  },
  {
    "objectID": "w02/index.html",
    "href": "w02/index.html",
    "title": "Week 2: How Do Maps Work?",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#helpful-feedback",
    "href": "w02/index.html#helpful-feedback",
    "title": "Week 2: How Do Maps Work?",
    "section": "Helpful Feedback!",
    "text": "Helpful Feedback!\n\nSry for machine-gunning words/concepts at you last week\n\n\\(\\leadsto\\) Talking more slowly!\n\\(\\leadsto\\) Less colloquial language!\nPls give me grace as I enact this video in reverse\n\nMore importantly: weekly coding workshops!\n\nNot only will they ‚Äúcancel out‚Äù my too-fast DC-slang-poisoned pace, but also‚Ä¶\nFocus will be on specific blocks of code rather than higher-level concepts [but see also: ‚Äúforgetting curve‚Äù diagram a few slides ahead]",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#pedagogical-principles",
    "href": "w02/index.html#pedagogical-principles",
    "title": "Week 2: How Do Maps Work?",
    "section": "Pedagogical Principles",
    "text": "Pedagogical Principles\n\nThere‚Äôs literally no such thing as ‚Äúintelligence‚Äù\nAnyone is capable of learning anything (neural plasticity)\nGrowth mindset: ‚ÄúI can‚Äôt do this‚Äù \\(\\leadsto\\) ‚ÄúI can‚Äôt do this yet!‚Äù\nThe point of a class is learning: understanding something about the world, either (a) For its own sake (end in itself) or (b) Because it‚Äôs relevant to something you care about (means to an end)\n\n\n\nOur teaching should be governed, not by a desire to make students learn things, but by the endeavor to keep burning within them that light which is called curiosity. (Montessori 1916)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#chatgpt-and-whatnot",
    "href": "w02/index.html#chatgpt-and-whatnot",
    "title": "Week 2: How Do Maps Work?",
    "section": "ChatGPT and Whatnot",
    "text": "ChatGPT and Whatnot\n\nIf you feel like ChatGPT will help you learn something in the course, then use it!\nIf you feel like you‚Äôre using it as a ‚Äúcrutch‚Äù, try to hold yourself accountable for not using it!\n\n\n\n\n\n\n\n\nTake the time/energy you're using to worry about...\nUse it instead to worry about...\n\n\n\n\n\nChatGPT\nCollaboration Policies\nPlagiarism\n\nLearning GIS",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#on-not-worrying-about-prereqs",
    "href": "w02/index.html#on-not-worrying-about-prereqs",
    "title": "Week 2: How Do Maps Work?",
    "section": "On Not Worrying About Prereqs",
    "text": "On Not Worrying About Prereqs\n\nI genuinely believe that I can make the course accessible to you, meeting you wherever you‚Äôre at, no matter what!\nEveryone learns at their own pace (who says 14 weeks is ‚Äúcorrect‚Äù amount of time to learn GIS?), and I structure my courses as best as I possibly can to adapt to your pace\n\\(\\Rightarrow\\) Assessments (HW, Midterm) valuable in two ways:\n[Valuable for you] As an accountability mechanism to make sure you‚Äôre learn the material (how do we know when we‚Äôve learned something? When we can answer questions about it / use it to accomplish things!)\n[Valuable for me] For assessing and updating pace",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#r-andor-python-andor-js",
    "href": "w02/index.html#r-andor-python-andor-js",
    "title": "Week 2: How Do Maps Work?",
    "section": "R and/or Python and/or JS",
    "text": "R and/or Python and/or JS\n\nMy Geometry vs.¬†Algebra Rant‚Ä¶ Euclid‚Äôs Elements, Book VI, Proposition 28.\nThe problem: Divide a given straight line so that the rectangle contained by its segments may be equal to a given area, not exceeding the square of half the line.\n\n\n\nGeometers solved w/geometry (300 BC)‚Ä¶\n\n\n\n\n\n\n‚Ä¶Algebraists solved w/algebra (2000 BC)‚Ä¶\n\\[\n\\begin{align*}\n&ax^2 + bx + c = 0 \\\\\n\\Rightarrow \\; & x_+ = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}\n\\end{align*}\n\\]\n‚Ä¶From 1637 onwards, whichever is easier! ü§Øü§Øü§Ø (Isomorphism)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Circle with radius 1? Or \\((x,y)\\) satisfying \\(x^2 + y^2 = 1\\)?",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#learning-how-to-learn",
    "href": "w02/index.html#learning-how-to-learn",
    "title": "Week 2: How Do Maps Work?",
    "section": "Learning How To Learn",
    "text": "Learning How To Learn\n\n\n\n\n\n\nFigure¬†2: From The Carter (Documentary)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#hes-literally-extremely-correct",
    "href": "w02/index.html#hes-literally-extremely-correct",
    "title": "Week 2: How Do Maps Work?",
    "section": "He‚Äôs Literally Extremely Correct!",
    "text": "He‚Äôs Literally Extremely Correct!\n\n\n\nFrom Elsevier Osmosis: Spaced Repetition",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#our-first-map-polygons",
    "href": "w02/index.html#our-first-map-polygons",
    "title": "Week 2: How Do Maps Work?",
    "section": "Our First Map: Polygons!",
    "text": "Our First Map: Polygons!\n(Quick demo adapted from Sherry Xie‚Äôs R Consortium Workshop: Analyzing Geospatial Data in R, using DC rather than Philadelphia open data.)\n\n\nCode\nlibrary(sf)\n# Load DC tracts data\ndc_sf_fpath &lt;- \"data/DC_Census_2020/Census_Tracts_in_2020.shp\"\ndc_sf &lt;- st_read(dc_sf_fpath);\n\n\nReading layer `Census_Tracts_in_2020' from data source \n  `/Users/jpj/gtown-local/ppol6805/w02/data/DC_Census_2020/Census_Tracts_in_2020.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 206 features and 315 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8584933 ymin: 4691871 xmax: -8561515 ymax: 4721078\nProjected CRS: WGS 84 / Pseudo-Mercator\n\n\nCode\ncols_to_keep &lt;- c(\"OBJECTID\", \"TRACT\", \"GEOID\", \"ALAND\", \"AWATER\", \"STUSAB\", \"SUMLEV\", \"GEOCODE\", \"STATE\", \"NAME\", \"POP100\", \"HU100\", \"geometry\")\ndc_sf &lt;- dc_sf |&gt; select(cols_to_keep)\n\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\n‚Ñπ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(cols_to_keep)\n\n  # Now:\n  data %&gt;% select(all_of(cols_to_keep))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#sf-objects",
    "href": "w02/index.html#sf-objects",
    "title": "Week 2: How Do Maps Work?",
    "section": "sf Objects",
    "text": "sf Objects\ndc_sf is an object of type sf (short for ‚Äúsimple feature‚Äù), which extends data.frame, and contains features which have type POLYGON\n\n\nCode\nclass(dc_sf)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nCode\nhead(dc_sf)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nTRACT\nGEOID\nALAND\nAWATER\nSTUSAB\nSUMLEV\nGEOCODE\nSTATE\nNAME\nPOP100\nHU100\ngeometry\n\n\n\n\n1\n002002\n11001002002\n849376\n0\nDC\n140\n11001002002\n11\nCensus Tract 20.02\n4072\n1532\nPOLYGON ((-8575655 4714476,‚Ä¶\n\n\n2\n002101\n11001002101\n600992\n0\nDC\n140\n11001002101\n11\nCensus Tract 21.01\n5687\n2335\nPOLYGON ((-8574745 4715676,‚Ä¶\n\n\n3\n002102\n11001002102\n725975\n0\nDC\n140\n11001002102\n11\nCensus Tract 21.02\n5099\n2221\nPOLYGON ((-8573824 4715684,‚Ä¶\n\n\n4\n002201\n11001002201\n415173\n0\nDC\n140\n11001002201\n11\nCensus Tract 22.01\n3485\n1229\nPOLYGON ((-8574654 4714781,‚Ä¶\n\n\n5\n002202\n11001002202\n698895\n566\nDC\n140\n11001002202\n11\nCensus Tract 22.02\n3339\n1454\nPOLYGON ((-8573792 4714811,‚Ä¶\n\n\n6\n000101\n11001000101\n199776\n5261\nDC\n140\n11001000101\n11\nCensus Tract 1.01\n1406\n999\nPOLYGON ((-8577962 4708867,‚Ä¶",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#working-with-sf-objects",
    "href": "w02/index.html#working-with-sf-objects",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\nWith some rare but important exceptions (which we‚Äôll learn!), can be used just like a data.frame / tibble:\n\n\nCode\nstr(dc_sf)   # view structure\n\n\nClasses 'sf' and 'data.frame':  206 obs. of  13 variables:\n $ OBJECTID: int  1 2 3 4 5 6 7 8 9 10 ...\n $ TRACT   : chr  \"002002\" \"002101\" \"002102\" \"002201\" ...\n $ GEOID   : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ ALAND   : int  849376 600992 725975 415173 698895 199776 1706484 505004 776435 1042157 ...\n $ AWATER  : int  0 0 0 0 566 5261 516665 0 439661 2305 ...\n $ STUSAB  : chr  \"DC\" \"DC\" \"DC\" \"DC\" ...\n $ SUMLEV  : int  140 140 140 140 140 140 140 140 140 140 ...\n $ GEOCODE : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ STATE   : int  11 11 11 11 11 11 11 11 11 11 ...\n $ NAME    : chr  \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\" \"Census Tract 22.01\" ...\n $ POP100  : int  4072 5687 5099 3485 3339 1406 3417 4108 4672 6161 ...\n $ HU100   : int  1532 2335 2221 1229 1454 999 2053 11 2169 2845 ...\n $ geometry:sfc_POLYGON of length 206; first list element: List of 1\n  ..$ : num [1:155, 1:2] -8575655 -8575655 -8575655 -8575655 -8575655 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:12] \"OBJECTID\" \"TRACT\" \"GEOID\" \"ALAND\" ...",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#working-with-sf-objects-1",
    "href": "w02/index.html#working-with-sf-objects-1",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf)  # view first several rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nTRACT\nGEOID\nALAND\nAWATER\nSTUSAB\nSUMLEV\nGEOCODE\nSTATE\nNAME\nPOP100\nHU100\ngeometry\n\n\n\n\n1\n002002\n11001002002\n849376\n0\nDC\n140\n11001002002\n11\nCensus Tract 20.02\n4072\n1532\nPOLYGON ((-8575655 4714476,‚Ä¶\n\n\n2\n002101\n11001002101\n600992\n0\nDC\n140\n11001002101\n11\nCensus Tract 21.01\n5687\n2335\nPOLYGON ((-8574745 4715676,‚Ä¶\n\n\n3\n002102\n11001002102\n725975\n0\nDC\n140\n11001002102\n11\nCensus Tract 21.02\n5099\n2221\nPOLYGON ((-8573824 4715684,‚Ä¶\n\n\n4\n002201\n11001002201\n415173\n0\nDC\n140\n11001002201\n11\nCensus Tract 22.01\n3485\n1229\nPOLYGON ((-8574654 4714781,‚Ä¶\n\n\n5\n002202\n11001002202\n698895\n566\nDC\n140\n11001002202\n11\nCensus Tract 22.02\n3339\n1454\nPOLYGON ((-8573792 4714811,‚Ä¶\n\n\n6\n000101\n11001000101\n199776\n5261\nDC\n140\n11001000101\n11\nCensus Tract 1.01\n1406\n999\nPOLYGON ((-8577962 4708867,‚Ä¶",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#working-with-sf-objects-2",
    "href": "w02/index.html#working-with-sf-objects-2",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\ndim(dc_sf)   # view dimensions\n\n\n[1] 206  13\n\n\nCode\ndc_sf[1,]    # select first row\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nTRACT\nGEOID\nALAND\nAWATER\nSTUSAB\nSUMLEV\nGEOCODE\nSTATE\nNAME\nPOP100\nHU100\ngeometry\n\n\n\n\n1\n002002\n11001002002\n849376\n0\nDC\n140\n11001002002\n11\nCensus Tract 20.02\n4072\n1532\nPOLYGON ((-8575655 4714476,‚Ä¶",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#working-with-sf-objects-3",
    "href": "w02/index.html#working-with-sf-objects-3",
    "title": "Week 2: How Do Maps Work?",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf$NAME)  # select column by name  \n\n\n[1] \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\"\n[4] \"Census Tract 22.01\" \"Census Tract 22.02\" \"Census Tract 1.01\" \n\n\nCode\nhead(dc_sf[,4])         # select column by number\n\n\n\n\n\n\nALAND\ngeometry\n\n\n\n\n849376\nPOLYGON ((-8575655 4714476,‚Ä¶\n\n\n600992\nPOLYGON ((-8574745 4715676,‚Ä¶\n\n\n725975\nPOLYGON ((-8573824 4715684,‚Ä¶\n\n\n415173\nPOLYGON ((-8574654 4714781,‚Ä¶\n\n\n698895\nPOLYGON ((-8573792 4714811,‚Ä¶\n\n\n199776\nPOLYGON ((-8577962 4708867,‚Ä¶",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#and-actually-displaying-the-map",
    "href": "w02/index.html#and-actually-displaying-the-map",
    "title": "Week 2: How Do Maps Work?",
    "section": "And‚Ä¶ Actually Displaying the Map!",
    "text": "And‚Ä¶ Actually Displaying the Map!\n\n\nCode\n# We can extract the geometry with the st_geometry function\ndc_geo &lt;- st_geometry(dc_sf)\n#pt_geo\n\n# Plot the geometry with base R's plot() function\nplot(dc_geo)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#and-with-ggplot",
    "href": "w02/index.html#and-with-ggplot",
    "title": "Week 2: How Do Maps Work?",
    "section": "And with ggplot!",
    "text": "And with ggplot!\n\n\nCode\ndc_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic()",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#raster-data",
    "href": "w02/index.html#raster-data",
    "title": "Week 2: How Do Maps Work?",
    "section": "Raster Data",
    "text": "Raster Data\n\nEach DC Census Tract has its own (odd) shape, which can be described by discrete coordinates forming a POLYGON\nFor geospatial analysis, however, we often need to compute over evenly-spaced grids rather than this odd collection of shapes\n\nMost common example: photos taken from an airplane/satellite! [Remote sensing]\n\nPOLYGONs may make sense for demographers, but how about someone studying air pollution in DC? (Smog, for example, does not confine itself to census tracts!)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#step-1-union-of-all-tracts",
    "href": "w02/index.html#step-1-union-of-all-tracts",
    "title": "Week 2: How Do Maps Work?",
    "section": "Step 1: Union of All Tracts",
    "text": "Step 1: Union of All Tracts\n\n\nCode\ndc_union_sf &lt;- sf::st_union(dc_sf)\ndc_union_sf |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_classic()",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#step-2-rasterize-terra",
    "href": "w02/index.html#step-2-rasterize-terra",
    "title": "Week 2: How Do Maps Work?",
    "section": "Step 2: Rasterize (terra)",
    "text": "Step 2: Rasterize (terra)\n\n\nCode\nlibrary(terra)\n\n\nterra 1.7.78\n\n\n\nAttaching package: 'terra'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nCode\ndc_SpatVector &lt;- terra::vect(dc_union_sf)\nrast_template &lt;- rast(ext(dc_SpatVector), resolution = 1000, crs = crs(dc_SpatVector))\ndc_SpatRaster &lt;- terra::rasterize(dc_SpatVector, rast_template)\ndim(dc_SpatRaster)\n\n\n[1] 29 23  1\n\n\nCode\nplot(dc_SpatRaster)",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#rasters-from-scratch",
    "href": "w02/index.html#rasters-from-scratch",
    "title": "Week 2: How Do Maps Work?",
    "section": "Rasters From Scratch",
    "text": "Rasters From Scratch\nWelcome to Gridtown!\n\n\nCode\nset.seed(6805)\nlibrary(terra)\ngridtown &lt;- terra::rast(\n  nrows = 4, ncols = 4,\n  xmin = 0, xmax = 4, ymin = 0, ymax = 4,\n  vals = sample(1:16)\n)\nplot(gridtown)\ntext(\n  gridtown,\n  labels=1:16,\n  halo=TRUE, hc=\"black\", col=\"white\", hw=0.2\n)\n\n\n\n\n\n\n\n\nFigure¬†3: Gridtown Indices\n\n\n\n\n\n\nRaster indices vs.¬†values: The above plot displays indices for each cell: since a raster is a regular grid, can achieve memory-efficient representation with a single index (rather than, e.g., \\((x, y)\\) coords). But what we really care about are‚Ä¶",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#raster-layer-values",
    "href": "w02/index.html#raster-layer-values",
    "title": "Week 2: How Do Maps Work?",
    "section": "Raster Layer Values",
    "text": "Raster Layer Values\n\n\nCode\nplot(gridtown)\ntext(gridtown, halo=TRUE, hc=\"black\", col=\"white\", hw=0.2)\n\n\n\n\n\n\n\n\nFigure¬†4: Gridtown Values",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w02/index.html#references",
    "href": "w02/index.html#references",
    "title": "Week 2: How Do Maps Work?",
    "section": "References",
    "text": "References\n\n\nMontessori, Maria. 1916. Spontaneous Activity in Education: A Basic Guide to the Montessori Methods of Learning in the Classroom. Lulu Press.",
    "crumbs": [
      "Week 2: Sep 3"
    ]
  },
  {
    "objectID": "w04/slides.html#hw1-question-1-generally",
    "href": "w04/slides.html#hw1-question-1-generally",
    "title": "Week 4: Unary Operations",
    "section": "HW1 Question 1 Generally",
    "text": "HW1 Question 1 Generally\n\n‚ÄúSimplest‚Äù / Most Efficient Representation\n\n‚ÄúIndicate which of the seven geometries above would provide the simplest representation of the entity‚Äù\n\nGEOMETRYCOLLECTION could represent any of the geographic entities in Q1, but would be overkill for representing e.g.¬†a single point or line"
  },
  {
    "objectID": "w04/slides.html#hw1-question-1.8-specifically",
    "href": "w04/slides.html#hw1-question-1.8-specifically",
    "title": "Week 4: Unary Operations",
    "section": "HW1 Question 1.8 Specifically",
    "text": "HW1 Question 1.8 Specifically\nFor the United Arab Emirates (UAE) data‚Ä¶ we have what we call the Not-Paraguay-Problem: Most countries, including the UAE, have a bunch of lil ‚Äúpieces‚Äù:\n\n\n\n\nCode\nru_national_map &lt;- ne_countries(type = \"countries\", country = \"Russia\", scale = \"medium\", returnclass = \"sf\")\nmapview(ru_national_map)\n\n\n\n\n\n\n\n\n\nCode\nuae_national_map &lt;- ne_countries(type = \"countries\", country = \"United Arab Emirates\", scale = \"large\", returnclass = \"sf\")\nmapview(uae_national_map)\n\n\n\n\n\n\n\nSo, for Q1.8: Assume we‚Äôre just trying to have the computer represent the ‚Äúmainland‚Äù (the biggest contiguous landmass, with Dubai on it!)"
  },
  {
    "objectID": "w04/slides.html#public-vs.-hidden-tests",
    "href": "w04/slides.html#public-vs.-hidden-tests",
    "title": "Week 4: Unary Operations",
    "section": "Public vs.¬†Hidden Tests",
    "text": "Public vs.¬†Hidden Tests\n\nPublic Tests are basically ‚ÄúQuality Assurance Test‚Äù\nHidden Tests check for correctness"
  },
  {
    "objectID": "w04/slides.html#latitude-and-longitude-are-angles",
    "href": "w04/slides.html#latitude-and-longitude-are-angles",
    "title": "Week 4: Unary Operations",
    "section": "Latitude and Longitude are Angles!",
    "text": "Latitude and Longitude are Angles!\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#angular-distance-vs.-travel-distance",
    "href": "w04/slides.html#angular-distance-vs.-travel-distance",
    "title": "Week 4: Unary Operations",
    "section": "Angular Distance vs.¬†Travel Distance",
    "text": "Angular Distance vs.¬†Travel Distance\nThe Earth‚Äôs ‚Äúwidth‚Äù is slightly greater than its ‚Äúlength‚Äù üò∞\n\nFrom Wikimedia Commons"
  },
  {
    "objectID": "w04/slides.html#smooshing-3d-into-2d",
    "href": "w04/slides.html#smooshing-3d-into-2d",
    "title": "Week 4: Unary Operations",
    "section": "Smooshing 3D into 2D",
    "text": "Smooshing 3D into 2D\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "w04/slides.html#avoid-getting-lost-in-the-sauce",
    "href": "w04/slides.html#avoid-getting-lost-in-the-sauce",
    "title": "Week 4: Unary Operations",
    "section": "Avoid Getting Lost in the Sauce",
    "text": "Avoid Getting Lost in the Sauce"
  },
  {
    "objectID": "w04/slides.html#how-to-avoid-getting-lost-in-the-sauce",
    "href": "w04/slides.html#how-to-avoid-getting-lost-in-the-sauce",
    "title": "Week 4: Unary Operations",
    "section": "How To Avoid Getting Lost in the Sauce",
    "text": "How To Avoid Getting Lost in the Sauce\n\n\n\n\n\nTissot Circles: Imagine infinitely small ellipses placed at regular intervals on the curved surface of the earth. Imagine these ellipses being projected along with the earth‚Äôs surface. When scaled up, changes in the ellipses show the location and quality of distortions on the projected map."
  },
  {
    "objectID": "w04/slides.html#the-uss-ur-choropleth-1-population",
    "href": "w04/slides.html#the-uss-ur-choropleth-1-population",
    "title": "Week 4: Unary Operations",
    "section": "The US‚Äôs Ur-Choropleth #1: Population",
    "text": "The US‚Äôs Ur-Choropleth #1: Population\n\nKieran Healy, ‚ÄúAmerica‚Äôs Ur-Choropleths‚Äù"
  },
  {
    "objectID": "w04/slides.html#the-uss-ur-choropleth-2-race",
    "href": "w04/slides.html#the-uss-ur-choropleth-2-race",
    "title": "Week 4: Unary Operations",
    "section": "The US‚Äôs Ur-Choropleth #2: Race",
    "text": "The US‚Äôs Ur-Choropleth #2: Race\n\nKieran Healy, ‚ÄúAmerica‚Äôs Ur-Choropleths‚Äù"
  },
  {
    "objectID": "w04/slides.html#crime-in-mongolia",
    "href": "w04/slides.html#crime-in-mongolia",
    "title": "Week 4: Unary Operations",
    "section": "Crime in Mongolia",
    "text": "Crime in Mongolia\n\nFrom Reddit"
  },
  {
    "objectID": "w04/slides.html#population-of-mongolia",
    "href": "w04/slides.html#population-of-mongolia",
    "title": "Week 4: Unary Operations",
    "section": "Population of Mongolia",
    "text": "Population of Mongolia\n\nFrom Wikimedia Commons"
  },
  {
    "objectID": "w04/slides.html#exhibit-a",
    "href": "w04/slides.html#exhibit-a",
    "title": "Week 4: Unary Operations",
    "section": "Exhibit A",
    "text": "Exhibit A\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "w04/slides.html#exhibit-b",
    "href": "w04/slides.html#exhibit-b",
    "title": "Week 4: Unary Operations",
    "section": "Exhibit B",
    "text": "Exhibit B\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "w04/slides.html#continuous-choropleth",
    "href": "w04/slides.html#continuous-choropleth",
    "title": "Week 4: Unary Operations",
    "section": "Continuous Choropleth",
    "text": "Continuous Choropleth\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#quantile-colormap",
    "href": "w04/slides.html#quantile-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Quantile Colormap",
    "text": "Quantile Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nAssigns the same number of observations to each color\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#equal-area-colormap",
    "href": "w04/slides.html#equal-area-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Equal-Area Colormap",
    "text": "Equal-Area Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nBoundaries between colors come at regular (equal) intervals\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#natural-break-colormap",
    "href": "w04/slides.html#natural-break-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Natural-Break Colormap",
    "text": "Natural-Break Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nClustering algorithm chooses classes to (a) minimize differences within classes, (b) maximize differences between classes\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#context-sensitive-colormap",
    "href": "w04/slides.html#context-sensitive-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Context-Sensitive Colormap",
    "text": "Context-Sensitive Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nA government program offers special funding for counties with above 25% poverty\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#the-importance-of-history",
    "href": "w04/slides.html#the-importance-of-history",
    "title": "Week 4: Unary Operations",
    "section": "The Importance of History",
    "text": "The Importance of History\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "w04/slides.html#getting-the-geometries",
    "href": "w04/slides.html#getting-the-geometries",
    "title": "Week 4: Unary Operations",
    "section": "Getting the Geometries",
    "text": "Getting the Geometries\nUsing rnaturalearth with mapview\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(mapview)\nfrance_sf &lt;- ne_countries(country = \"France\", scale = 50)\n(france_map &lt;- mapview(france_sf, label = \"geounit\", legend = FALSE))"
  },
  {
    "objectID": "w04/slides.html#centroid-of-france",
    "href": "w04/slides.html#centroid-of-france",
    "title": "Week 4: Unary Operations",
    "section": "Centroid of France",
    "text": "Centroid of France\n\n\nCode\nfrance_cent_sf &lt;- sf::st_centroid(france_sf)\nfrance_map + mapview(france_cent_sf, label = \"Centroid\", legend = FALSE)"
  },
  {
    "objectID": "w04/slides.html#one-we-already-saw-union",
    "href": "w04/slides.html#one-we-already-saw-union",
    "title": "Week 4: Unary Operations",
    "section": "One We Already Saw: Union",
    "text": "One We Already Saw: Union\nComputing the union of all geometries in the sf via sf::st_union()\n\n\nCode\nlibrary(leaflet.extras2)\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nafrica_union_map &lt;- mapview(africa_union_sf, label=\"st_union(africa)\", legend=FALSE)\nafrica_map | africa_union_map"
  },
  {
    "objectID": "w04/slides.html#helpful-for-rasterizing-bbox",
    "href": "w04/slides.html#helpful-for-rasterizing-bbox",
    "title": "Week 4: Unary Operations",
    "section": "Helpful for Rasterizing: BBox",
    "text": "Helpful for Rasterizing: BBox\n\n\nCode\nafrica_bbox_sf &lt;- sf::st_bbox(africa_sf)\nafrica_bbox_map &lt;- mapview(africa_bbox_sf, label=\"st_bbox(africa)\", legend=FALSE)\nafrica_map | africa_bbox_map"
  },
  {
    "objectID": "w04/slides.html#convex-hulls-by-country",
    "href": "w04/slides.html#convex-hulls-by-country",
    "title": "Week 4: Unary Operations",
    "section": "Convex Hulls by Country",
    "text": "Convex Hulls by Country\n\n\nCode\nafrica_countries_cvx &lt;- sf::st_convex_hull(africa_sf)\nafrica_countries_cvx_map &lt;- mapview(africa_countries_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_countries_cvx_map"
  },
  {
    "objectID": "w04/slides.html#convex-hull-of-continent",
    "href": "w04/slides.html#convex-hull-of-continent",
    "title": "Week 4: Unary Operations",
    "section": "Convex Hull of Continent",
    "text": "Convex Hull of Continent\nUse st_union() first:\n\n\nCode\nafrica_cvx &lt;- africa_sf |&gt; st_union() |&gt; st_convex_hull()\nafrica_cvx_map &lt;- mapview(africa_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cvx_map"
  },
  {
    "objectID": "w04/slides.html#one-we-already-saw-centroids",
    "href": "w04/slides.html#one-we-already-saw-centroids",
    "title": "Week 4: Unary Operations",
    "section": "One We Already Saw: Centroids",
    "text": "One We Already Saw: Centroids\nComputing the centroid of all geometries in the sf via sf::st_centroid()\n\n\nCode\nafrica_cents_sf &lt;- sf::st_centroid(africa_sf)\nafrica_cents_map &lt;- mapview(africa_cents_sf, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cents_map"
  },
  {
    "objectID": "w04/slides.html#references",
    "href": "w04/slides.html#references",
    "title": "Week 4: Unary Operations",
    "section": "References",
    "text": "References\n\n\nKrygier, John, and Denis Wood. 2016. Making Maps, Third Edition: A Visual Guide to Map Design for GIS. Guilford Publications.\n\n\nMonmonier, Mark. 2018. How to Lie with Maps. University of Chicago Press. https://www.dropbox.com/scl/fi/7rsqbxgge6llggnaf5tit/How-to-Lie-with-Maps-Third-Edition.pdf?rlkey=6rqxta7cjyq3oqdnskj4dtwj8&dl=1."
  },
  {
    "objectID": "w04/index.html",
    "href": "w04/index.html",
    "title": "Week 4: Unary Operations",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#hw1-question-1-generally",
    "href": "w04/index.html#hw1-question-1-generally",
    "title": "Week 4: Unary Operations",
    "section": "HW1 Question 1 Generally",
    "text": "HW1 Question 1 Generally\n\n‚ÄúSimplest‚Äù / Most Efficient Representation\n\n‚ÄúIndicate which of the seven geometries above would provide the simplest representation of the entity‚Äù\n\nGEOMETRYCOLLECTION could represent any of the geographic entities in Q1, but would be overkill for representing e.g.¬†a single point or line",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#hw1-question-1.8-specifically",
    "href": "w04/index.html#hw1-question-1.8-specifically",
    "title": "Week 4: Unary Operations",
    "section": "HW1 Question 1.8 Specifically",
    "text": "HW1 Question 1.8 Specifically\nFor the United Arab Emirates (UAE) data‚Ä¶ we have what we call the Not-Paraguay-Problem: Most countries, including the UAE, have a bunch of lil ‚Äúpieces‚Äù:\n\n\n\n\nCode\nru_national_map &lt;- ne_countries(type = \"countries\", country = \"Russia\", scale = \"medium\", returnclass = \"sf\")\nmapview(ru_national_map)\n\n\n\n\n\n\n\n\n\nCode\nuae_national_map &lt;- ne_countries(type = \"countries\", country = \"United Arab Emirates\", scale = \"large\", returnclass = \"sf\")\nmapview(uae_national_map)\n\n\n\n\n\n\n\n\nSo, for Q1.8: Assume we‚Äôre just trying to have the computer represent the ‚Äúmainland‚Äù (the biggest contiguous landmass, with Dubai on it!)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#public-vs.-hidden-tests",
    "href": "w04/index.html#public-vs.-hidden-tests",
    "title": "Week 4: Unary Operations",
    "section": "Public vs.¬†Hidden Tests",
    "text": "Public vs.¬†Hidden Tests\n\nPublic Tests are basically ‚ÄúQuality Assurance Test‚Äù\nHidden Tests check for correctness",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#latitude-and-longitude-are-angles",
    "href": "w04/index.html#latitude-and-longitude-are-angles",
    "title": "Week 4: Unary Operations",
    "section": "Latitude and Longitude are Angles!",
    "text": "Latitude and Longitude are Angles!\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#angular-distance-vs.-travel-distance",
    "href": "w04/index.html#angular-distance-vs.-travel-distance",
    "title": "Week 4: Unary Operations",
    "section": "Angular Distance vs.¬†Travel Distance",
    "text": "Angular Distance vs.¬†Travel Distance\nThe Earth‚Äôs ‚Äúwidth‚Äù is slightly greater than its ‚Äúlength‚Äù üò∞\n\n\n\nFrom Wikimedia Commons",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#smooshing-3d-into-2d",
    "href": "w04/index.html#smooshing-3d-into-2d",
    "title": "Week 4: Unary Operations",
    "section": "Smooshing 3D into 2D",
    "text": "Smooshing 3D into 2D\n\n\n\nFrom Monmonier (2018)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#avoid-getting-lost-in-the-sauce",
    "href": "w04/index.html#avoid-getting-lost-in-the-sauce",
    "title": "Week 4: Unary Operations",
    "section": "Avoid Getting Lost in the Sauce",
    "text": "Avoid Getting Lost in the Sauce",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#how-to-avoid-getting-lost-in-the-sauce",
    "href": "w04/index.html#how-to-avoid-getting-lost-in-the-sauce",
    "title": "Week 4: Unary Operations",
    "section": "How To Avoid Getting Lost in the Sauce",
    "text": "How To Avoid Getting Lost in the Sauce\n\n\n\n\n\nTissot Circles: Imagine infinitely small ellipses placed at regular intervals on the curved surface of the earth. Imagine these ellipses being projected along with the earth‚Äôs surface. When scaled up, changes in the ellipses show the location and quality of distortions on the projected map.",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#the-uss-ur-choropleth-1-population",
    "href": "w04/index.html#the-uss-ur-choropleth-1-population",
    "title": "Week 4: Unary Operations",
    "section": "The US‚Äôs Ur-Choropleth #1: Population",
    "text": "The US‚Äôs Ur-Choropleth #1: Population\n\n\n\nKieran Healy, ‚ÄúAmerica‚Äôs Ur-Choropleths‚Äù",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#the-uss-ur-choropleth-2-race",
    "href": "w04/index.html#the-uss-ur-choropleth-2-race",
    "title": "Week 4: Unary Operations",
    "section": "The US‚Äôs Ur-Choropleth #2: Race",
    "text": "The US‚Äôs Ur-Choropleth #2: Race\n\n\n\nKieran Healy, ‚ÄúAmerica‚Äôs Ur-Choropleths‚Äù",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#crime-in-mongolia",
    "href": "w04/index.html#crime-in-mongolia",
    "title": "Week 4: Unary Operations",
    "section": "Crime in Mongolia",
    "text": "Crime in Mongolia\n\n\n\nFrom Reddit",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#population-of-mongolia",
    "href": "w04/index.html#population-of-mongolia",
    "title": "Week 4: Unary Operations",
    "section": "Population of Mongolia",
    "text": "Population of Mongolia\n\n\n\nFrom Wikimedia Commons",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#exhibit-a",
    "href": "w04/index.html#exhibit-a",
    "title": "Week 4: Unary Operations",
    "section": "Exhibit A",
    "text": "Exhibit A\n\n\n\nFrom Monmonier (2018)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#exhibit-b",
    "href": "w04/index.html#exhibit-b",
    "title": "Week 4: Unary Operations",
    "section": "Exhibit B",
    "text": "Exhibit B\n\n\n\nFrom Monmonier (2018)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#continuous-choropleth",
    "href": "w04/index.html#continuous-choropleth",
    "title": "Week 4: Unary Operations",
    "section": "Continuous Choropleth",
    "text": "Continuous Choropleth\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#quantile-colormap",
    "href": "w04/index.html#quantile-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Quantile Colormap",
    "text": "Quantile Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nAssigns the same number of observations to each color\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#equal-area-colormap",
    "href": "w04/index.html#equal-area-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Equal-Area Colormap",
    "text": "Equal-Area Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nBoundaries between colors come at regular (equal) intervals\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#natural-break-colormap",
    "href": "w04/index.html#natural-break-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Natural-Break Colormap",
    "text": "Natural-Break Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nClustering algorithm chooses classes to (a) minimize differences within classes, (b) maximize differences between classes\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#context-sensitive-colormap",
    "href": "w04/index.html#context-sensitive-colormap",
    "title": "Week 4: Unary Operations",
    "section": "Context-Sensitive Colormap",
    "text": "Context-Sensitive Colormap\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\nA government program offers special funding for counties with above 25% poverty\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#the-importance-of-history",
    "href": "w04/index.html#the-importance-of-history",
    "title": "Week 4: Unary Operations",
    "section": "The Importance of History",
    "text": "The Importance of History\nIs poverty a ‚Äúsignificant issue‚Äù in the US?\n\n\n\nFrom Krygier and Wood (2016)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#getting-the-geometries",
    "href": "w04/index.html#getting-the-geometries",
    "title": "Week 4: Unary Operations",
    "section": "Getting the Geometries",
    "text": "Getting the Geometries\nUsing rnaturalearth with mapview\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(mapview)\nfrance_sf &lt;- ne_countries(country = \"France\", scale = 50)\n(france_map &lt;- mapview(france_sf, label = \"geounit\", legend = FALSE))",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#centroid-of-france",
    "href": "w04/index.html#centroid-of-france",
    "title": "Week 4: Unary Operations",
    "section": "Centroid of France",
    "text": "Centroid of France\n\n\nCode\nfrance_cent_sf &lt;- sf::st_centroid(france_sf)\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\nCode\nfrance_map + mapview(france_cent_sf, label = \"Centroid\", legend = FALSE)",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#one-we-already-saw-union",
    "href": "w04/index.html#one-we-already-saw-union",
    "title": "Week 4: Unary Operations",
    "section": "One We Already Saw: Union",
    "text": "One We Already Saw: Union\nComputing the union of all geometries in the sf via sf::st_union()\n\n\nCode\nlibrary(leaflet.extras2)\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nafrica_union_map &lt;- mapview(africa_union_sf, label=\"st_union(africa)\", legend=FALSE)\nafrica_map | africa_union_map",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#helpful-for-rasterizing-bbox",
    "href": "w04/index.html#helpful-for-rasterizing-bbox",
    "title": "Week 4: Unary Operations",
    "section": "Helpful for Rasterizing: BBox",
    "text": "Helpful for Rasterizing: BBox\n\n\nCode\nafrica_bbox_sf &lt;- sf::st_bbox(africa_sf)\nafrica_bbox_map &lt;- mapview(africa_bbox_sf, label=\"st_bbox(africa)\", legend=FALSE)\nafrica_map | africa_bbox_map",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#convex-hulls-by-country",
    "href": "w04/index.html#convex-hulls-by-country",
    "title": "Week 4: Unary Operations",
    "section": "Convex Hulls by Country",
    "text": "Convex Hulls by Country\n\n\nCode\nafrica_countries_cvx &lt;- sf::st_convex_hull(africa_sf)\nafrica_countries_cvx_map &lt;- mapview(africa_countries_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_countries_cvx_map",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#convex-hull-of-continent",
    "href": "w04/index.html#convex-hull-of-continent",
    "title": "Week 4: Unary Operations",
    "section": "Convex Hull of Continent",
    "text": "Convex Hull of Continent\nUse st_union() first:\n\n\nCode\nafrica_cvx &lt;- africa_sf |&gt; st_union() |&gt; st_convex_hull()\nafrica_cvx_map &lt;- mapview(africa_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cvx_map",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#one-we-already-saw-centroids",
    "href": "w04/index.html#one-we-already-saw-centroids",
    "title": "Week 4: Unary Operations",
    "section": "One We Already Saw: Centroids",
    "text": "One We Already Saw: Centroids\nComputing the centroid of all geometries in the sf via sf::st_centroid()\n\n\nCode\nafrica_cents_sf &lt;- sf::st_centroid(africa_sf)\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\nCode\nafrica_cents_map &lt;- mapview(africa_cents_sf, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cents_map",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w04/index.html#references",
    "href": "w04/index.html#references",
    "title": "Week 4: Unary Operations",
    "section": "References",
    "text": "References\n\n\nKrygier, John, and Denis Wood. 2016. Making Maps, Third Edition: A Visual Guide to Map Design for GIS. Guilford Publications.\n\n\nMonmonier, Mark. 2018. How to Lie with Maps. University of Chicago Press. https://www.dropbox.com/scl/fi/7rsqbxgge6llggnaf5tit/How-to-Lie-with-Maps-Third-Edition.pdf?rlkey=6rqxta7cjyq3oqdnskj4dtwj8&dl=1.",
    "crumbs": [
      "Week 4: Sep 17"
    ]
  },
  {
    "objectID": "w03/index.html",
    "href": "w03/index.html",
    "title": "Week 3: Vector and Raster Representations",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#ta-intros",
    "href": "w03/index.html#ta-intros",
    "title": "Week 3: Vector and Raster Representations",
    "section": "TA Intros",
    "text": "TA Intros\n(In alphabetical order by surname wohoo)\n\n\n\nChristy Hsuth1010@georgetown.edu\n\n\nCoding workshop leader\nSurvived the fire and flames of this class in first semester after studying history ü§Ø\n\n\n\nYumi Lixl794@georgetown.edu\n\n\nOmbuds-person\nSurvived several Jeff classes + background in computer science (including Java!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelevant Word of the Day: Â±± (ShƒÅn) = Mountain",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#coding-workshops-starting-this-friday",
    "href": "w03/index.html#coding-workshops-starting-this-friday",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Coding Workshops Starting This Friday!",
    "text": "Coding Workshops Starting This Friday!\n\nCar Barn Room 230 (conference room across hallway from DSAN Suite 207), if you can make it in person!\nZoom Link if you can join remotely!\nVideo recording to be posted on Panopto (link TBD) once processed",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#hw1-fun-with-vectors-and-rasters",
    "href": "w03/index.html#hw1-fun-with-vectors-and-rasters",
    "title": "Week 3: Vector and Raster Representations",
    "section": "HW1: Fun with Vectors and Rasters",
    "text": "HW1: Fun with Vectors and Rasters\n\nQuestion 1 [Multiple Choice!]: Understanding the WKT geometries conceptually\nQuestion 2: Using the WKT geometries to create Vectortown\nQuestion 3: Using the raster format (today‚Äôs lecture) to create Gridtopia",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#hw1-rightarrow-hw2",
    "href": "w03/index.html#hw1-rightarrow-hw2",
    "title": "Week 3: Vector and Raster Representations",
    "section": "HW1 \\(\\rightarrow\\) HW2",
    "text": "HW1 \\(\\rightarrow\\) HW2\n\nOnce you finish HW1, you‚Äôll know how to create geometries with sf and terra\nSo now, what can you do with them?\nFor example, we‚Äôd like to be able to say things like:\n\n‚ÄúThe new lamppost cannot be placed at \\((x, y)\\), since there is already a building there!‚Äù\n‚ÄúThere are \\(N_1\\) lampposts in County 1, and \\(N_2\\) lampposts in County 2‚Äù\n‚ÄúThe average resident in Neighborhood A lives 2 km away from their nearest bus stop",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#first-things-first-loading-and-saving",
    "href": "w03/index.html#first-things-first-loading-and-saving",
    "title": "Week 3: Vector and Raster Representations",
    "section": "First Things First: Loading and Saving",
    "text": "First Things First: Loading and Saving\n\nNote how there were no data files in HW1 üò±\nFrom HW2 onwards (and in your GIS life), we‚Äôll:\n\nDownload from e.g.¬†city Open Data Portals: geo data files, but also loading on-the-fly (this week)\nSummarize/aggregate (this week and next week)\nVisualize findings (‚ÄúMapping Libraries‚Äù unit)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#shapefiles-.shp-et-al.",
    "href": "w03/index.html#shapefiles-.shp-et-al.",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Shapefiles (.shp et al.)",
    "text": "Shapefiles (.shp et al.)\nA shape‚Äúfile‚Äù is actually (at least) three separate files bundled together:\n\n Mandatory .shp: Containing feature geometries\n Mandatory .shx: Positional indices\n Mandatory .dbf: Data attributes\n Optional .prj: Coordinate reference system\n Optional .xml: Metadata",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#shapefiles",
    "href": "w03/index.html#shapefiles",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Shapefiles",
    "text": "Shapefiles\nLet‚Äôs see what‚Äôs inside the shapefile we first saw in Week 1, containing data on DC‚Äôs Census Tracts: Census Tracts in 2020\n\n\n\nDC Census Tracts (with the Georgetown campus tract highlighted!) from OpenData.DC.gov",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#shapefile-anatomy",
    "href": "w03/index.html#shapefile-anatomy",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Shapefile Anatomy",
    "text": "Shapefile Anatomy\n\n\n\nFrom Rodrigue (2016)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#geojson-topojson-.geojson",
    "href": "w03/index.html#geojson-topojson-.geojson",
    "title": "Week 3: Vector and Raster Representations",
    "section": "GeoJSON / TopoJSON (.geojson)",
    "text": "GeoJSON / TopoJSON (.geojson)\n\n\n\nJavaScript Object Notation: General cross-platform format\nUseful when data is too complex for e.g.¬†.csv\nTopoJSON = Memory-efficient GeoJSON\nBonus: Inline preview on GitHub!\n\n\n\n\nmy_data.geojson\n\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [30, 20], [45, 40],\n            [10, 40], [30, 20]\n          ]\n        ]\n      },\n      \"properties\": {\n        \"color\": \"green\",\n        \"area\": 3565747\n      }\n    },\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [15, 5], [40, 10],\n            [10, 20], [5, 10], \n            [15, 5]\n          ]\n        ]\n      },\n      \"properties\": {\n        \"color\": \"red\",\n        \"area\": 3272386\n      }\n    }\n  ]\n}",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#geopackage-.gpkg",
    "href": "w03/index.html#geopackage-.gpkg",
    "title": "Week 3: Vector and Raster Representations",
    "section": "GeoPackage (.gpkg)",
    "text": "GeoPackage (.gpkg)\n\nOpen-source (non-proprietary) data format standard",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#raster-formats",
    "href": "w03/index.html#raster-formats",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Raster Formats",
    "text": "Raster Formats\n\nGeoTIFF (.tif or .tiff)\n\nBased on TIFF format developed at NASA\n\nNetCDF (.nc4)\n\nUsed in earth sciences, as format for data sources measured and distributed multiple times per day over large full-country or full-continent areas.",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#coordinate-reference-systems-crs",
    "href": "w03/index.html#coordinate-reference-systems-crs",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Coordinate Reference Systems (CRS)",
    "text": "Coordinate Reference Systems (CRS)\n\nEPSG (European Petroleum Survey Group) Registry: Most common way to specify a CRS\n\nFor example, 4326 is the EPSG code for the WGS84 coordinate system\n\nPROJ: Rather than opaque numeric code like EPSG, uses plaintext ‚Äúproj-strings‚Äù containing parameter info: datum, ellipsoid, projection, and units (e.g.¬†meters). Example: PROJ4 code EPSG:4326 is represented as\n+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\nWKT: Lengthy but human-readable descriptions",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#getting-the-geometries",
    "href": "w03/index.html#getting-the-geometries",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Getting the Geometries",
    "text": "Getting the Geometries\nUsing rnaturalearth with mapview\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(mapview)\nfrance_sf &lt;- ne_countries(country = \"France\", scale = 50)\n(france_map &lt;- mapview(france_sf, label = \"geounit\", legend = FALSE))",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#centroid-of-france",
    "href": "w03/index.html#centroid-of-france",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Centroid of France",
    "text": "Centroid of France\n\n\nCode\nfrance_cent_sf &lt;- sf::st_centroid(france_sf)\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\nCode\nfrance_map + mapview(france_cent_sf, label = \"Centroid\", legend = FALSE)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#one-we-already-saw-union",
    "href": "w03/index.html#one-we-already-saw-union",
    "title": "Week 3: Vector and Raster Representations",
    "section": "One We Already Saw: Union",
    "text": "One We Already Saw: Union\nComputing the union of all geometries in the sf via sf::st_union()\n\n\nCode\nlibrary(leaflet.extras2)\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nafrica_union_map &lt;- mapview(africa_union_sf, label=\"st_union(africa)\", legend=FALSE)\nafrica_map | africa_union_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#helpful-for-rasterizing-bbox",
    "href": "w03/index.html#helpful-for-rasterizing-bbox",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Helpful for Rasterizing: BBox",
    "text": "Helpful for Rasterizing: BBox\n\n\nCode\nafrica_bbox_sf &lt;- sf::st_bbox(africa_sf)\nafrica_bbox_map &lt;- mapview(africa_bbox_sf, label=\"st_bbox(africa)\", legend=FALSE)\nafrica_map | africa_bbox_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#convex-hulls-by-country",
    "href": "w03/index.html#convex-hulls-by-country",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Convex Hulls by Country",
    "text": "Convex Hulls by Country\n\n\nCode\nafrica_countries_cvx &lt;- sf::st_convex_hull(africa_sf)\nafrica_countries_cvx_map &lt;- mapview(africa_countries_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_countries_cvx_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#convex-hull-of-continent",
    "href": "w03/index.html#convex-hull-of-continent",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Convex Hull of Continent",
    "text": "Convex Hull of Continent\nUse st_union() first:\n\n\nCode\nafrica_cvx &lt;- africa_sf |&gt; st_union() |&gt; st_convex_hull()\nafrica_cvx_map &lt;- mapview(africa_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cvx_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#one-we-already-saw-centroids",
    "href": "w03/index.html#one-we-already-saw-centroids",
    "title": "Week 3: Vector and Raster Representations",
    "section": "One We Already Saw: Centroids",
    "text": "One We Already Saw: Centroids\nComputing the centroid of all geometries in the sf via sf::st_centroid()\n\n\nCode\nafrica_cents_sf &lt;- sf::st_centroid(africa_sf)\n\n\nWarning: st_centroid assumes attributes are constant over geometries\n\n\nCode\nafrica_cents_map &lt;- mapview(africa_cents_sf, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cents_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#spatial-joins",
    "href": "w03/index.html#spatial-joins",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Spatial Joins",
    "text": "Spatial Joins\n\n\nCode\nnc &lt;- system.file(\"shape/nc.shp\", package=\"sf\") |&gt;\n  read_sf() |&gt;\n  st_transform('EPSG:2264')\ngr &lt;- st_sf(\n         label = apply(expand.grid(1:10, LETTERS[10:1])[,2:1], 1, paste0, collapse = \"\"),\n         geom = st_make_grid(nc))\ngr$col &lt;- sf.colors(10, categorical = TRUE, alpha = .3)\n# cut, to verify that NA's work out:\ngr &lt;- gr[-(1:30),]\nsuppressWarnings(nc_j &lt;- st_join(nc, gr, largest = TRUE))\npar(mfrow = c(2,1), mar = rep(0,4))\nplot(st_geometry(nc_j), border = 'grey')\nplot(st_geometry(gr), add = TRUE, col = gr$col)\ntext(st_coordinates(st_centroid(st_geometry(gr))), labels = gr$label, cex = .85)\n# the joined dataset:\nplot(st_geometry(nc_j), border = 'grey', col = nc_j$col)\ntext(st_coordinates(st_centroid(st_geometry(nc_j))), labels = nc_j$label, cex = .7)\nplot(st_geometry(gr), border = '#88ff88aa', add = TRUE)",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#spatial-sampling",
    "href": "w03/index.html#spatial-sampling",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Spatial Sampling",
    "text": "Spatial Sampling\n\n\nCode\n# Sample random points\nafrica_points_list &lt;- sf::st_sample(africa_union_sf, 10)\nafrica_points_sf &lt;- sf::st_sf(africa_points_list)\nafrica_points_map &lt;- mapview(africa_points_sf, label=\"Random Point\", col.regions=cb_palette[1], legend=FALSE)\n\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\nCode\nafrica_map + africa_points_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#the-default-predicate-st_intersects",
    "href": "w03/index.html#the-default-predicate-st_intersects",
    "title": "Week 3: Vector and Raster Representations",
    "section": "The ‚ÄúDefault‚Äù Predicate: st_intersects",
    "text": "The ‚ÄúDefault‚Äù Predicate: st_intersects\n\n\nCode\ncountries_w_points &lt;- africa_sf[africa_points_sf,]\nmapview(countries_w_points, label=\"geounit\", legend=FALSE) + africa_points_map",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#counting-with-lengths",
    "href": "w03/index.html#counting-with-lengths",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Counting with lengths()",
    "text": "Counting with lengths()\n\n\nCode\ncountry_inter &lt;- sf::st_intersects(africa_sf, africa_points_sf)\n# Computes point counts for each polygon\n(num_intersections &lt;- lengths(country_inter))\n\n\n [1] 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2\n\n\nCode\nafrica_sf &lt;- africa_sf |&gt; mutate(\n  num_points = num_intersections\n) |&gt; arrange(geounit)\nafrica_sf |&gt; select(geounit, num_points) |&gt; head()\n\n\n\n\n\n\ngeounit\nnum_points\ngeometry\n\n\n\n\nAlgeria\n2\nMULTIPOLYGON (((8.576563 36‚Ä¶\n\n\nAngola\n2\nMULTIPOLYGON (((13.07275 -4‚Ä¶\n\n\nBenin\n0\nMULTIPOLYGON (((1.622656 6‚Ä¶.\n\n\nBotswana\n0\nMULTIPOLYGON (((25.25879 -1‚Ä¶\n\n\nBurkina Faso\n0\nMULTIPOLYGON (((0.9004883 1‚Ä¶\n\n\nBurundi\n0\nMULTIPOLYGON (((30.55361 -2‚Ä¶",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#plotting-with-mapview",
    "href": "w03/index.html#plotting-with-mapview",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Plotting with mapview",
    "text": "Plotting with mapview\n\n\nCode\nmapview(africa_sf, zcol=\"num_points\")",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#plotting-with-ggplot2",
    "href": "w03/index.html#plotting-with-ggplot2",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Plotting with ggplot2",
    "text": "Plotting with ggplot2\nSince we‚Äôre starting to get into data attributes rather than geometric features, switching to ggplot2 is recommended!\n\n\nCode\nafrica_sf |&gt; ggplot(aes(fill=num_points)) +\n  geom_sf() +\n  theme_classic()",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#getting-fancier",
    "href": "w03/index.html#getting-fancier",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Getting Fancier‚Ä¶",
    "text": "Getting Fancier‚Ä¶\n\nTo do fancier geospatial operations, we‚Äôll need to start overthinking the different possible relationships between two or more geometries!\nTo this end: predicates",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#de-9im-strings",
    "href": "w03/index.html#de-9im-strings",
    "title": "Week 3: Vector and Raster Representations",
    "section": "DE-9IM Strings",
    "text": "DE-9IM Strings\n\n\nCode\nlibrary(sf)\npolygon &lt;- po &lt;- st_polygon(list(rbind(c(0,0), c(1,0), c(1,1), c(0,1), c(0,0))))\np0 &lt;- st_polygon(list(rbind(c(-1,-1), c(2,-1), c(2,2), c(-1,2), c(-1,-1))))\nline &lt;- li &lt;- st_linestring(rbind(c(.5, -.5), c(.5, 0.5)))\ns &lt;- st_sfc(po, li)\n\npar(mfrow = c(3,3))\npar(mar = c(1,1,1,1))\n\n# \"1020F1102\"\n# 1: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5,0), c(.5,.495)), col = 'red', lwd = 2)\npoints(0.5, 0.5, pch = 1)\n\n# 2: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"B(line) = 0\")))\npoints(0.5, 0.5, col = 'red', pch = 16)\n\n# 3: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"E(line) = 2\")))\nplot(po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n# 4: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"I(line) = 0\")))\npoints(.5, 0, col = 'red', pch = 16)\n\n# 5: F\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"B(line) = F\")))\n\n# 6: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"E(line) = 1\")))\nplot(po, border = 'red', col = NA, add = TRUE, lwd = 2)\n\n# 7: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5, -.5), c(.5, 0)), col = 'red', lwd = 2)\n\n# 8: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"B(line) = 0\")))\npoints(.5, -.5, col = 'red', pch = 16)\n\n# 9: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"E(line) = 2\")))\nplot(p0 / po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n\n\n\n\n\n\n\n\n\nThe predicate equals corresponds to the DE-9IM string \"T*F**FFF*\". If any two geometries obey this relationship, they are (topologically) equal!",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/index.html#references",
    "href": "w03/index.html#references",
    "title": "Week 3: Vector and Raster Representations",
    "section": "References",
    "text": "References\n\n\nRodrigue, Jean-Paul. 2016. The Geography of Transport Systems. Taylor & Francis.",
    "crumbs": [
      "Week 3: Sep 10"
    ]
  },
  {
    "objectID": "w03/slides.html#ta-intros",
    "href": "w03/slides.html#ta-intros",
    "title": "Week 3: Vector and Raster Representations",
    "section": "TA Intros",
    "text": "TA Intros\n(In alphabetical order by surname wohoo)\n\n\n\nChristy Hsuth1010@georgetown.edu\n\n\nCoding workshop leader\nSurvived the fire and flames of this class in first semester after studying history ü§Ø\n\n\n\nYumi Lixl794@georgetown.edu\n\n\nOmbuds-person\nSurvived several Jeff classes + background in computer science (including Java!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelevant Word of the Day: Â±± (ShƒÅn) = Mountain"
  },
  {
    "objectID": "w03/slides.html#coding-workshops-starting-this-friday",
    "href": "w03/slides.html#coding-workshops-starting-this-friday",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Coding Workshops Starting This Friday!",
    "text": "Coding Workshops Starting This Friday!\n\nCar Barn Room 230 (conference room across hallway from DSAN Suite 207), if you can make it in person!\nZoom Link if you can join remotely!\nVideo recording to be posted on Panopto (link TBD) once processed"
  },
  {
    "objectID": "w03/slides.html#hw1-fun-with-vectors-and-rasters",
    "href": "w03/slides.html#hw1-fun-with-vectors-and-rasters",
    "title": "Week 3: Vector and Raster Representations",
    "section": "HW1: Fun with Vectors and Rasters",
    "text": "HW1: Fun with Vectors and Rasters\n\nQuestion 1 [Multiple Choice!]: Understanding the WKT geometries conceptually\nQuestion 2: Using the WKT geometries to create Vectortown\nQuestion 3: Using the raster format (today‚Äôs lecture) to create Gridtopia"
  },
  {
    "objectID": "w03/slides.html#hw1-rightarrow-hw2",
    "href": "w03/slides.html#hw1-rightarrow-hw2",
    "title": "Week 3: Vector and Raster Representations",
    "section": "HW1 \\(\\rightarrow\\) HW2",
    "text": "HW1 \\(\\rightarrow\\) HW2\n\nOnce you finish HW1, you‚Äôll know how to create geometries with sf and terra\nSo now, what can you do with them?\nFor example, we‚Äôd like to be able to say things like:\n\n‚ÄúThe new lamppost cannot be placed at \\((x, y)\\), since there is already a building there!‚Äù\n‚ÄúThere are \\(N_1\\) lampposts in County 1, and \\(N_2\\) lampposts in County 2‚Äù\n‚ÄúThe average resident in Neighborhood A lives 2 km away from their nearest bus stop"
  },
  {
    "objectID": "w03/slides.html#first-things-first-loading-and-saving",
    "href": "w03/slides.html#first-things-first-loading-and-saving",
    "title": "Week 3: Vector and Raster Representations",
    "section": "First Things First: Loading and Saving",
    "text": "First Things First: Loading and Saving\n\nNote how there were no data files in HW1 üò±\nFrom HW2 onwards (and in your GIS life), we‚Äôll:\n\nDownload from e.g.¬†city Open Data Portals: geo data files, but also loading on-the-fly (this week)\nSummarize/aggregate (this week and next week)\nVisualize findings (‚ÄúMapping Libraries‚Äù unit)"
  },
  {
    "objectID": "w03/slides.html#shapefiles-.shp-et-al.",
    "href": "w03/slides.html#shapefiles-.shp-et-al.",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Shapefiles (.shp et al.)",
    "text": "Shapefiles (.shp et al.)\nA shape‚Äúfile‚Äù is actually (at least) three separate files bundled together:\n\n Mandatory .shp: Containing feature geometries\n Mandatory .shx: Positional indices\n Mandatory .dbf: Data attributes\n Optional .prj: Coordinate reference system\n Optional .xml: Metadata"
  },
  {
    "objectID": "w03/slides.html#shapefiles",
    "href": "w03/slides.html#shapefiles",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Shapefiles",
    "text": "Shapefiles\nLet‚Äôs see what‚Äôs inside the shapefile we first saw in Week 1, containing data on DC‚Äôs Census Tracts: Census Tracts in 2020\n\nDC Census Tracts (with the Georgetown campus tract highlighted!) from OpenData.DC.gov"
  },
  {
    "objectID": "w03/slides.html#shapefile-anatomy",
    "href": "w03/slides.html#shapefile-anatomy",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Shapefile Anatomy",
    "text": "Shapefile Anatomy\n\nFrom Rodrigue (2016)"
  },
  {
    "objectID": "w03/slides.html#geojson-topojson-.geojson",
    "href": "w03/slides.html#geojson-topojson-.geojson",
    "title": "Week 3: Vector and Raster Representations",
    "section": "GeoJSON / TopoJSON (.geojson)",
    "text": "GeoJSON / TopoJSON (.geojson)\n\n\n\nJavaScript Object Notation: General cross-platform format\nUseful when data is too complex for e.g.¬†.csv\nTopoJSON = Memory-efficient GeoJSON\nBonus: Inline preview on GitHub!\n\n\n\n\nmy_data.geojson\n\n{\n  \"type\": \"FeatureCollection\",\n  \"features\": [\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [30, 20], [45, 40],\n            [10, 40], [30, 20]\n          ]\n        ]\n      },\n      \"properties\": {\n        \"color\": \"green\",\n        \"area\": 3565747\n      }\n    },\n    {\n      \"type\": \"Feature\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [15, 5], [40, 10],\n            [10, 20], [5, 10], \n            [15, 5]\n          ]\n        ]\n      },\n      \"properties\": {\n        \"color\": \"red\",\n        \"area\": 3272386\n      }\n    }\n  ]\n}"
  },
  {
    "objectID": "w03/slides.html#geopackage-.gpkg",
    "href": "w03/slides.html#geopackage-.gpkg",
    "title": "Week 3: Vector and Raster Representations",
    "section": "GeoPackage (.gpkg)",
    "text": "GeoPackage (.gpkg)\n\nOpen-source (non-proprietary) data format standard"
  },
  {
    "objectID": "w03/slides.html#raster-formats",
    "href": "w03/slides.html#raster-formats",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Raster Formats",
    "text": "Raster Formats\n\nGeoTIFF (.tif or .tiff)\n\nBased on TIFF format developed at NASA\n\nNetCDF (.nc4)\n\nUsed in earth sciences, as format for data sources measured and distributed multiple times per day over large full-country or full-continent areas."
  },
  {
    "objectID": "w03/slides.html#coordinate-reference-systems-crs",
    "href": "w03/slides.html#coordinate-reference-systems-crs",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Coordinate Reference Systems (CRS)",
    "text": "Coordinate Reference Systems (CRS)\n\nEPSG (European Petroleum Survey Group) Registry: Most common way to specify a CRS\n\nFor example, 4326 is the EPSG code for the WGS84 coordinate system\n\nPROJ: Rather than opaque numeric code like EPSG, uses plaintext ‚Äúproj-strings‚Äù containing parameter info: datum, ellipsoid, projection, and units (e.g.¬†meters). Example: PROJ4 code EPSG:4326 is represented as\n+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\nWKT: Lengthy but human-readable descriptions"
  },
  {
    "objectID": "w03/slides.html#getting-the-geometries",
    "href": "w03/slides.html#getting-the-geometries",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Getting the Geometries",
    "text": "Getting the Geometries\nUsing rnaturalearth with mapview\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(mapview)\nfrance_sf &lt;- ne_countries(country = \"France\", scale = 50)\n(france_map &lt;- mapview(france_sf, label = \"geounit\", legend = FALSE))"
  },
  {
    "objectID": "w03/slides.html#centroid-of-france",
    "href": "w03/slides.html#centroid-of-france",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Centroid of France",
    "text": "Centroid of France\n\n\nCode\nfrance_cent_sf &lt;- sf::st_centroid(france_sf)\nfrance_map + mapview(france_cent_sf, label = \"Centroid\", legend = FALSE)"
  },
  {
    "objectID": "w03/slides.html#one-we-already-saw-union",
    "href": "w03/slides.html#one-we-already-saw-union",
    "title": "Week 3: Vector and Raster Representations",
    "section": "One We Already Saw: Union",
    "text": "One We Already Saw: Union\nComputing the union of all geometries in the sf via sf::st_union()\n\n\nCode\nlibrary(leaflet.extras2)\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nafrica_union_map &lt;- mapview(africa_union_sf, label=\"st_union(africa)\", legend=FALSE)\nafrica_map | africa_union_map"
  },
  {
    "objectID": "w03/slides.html#helpful-for-rasterizing-bbox",
    "href": "w03/slides.html#helpful-for-rasterizing-bbox",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Helpful for Rasterizing: BBox",
    "text": "Helpful for Rasterizing: BBox\n\n\nCode\nafrica_bbox_sf &lt;- sf::st_bbox(africa_sf)\nafrica_bbox_map &lt;- mapview(africa_bbox_sf, label=\"st_bbox(africa)\", legend=FALSE)\nafrica_map | africa_bbox_map"
  },
  {
    "objectID": "w03/slides.html#convex-hulls-by-country",
    "href": "w03/slides.html#convex-hulls-by-country",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Convex Hulls by Country",
    "text": "Convex Hulls by Country\n\n\nCode\nafrica_countries_cvx &lt;- sf::st_convex_hull(africa_sf)\nafrica_countries_cvx_map &lt;- mapview(africa_countries_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_countries_cvx_map"
  },
  {
    "objectID": "w03/slides.html#convex-hull-of-continent",
    "href": "w03/slides.html#convex-hull-of-continent",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Convex Hull of Continent",
    "text": "Convex Hull of Continent\nUse st_union() first:\n\n\nCode\nafrica_cvx &lt;- africa_sf |&gt; st_union() |&gt; st_convex_hull()\nafrica_cvx_map &lt;- mapview(africa_cvx, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cvx_map"
  },
  {
    "objectID": "w03/slides.html#one-we-already-saw-centroids",
    "href": "w03/slides.html#one-we-already-saw-centroids",
    "title": "Week 3: Vector and Raster Representations",
    "section": "One We Already Saw: Centroids",
    "text": "One We Already Saw: Centroids\nComputing the centroid of all geometries in the sf via sf::st_centroid()\n\n\nCode\nafrica_cents_sf &lt;- sf::st_centroid(africa_sf)\nafrica_cents_map &lt;- mapview(africa_cents_sf, label=\"geounit\", legend=FALSE)\nafrica_map | africa_cents_map"
  },
  {
    "objectID": "w03/slides.html#spatial-joins",
    "href": "w03/slides.html#spatial-joins",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Spatial Joins",
    "text": "Spatial Joins\n\n\n\nCode\nnc &lt;- system.file(\"shape/nc.shp\", package=\"sf\") |&gt;\n  read_sf() |&gt;\n  st_transform('EPSG:2264')\ngr &lt;- st_sf(\n         label = apply(expand.grid(1:10, LETTERS[10:1])[,2:1], 1, paste0, collapse = \"\"),\n         geom = st_make_grid(nc))\ngr$col &lt;- sf.colors(10, categorical = TRUE, alpha = .3)\n# cut, to verify that NA's work out:\ngr &lt;- gr[-(1:30),]\nsuppressWarnings(nc_j &lt;- st_join(nc, gr, largest = TRUE))\npar(mfrow = c(2,1), mar = rep(0,4))\nplot(st_geometry(nc_j), border = 'grey')\nplot(st_geometry(gr), add = TRUE, col = gr$col)\ntext(st_coordinates(st_centroid(st_geometry(gr))), labels = gr$label, cex = .85)\n# the joined dataset:\nplot(st_geometry(nc_j), border = 'grey', col = nc_j$col)\ntext(st_coordinates(st_centroid(st_geometry(nc_j))), labels = nc_j$label, cex = .7)\nplot(st_geometry(gr), border = '#88ff88aa', add = TRUE)"
  },
  {
    "objectID": "w03/slides.html#spatial-sampling",
    "href": "w03/slides.html#spatial-sampling",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Spatial Sampling",
    "text": "Spatial Sampling\n\n\nCode\n# Sample random points\nafrica_points_list &lt;- sf::st_sample(africa_union_sf, 10)\nafrica_points_sf &lt;- sf::st_sf(africa_points_list)\nafrica_points_map &lt;- mapview(africa_points_sf, label=\"Random Point\", col.regions=cb_palette[1], legend=FALSE)\nafrica_map + africa_points_map"
  },
  {
    "objectID": "w03/slides.html#the-default-predicate-st_intersects",
    "href": "w03/slides.html#the-default-predicate-st_intersects",
    "title": "Week 3: Vector and Raster Representations",
    "section": "The ‚ÄúDefault‚Äù Predicate: st_intersects",
    "text": "The ‚ÄúDefault‚Äù Predicate: st_intersects\n\n\nCode\ncountries_w_points &lt;- africa_sf[africa_points_sf,]\nmapview(countries_w_points, label=\"geounit\", legend=FALSE) + africa_points_map"
  },
  {
    "objectID": "w03/slides.html#counting-with-lengths",
    "href": "w03/slides.html#counting-with-lengths",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Counting with lengths()",
    "text": "Counting with lengths()\n\n\nCode\ncountry_inter &lt;- sf::st_intersects(africa_sf, africa_points_sf)\n# Computes point counts for each polygon\n(num_intersections &lt;- lengths(country_inter))\n\n\n [1] 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2\n\n\nCode\nafrica_sf &lt;- africa_sf |&gt; mutate(\n  num_points = num_intersections\n) |&gt; arrange(geounit)\nafrica_sf |&gt; select(geounit, num_points) |&gt; head()\n\n\n\n\n\n\ngeounit\nnum_points\ngeometry\n\n\n\n\nAlgeria\n2\nMULTIPOLYGON (((8.576563 36‚Ä¶\n\n\nAngola\n2\nMULTIPOLYGON (((13.07275 -4‚Ä¶\n\n\nBenin\n0\nMULTIPOLYGON (((1.622656 6‚Ä¶.\n\n\nBotswana\n0\nMULTIPOLYGON (((25.25879 -1‚Ä¶\n\n\nBurkina Faso\n0\nMULTIPOLYGON (((0.9004883 1‚Ä¶\n\n\nBurundi\n0\nMULTIPOLYGON (((30.55361 -2‚Ä¶"
  },
  {
    "objectID": "w03/slides.html#plotting-with-mapview",
    "href": "w03/slides.html#plotting-with-mapview",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Plotting with mapview",
    "text": "Plotting with mapview\n\n\nCode\nmapview(africa_sf, zcol=\"num_points\")"
  },
  {
    "objectID": "w03/slides.html#plotting-with-ggplot2",
    "href": "w03/slides.html#plotting-with-ggplot2",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Plotting with ggplot2",
    "text": "Plotting with ggplot2\nSince we‚Äôre starting to get into data attributes rather than geometric features, switching to ggplot2 is recommended!\n\n\nCode\nafrica_sf |&gt; ggplot(aes(fill=num_points)) +\n  geom_sf() +\n  theme_classic()"
  },
  {
    "objectID": "w03/slides.html#getting-fancier",
    "href": "w03/slides.html#getting-fancier",
    "title": "Week 3: Vector and Raster Representations",
    "section": "Getting Fancier‚Ä¶",
    "text": "Getting Fancier‚Ä¶\n\nTo do fancier geospatial operations, we‚Äôll need to start overthinking the different possible relationships between two or more geometries!\nTo this end: predicates"
  },
  {
    "objectID": "w03/slides.html#de-9im-strings",
    "href": "w03/slides.html#de-9im-strings",
    "title": "Week 3: Vector and Raster Representations",
    "section": "DE-9IM Strings",
    "text": "DE-9IM Strings\n\n\nCode\nlibrary(sf)\npolygon &lt;- po &lt;- st_polygon(list(rbind(c(0,0), c(1,0), c(1,1), c(0,1), c(0,0))))\np0 &lt;- st_polygon(list(rbind(c(-1,-1), c(2,-1), c(2,2), c(-1,2), c(-1,-1))))\nline &lt;- li &lt;- st_linestring(rbind(c(.5, -.5), c(.5, 0.5)))\ns &lt;- st_sfc(po, li)\n\npar(mfrow = c(3,3))\npar(mar = c(1,1,1,1))\n\n# \"1020F1102\"\n# 1: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5,0), c(.5,.495)), col = 'red', lwd = 2)\npoints(0.5, 0.5, pch = 1)\n\n# 2: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"B(line) = 0\")))\npoints(0.5, 0.5, col = 'red', pch = 16)\n\n# 3: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"E(line) = 2\")))\nplot(po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n# 4: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"I(line) = 0\")))\npoints(.5, 0, col = 'red', pch = 16)\n\n# 5: F\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"B(line) = F\")))\n\n# 6: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"E(line) = 1\")))\nplot(po, border = 'red', col = NA, add = TRUE, lwd = 2)\n\n# 7: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5, -.5), c(.5, 0)), col = 'red', lwd = 2)\n\n# 8: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"B(line) = 0\")))\npoints(.5, -.5, col = 'red', pch = 16)\n\n# 9: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"E(line) = 2\")))\nplot(p0 / po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n\n\n\nThe predicate equals corresponds to the DE-9IM string \"T*F**FFF*\". If any two geometries obey this relationship, they are (topologically) equal!"
  },
  {
    "objectID": "w03/slides.html#references",
    "href": "w03/slides.html#references",
    "title": "Week 3: Vector and Raster Representations",
    "section": "References",
    "text": "References\n\n\nRodrigue, Jean-Paul. 2016. The Geography of Transport Systems. Taylor & Francis."
  },
  {
    "objectID": "w05/index.html",
    "href": "w05/index.html",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#spatial-joins",
    "href": "w05/index.html#spatial-joins",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Spatial Joins",
    "text": "Spatial Joins\n\n\nCode\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nnc &lt;- system.file(\"shape/nc.shp\", package=\"sf\") |&gt;\n  read_sf() |&gt;\n  st_transform('EPSG:2264')\ngr &lt;- st_sf(\n         label = apply(expand.grid(1:10, LETTERS[10:1])[,2:1], 1, paste0, collapse = \"\"),\n         geom = st_make_grid(nc))\ngr$col &lt;- sf.colors(10, categorical = TRUE, alpha = .3)\n# cut, to verify that NA's work out:\ngr &lt;- gr[-(1:30),]\nsuppressWarnings(nc_j &lt;- st_join(nc, gr, largest = TRUE))\npar(mfrow = c(2,1), mar = rep(0,4))\nplot(st_geometry(nc_j), border = 'grey')\nplot(st_geometry(gr), add = TRUE, col = gr$col)\ntext(st_coordinates(st_centroid(st_geometry(gr))), labels = gr$label, cex = .85)\n# the joined dataset:\nplot(st_geometry(nc_j), border = 'grey', col = nc_j$col)\ntext(st_coordinates(st_centroid(st_geometry(nc_j))), labels = nc_j$label, cex = .7)\nplot(st_geometry(gr), border = '#88ff88aa', add = TRUE)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#spatial-sampling",
    "href": "w05/index.html#spatial-sampling",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Spatial Sampling",
    "text": "Spatial Sampling\n\n\nCode\n# Sample random points\nafrica_points_list &lt;- sf::st_sample(africa_union_sf, 10)\nafrica_points_sf &lt;- sf::st_sf(africa_points_list)\nafrica_points_map &lt;- mapview(africa_points_sf, label=\"Random Point\", col.regions=cb_palette[1], legend=FALSE)\n\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\nCode\nafrica_map + africa_points_map",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-default-predicate-st_intersects",
    "href": "w05/index.html#the-default-predicate-st_intersects",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "The ‚ÄúDefault‚Äù Predicate: st_intersects",
    "text": "The ‚ÄúDefault‚Äù Predicate: st_intersects\n\n\nCode\ncountries_w_points &lt;- africa_sf[africa_points_sf,]\nmapview(countries_w_points, label=\"geounit\", legend=FALSE) + africa_points_map",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#counting-with-lengths",
    "href": "w05/index.html#counting-with-lengths",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Counting with lengths()",
    "text": "Counting with lengths()\n\n\nCode\ncountry_inter &lt;- sf::st_intersects(africa_sf, africa_points_sf)\n# Computes point counts for each polygon\n(num_intersections &lt;- lengths(country_inter))\n\n\n [1] 0 1 0 0 0 0 0 3 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n\n\nCode\nafrica_sf &lt;- africa_sf |&gt; mutate(\n  num_points = num_intersections\n) |&gt; arrange(geounit)\nafrica_sf |&gt; select(geounit, num_points) |&gt; head()\n\n\n\n\n\n\ngeounit\nnum_points\ngeometry\n\n\n\n\nAlgeria\n0\nMULTIPOLYGON (((8.576563 36‚Ä¶\n\n\nAngola\n1\nMULTIPOLYGON (((13.07275 -4‚Ä¶\n\n\nBenin\n0\nMULTIPOLYGON (((1.622656 6‚Ä¶.\n\n\nBotswana\n0\nMULTIPOLYGON (((25.25879 -1‚Ä¶\n\n\nBurkina Faso\n0\nMULTIPOLYGON (((0.9004883 1‚Ä¶\n\n\nBurundi\n0\nMULTIPOLYGON (((30.55361 -2‚Ä¶",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#plotting-with-mapview",
    "href": "w05/index.html#plotting-with-mapview",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Plotting with mapview",
    "text": "Plotting with mapview\n\n\nCode\nmapview(africa_sf, zcol=\"num_points\")",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#plotting-with-ggplot2",
    "href": "w05/index.html#plotting-with-ggplot2",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Plotting with ggplot2",
    "text": "Plotting with ggplot2\nSince we‚Äôre starting to get into data attributes rather than geometric features, switching to ggplot2 is recommended!\n\n\nCode\nafrica_sf |&gt; ggplot(aes(fill=num_points)) +\n  geom_sf() +\n  theme_classic()",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#one-more-unary-operation-st_buffer",
    "href": "w05/index.html#one-more-unary-operation-st_buffer",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "One More Unary Operation: st_buffer()",
    "text": "One More Unary Operation: st_buffer()\n\nThink about how you might answer questions like:\n\n‚ÄúHow far is your house (POINT) from Manhattan (POLYGON)?‚Äù\n‚ÄúAre there any chemical plants within a mile of this building (POLYGON) / stretch of road (LINESTRING)?‚Äù\n\nLazy mode (my favorite mode): Compute distances from the centroid\nGIS master mode: Construct the buffer!",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#on-polygons",
    "href": "w05/index.html#on-polygons",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "On POLYGONs",
    "text": "On POLYGONs\nKey line: manhattan_buffer_sf &lt;- manhattan_union_sf |&gt; st_buffer(dist = 1609.34) (1 mile \\(\\approx\\) 1609.34 meters)\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(mapview)\noptions(tigris_use_cache = TRUE)\nmanhattan_sf &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  state = \"NY\",\n  county = \"New York\",\n  year = 2020,\n  geometry = TRUE,\n  cb = FALSE\n)\n# Erase the island tracts real quick\nisland_tracts &lt;- c(\n  \"Census Tract 1, New York County, New York\",\n  \"Census Tract 2.02, New York County, New York\"\n)\nmanhattan_sf &lt;- manhattan_sf |&gt; filter(\n  !(NAME %in% island_tracts)\n)\n# Union of all census tracts within the county\nmanhattan_union_sf &lt;- st_union(manhattan_sf)\nmanhattan_union_map &lt;- mapview(manhattan_union_sf, label=\"New York County\")\n# Construct buffer (1 mile ~= 1609.34 meters)\nmanhattan_buffer_sf &lt;- manhattan_union_sf |&gt; st_buffer(dist = 1609.34)\nmanhattan_buffer_map &lt;- mapview(manhattan_buffer_sf, label=\"Buffer (1 Mile)\", col.regions = cbPalette[1], legend = TRUE)\nmanhattan_buffer_map + manhattan_union_map",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#on-linestrings",
    "href": "w05/index.html#on-linestrings",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "On LINESTRINGs",
    "text": "On LINESTRINGs\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\n## st_buffer, style options (taken from rgeos gBuffer)\nl1 = st_as_sfc(\"LINESTRING(0 0,1 5,4 5,5 2,8 2,9 4,4 6.5)\")\nop = par(mfrow=c(2,3))\nplot(st_buffer(l1, dist = 1, endCapStyle=\"ROUND\"), reset = FALSE, main = \"endCapStyle: ROUND\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, endCapStyle=\"FLAT\"), reset = FALSE, main = \"endCapStyle: FLAT\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, endCapStyle=\"SQUARE\"), reset = FALSE, main = \"endCapStyle: SQUARE\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, nQuadSegs=1), reset = FALSE, main = \"nQuadSegs: 1\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, nQuadSegs=2), reset = FALSE, main = \"nQuadSegs: 2\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, nQuadSegs= 5), reset = FALSE, main = \"nQuadSegs: 5\")\nplot(l1,col='blue',add=TRUE)\n\n\n\n\n\nFrom the sf Documentation",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#what-makes-binary-operations-fancier",
    "href": "w05/index.html#what-makes-binary-operations-fancier",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "What Makes Binary Operations ‚ÄúFancier‚Äù?",
    "text": "What Makes Binary Operations ‚ÄúFancier‚Äù?\n\n\n\nUnary\n\n\nst_centroid()\n\nPOLYGON \\(\\mapsto\\) POINT\nMULTIPOLYGON \\(\\mapsto\\) POINT\n\nst_convex_hull()\n\nPOLYGON \\(\\mapsto\\) POLYGON\nMULTIPOINT \\(\\mapsto\\) POLYGON\n\n\n\n\nBinary\n\n\nst_intersection()\n\n(POINT, POINT) \\(\\mapsto\\) POINT | POINT EMPTY\n(POLYGON, POLYGON) \\(\\mapsto\\) POLYGON | LINESTRING | POINT | POLYGON EMPTY\n\n\n\n\n\nst_is_empty() and st_dimension() become your new best friends üòâ\nst_is_empty(): Distinguishes between, e.g., POINT EMPTY and POINT(0 0)\nst_dimension(): NA for empty versions, otherwise\n\n2 for surfaces (POLYGON, MULTIPOLYGON)\n1 for lines (LINESTRING, MULTILINESTRING)\n0 for points (POINT, MULTIPOINT)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-bad-kind-of-overthinking-will-my-life-just-get-harder-and-harder",
    "href": "w05/index.html#the-bad-kind-of-overthinking-will-my-life-just-get-harder-and-harder",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "The Bad Kind of Overthinking: Will My Life Just Get Harder and Harder?",
    "text": "The Bad Kind of Overthinking: Will My Life Just Get Harder and Harder?\n\n\n\n\n\n\n\n\n\n\nUnary Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinary Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\nTernary Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuaternary Operations",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#good-news-and-bad-news",
    "href": "w05/index.html#good-news-and-bad-news",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Good News and Bad News",
    "text": "Good News and Bad News\n\nThe good news: No!\nThe bad news: You‚Äôll have to read the 465-page Volume I and then the 451-page Volume II and then to page 15 of Volume III of Cohn (1965) to know why:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(i spent 4 yrs of undergrad studying abstract algebra and now it all sits gathering dust somewhere deep within my brain plz just let me have this moment i‚Äôll never mention it again i promise)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#the-good-kind-of-overthinking",
    "href": "w05/index.html#the-good-kind-of-overthinking",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "The Good Kind of Overthinking‚Ä¶",
    "text": "The Good Kind of Overthinking‚Ä¶\n\nFor fancier geospatial operations, we‚Äôll need to start overthinking, about the possible relationships between two (or more) geometries! \\(\\leadsto\\) Relational Predicates:\n\n\n\n\nFigure 4.2 in Lovelace, Nowosad, and Muenchow (2024)",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#de-9im-strings",
    "href": "w05/index.html#de-9im-strings",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "DE-9IM Strings",
    "text": "DE-9IM Strings\nEach cell here visualizes one component of the DE-9IM string 1020F1102, which describes the relationship between the following two geometries:\n\nBoxey McBoxface: POLYGON(0 0, 1 0, 1 1, 0 1, 0 0)\nLiney McLineface: LINESTRING(0.5 -0.5, 0.5 0.5)\n\n\n\nCode\nlibrary(sf)\npolygon &lt;- po &lt;- st_polygon(list(rbind(c(0,0), c(1,0), c(1,1), c(0,1), c(0,0))))\np0 &lt;- st_polygon(list(rbind(c(-1,-1), c(2,-1), c(2,2), c(-1,2), c(-1,-1))))\nline &lt;- li &lt;- st_linestring(rbind(c(.5, -.5), c(.5, 0.5)))\ns &lt;- st_sfc(po, li)\n\npar(mfrow = c(3,3))\npar(mar = c(1,1,1,1))\n\n# \"1020F1102\"\n# 1: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5,0), c(.5,.495)), col = 'red', lwd = 2)\npoints(0.5, 0.5, pch = 1)\n\n# 2: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"B(line) = 0\")))\npoints(0.5, 0.5, col = 'red', pch = 16)\n\n# 3: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"E(line) = 2\")))\nplot(po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n# 4: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"I(line) = 0\")))\npoints(.5, 0, col = 'red', pch = 16)\n\n# 5: F\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"B(line) = F\")))\n\n# 6: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"E(line) = 1\")))\nplot(po, border = 'red', col = NA, add = TRUE, lwd = 2)\n\n# 7: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5, -.5), c(.5, 0)), col = 'red', lwd = 2)\n\n# 8: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"B(line) = 0\")))\npoints(.5, -.5, col = 'red', pch = 16)\n\n# 9: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"E(line) = 2\")))\nplot(p0 / po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n\n\n\n\nCode from Pebesma and Bivand (2023)\n\n\n\n\n\nThe predicate equals corresponds to the DE-9IM string \"T*F**FFF*\". If any two geometries obey this relationship, they are (topologically) equal!",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#slowing-down-9im-no-de-yet",
    "href": "w05/index.html#slowing-down-9im-no-de-yet",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Slowing Down: 9IM (no DE yet!)",
    "text": "Slowing Down: 9IM (no DE yet!)\n\n\n\nTable¬†1: From OSGeo Project\n\n\n\n\n\n\n\n\n\n\n\n9IM\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\n¬†\n¬†\n¬†\n\n\nBoundary\n¬†\n¬†\n¬†\n\n\nExterior",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#dimensionally-extended-de-9im",
    "href": "w05/index.html#dimensionally-extended-de-9im",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Dimensionally Extended (DE) 9IM",
    "text": "Dimensionally Extended (DE) 9IM\n\n\n\nTable¬†2: From OSGeo Project\n\n\n\n\n\n\n\n\n\n\n\n9IM\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\n2\n1\n2\n\n\nBoundary\n1\n0\n1\n\n\nExterior\n2\n1\n2",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#crunching-it-down-into-a-tiny-box",
    "href": "w05/index.html#crunching-it-down-into-a-tiny-box",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Crunching it Down into a Tiny Box",
    "text": "Crunching it Down into a Tiny Box\n\n\n\nDE-9IM\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\n2\n1\n2\n\n\nBoundary\n1\n0\n1\n\n\nExterior\n2\n1\n2\n\n\n\n\nAnd Then into a Tiny String\n\n\n212101212\n\n\nAnd Then into an Infinitesimally-Small Point",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#de-9im-masks",
    "href": "w05/index.html#de-9im-masks",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "DE-9IM Masks",
    "text": "DE-9IM Masks\n\nNow terms can be given unambiguous, precise meaning!\n\n\n\n\nst_overlaps()\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\nT\n*\nT\n\n\nBoundary\n*\n*\n*\n\n\nExterior\nT\n*\n*\n\n\n\n\nSpecial Values (besides 0, 1, 2):\n\nT: ‚ÄúTrue‚Äù (non-empty, st_dimension() &gt;= 0)\nF: ‚ÄúFalse‚Äù (empty, st_dimension() == NA)\n*: ‚ÄúWildcard‚Äù (Don‚Äôt care what the value is)\n\nst_overlaps(): T*T***T**, st_equals(): T*F**FFF*",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#de-9im-vs.-everyday-language",
    "href": "w05/index.html#de-9im-vs.-everyday-language",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "DE-9IM vs.¬†Everyday Language",
    "text": "DE-9IM vs.¬†Everyday Language\n\nDE-9IM can (in theory) represent \\(6^9 = 10~077~696\\) possible geometric relationships!\nThe English language has like 10, and they‚Äôre ambiguous ‚ò†Ô∏è (Compromise employed by GIS systems: allow multiple masks for same English word:)\n\n\n\n\nEnglish\nMask\n212101212\nResult\n\n\n\n\n‚ÄúDisjoint‚Äù\nFF*FF****\nFALSE\nx not disjoint from y\n\n\n‚ÄúTouches‚Äù\nFT*******\nFALSE\nx doesn‚Äôt touch y\n\n\n‚ÄúTouches‚Äù\nF***T****\nFALSE\nx doesn‚Äôt touch y\n\n\n‚ÄúCrosses‚Äù\nT*T***T**\nTRUE\nx crosses y\n\n\n‚ÄúWithin‚Äù\nTF*F*****\nFALSE\nx is not within y\n\n\n‚ÄúOverlaps‚Äù\nT*T***T**\nTRUE\nx overlaps y",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#st_relate-the-ultimate-predicate",
    "href": "w05/index.html#st_relate-the-ultimate-predicate",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "st_relate(): The Ultimate Predicate",
    "text": "st_relate(): The Ultimate Predicate\n\n\nCode\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nus &lt;- ne_states(country=\"United States of America\")\ndc &lt;- us |&gt; filter(iso_3166_2 == \"US-DC\")\nus &lt;- us |&gt;\n  mutate(\n    de9im = st_relate(us, dc),\n    touch = st_touches(us, dc, sparse = F)\n  ) |&gt;\n  select(iso_3166_2, name, de9im, touch) |&gt;\n  arrange(name)\n\n\nalthough coordinates are longitude/latitude, st_relate assumes that they are\nplanar\n\n\nCode\nus\n\n\n\n\n\n\n\n\n\n\n\n\n\niso_3166_2\nname\nde9im\ntouch\ngeometry\n\n\n\n\nUS-AL\nAlabama\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-87.41958 3‚Ä¶\n\n\nUS-AK\nAlaska\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-141.0056 6‚Ä¶\n\n\nUS-AZ\nArizona\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-111.0063 3‚Ä¶\n\n\nUS-AR\nArkansas\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-90.30422 3‚Ä¶\n\n\nUS-CA\nCalifornia\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-114.7243 3‚Ä¶\n\n\nUS-CO\nColorado\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-109.0463 4‚Ä¶\n\n\nUS-CT\nConnecticut\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-73.6417 41‚Ä¶\n\n\nUS-DE\nDelaware\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-75.05809 3‚Ä¶\n\n\nUS-DC\nDistrict of Columbia\n2FFF1FFF2\nFALSE\nMULTIPOLYGON (((-77.02293 3‚Ä¶\n\n\nUS-FL\nFlorida\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-87.44734 3‚Ä¶\n\n\nUS-GA\nGeorgia\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-80.89029 3‚Ä¶\n\n\nUS-HI\nHawaii\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-154.8996 1‚Ä¶\n\n\nUS-ID\nIdaho\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-117.0382 4‚Ä¶\n\n\nUS-IL\nIllinois\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-89.1237 36‚Ä¶\n\n\nUS-IN\nIndiana\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-84.80608 4‚Ä¶\n\n\nUS-IA\nIowa\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-96.48266 4‚Ä¶\n\n\nUS-KS\nKansas\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-102.0396 3‚Ä¶\n\n\nUS-KY\nKentucky\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-89.42446 3‚Ä¶\n\n\nUS-LA\nLouisiana\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-89.52599 3‚Ä¶\n\n\nUS-ME\nMaine\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.08495 4‚Ä¶\n\n\nUS-MD\nMaryland\nFF2F11212\nTRUE\nMULTIPOLYGON (((-75.64786 3‚Ä¶\n\n\nUS-MA\nMassachusetts\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.19396 4‚Ä¶\n\n\nUS-MI\nMichigan\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-84.4913 46‚Ä¶\n\n\nUS-MN\nMinnesota\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-97.22609 4‚Ä¶\n\n\nUS-MS\nMississippi\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-88.40221 3‚Ä¶\n\n\nUS-MO\nMissouri\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-95.31725 4‚Ä¶\n\n\nUS-MT\nMontana\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-116.0482 4‚Ä¶\n\n\nUS-NE\nNebraska\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-104.0537 4‚Ä¶\n\n\nUS-NV\nNevada\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-114.0425 4‚Ä¶\n\n\nUS-NH\nNew Hampshire\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.50585 4‚Ä¶\n\n\nUS-NJ\nNew Jersey\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-75.54133 3‚Ä¶\n\n\nUS-NM\nNew Mexico\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-108.1375 3‚Ä¶\n\n\nUS-NY\nNew York\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-79.06523 4‚Ä¶\n\n\nUS-NC\nNorth Carolina\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-76.03173 3‚Ä¶\n\n\nUS-ND\nNorth Dakota\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-104.0476 4‚Ä¶\n\n\nUS-OH\nOhio\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-80.52023 4‚Ä¶\n\n\nUS-OK\nOklahoma\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-103.0002 3‚Ä¶\n\n\nUS-OR\nOregon\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-124.4924 4‚Ä¶\n\n\nUS-PA\nPennsylvania\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-79.76301 4‚Ä¶\n\n\nUS-RI\nRhode Island\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.23686 4‚Ä¶\n\n\nUS-SC\nSouth Carolina\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-78.57316 3‚Ä¶\n\n\nUS-SD\nSouth Dakota\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-104.0567 4‚Ä¶\n\n\nUS-TN\nTennessee\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-90.30422 3‚Ä¶\n\n\nUS-TX\nTexas\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-103.3115 2‚Ä¶\n\n\nUS-UT\nUtah\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-111.0502 4‚Ä¶\n\n\nUS-VT\nVermont\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-73.35134 4‚Ä¶\n\n\nUS-VA\nVirginia\nFF2F11212\nTRUE\nMULTIPOLYGON (((-76.01325 3‚Ä¶\n\n\nUS-WA\nWashington\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-122.753 48‚Ä¶\n\n\nUS-WV\nWest Virginia\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-82.58945 3‚Ä¶\n\n\nUS-WI\nWisconsin\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-87.80425 4‚Ä¶\n\n\nUS-WY\nWyoming\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-109.0463 4‚Ä¶",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/index.html#if-you-dont-want-to-scroll",
    "href": "w05/index.html#if-you-dont-want-to-scroll",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "(If You Don‚Äôt Want to Scroll)",
    "text": "(If You Don‚Äôt Want to Scroll)\n\n\nCode\nus |&gt; filter(touch)\n\n\nWarning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0.\n‚Ñπ Please use one dimensional logical vectors instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\niso_3166_2\nname\nde9im\ntouch\ngeometry\n\n\n\n\nUS-MD\nMaryland\nFF2F11212\nTRUE\nMULTIPOLYGON (((-75.64786 3‚Ä¶\n\n\nUS-VA\nVirginia\nFF2F11212\nTRUE\nMULTIPOLYGON (((-76.01325 3‚Ä¶",
    "crumbs": [
      "Week 5: Sep 24"
    ]
  },
  {
    "objectID": "w05/slides.html#spatial-joins",
    "href": "w05/slides.html#spatial-joins",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Spatial Joins",
    "text": "Spatial Joins\n\n\n\nCode\nafrica_sf &lt;- ne_countries(continent = \"Africa\", scale = 50)\nafrica_union_sf &lt;- sf::st_union(africa_sf)\nafrica_map &lt;- mapview(africa_sf, label=\"geounit\", legend=FALSE)\nnc &lt;- system.file(\"shape/nc.shp\", package=\"sf\") |&gt;\n  read_sf() |&gt;\n  st_transform('EPSG:2264')\ngr &lt;- st_sf(\n         label = apply(expand.grid(1:10, LETTERS[10:1])[,2:1], 1, paste0, collapse = \"\"),\n         geom = st_make_grid(nc))\ngr$col &lt;- sf.colors(10, categorical = TRUE, alpha = .3)\n# cut, to verify that NA's work out:\ngr &lt;- gr[-(1:30),]\nsuppressWarnings(nc_j &lt;- st_join(nc, gr, largest = TRUE))\npar(mfrow = c(2,1), mar = rep(0,4))\nplot(st_geometry(nc_j), border = 'grey')\nplot(st_geometry(gr), add = TRUE, col = gr$col)\ntext(st_coordinates(st_centroid(st_geometry(gr))), labels = gr$label, cex = .85)\n# the joined dataset:\nplot(st_geometry(nc_j), border = 'grey', col = nc_j$col)\ntext(st_coordinates(st_centroid(st_geometry(nc_j))), labels = nc_j$label, cex = .7)\nplot(st_geometry(gr), border = '#88ff88aa', add = TRUE)"
  },
  {
    "objectID": "w05/slides.html#spatial-sampling",
    "href": "w05/slides.html#spatial-sampling",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Spatial Sampling",
    "text": "Spatial Sampling\n\n\nCode\n# Sample random points\nafrica_points_list &lt;- sf::st_sample(africa_union_sf, 10)\nafrica_points_sf &lt;- sf::st_sf(africa_points_list)\nafrica_points_map &lt;- mapview(africa_points_sf, label=\"Random Point\", col.regions=cb_palette[1], legend=FALSE)\nafrica_map + africa_points_map"
  },
  {
    "objectID": "w05/slides.html#the-default-predicate-st_intersects",
    "href": "w05/slides.html#the-default-predicate-st_intersects",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "The ‚ÄúDefault‚Äù Predicate: st_intersects",
    "text": "The ‚ÄúDefault‚Äù Predicate: st_intersects\n\n\nCode\ncountries_w_points &lt;- africa_sf[africa_points_sf,]\nmapview(countries_w_points, label=\"geounit\", legend=FALSE) + africa_points_map"
  },
  {
    "objectID": "w05/slides.html#counting-with-lengths",
    "href": "w05/slides.html#counting-with-lengths",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Counting with lengths()",
    "text": "Counting with lengths()\n\n\nCode\ncountry_inter &lt;- sf::st_intersects(africa_sf, africa_points_sf)\n# Computes point counts for each polygon\n(num_intersections &lt;- lengths(country_inter))\n\n\n [1] 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n[39] 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0\n\n\nCode\nafrica_sf &lt;- africa_sf |&gt; mutate(\n  num_points = num_intersections\n) |&gt; arrange(geounit)\nafrica_sf |&gt; select(geounit, num_points) |&gt; head()\n\n\n\n\n\n\ngeounit\nnum_points\ngeometry\n\n\n\n\nAlgeria\n0\nMULTIPOLYGON (((8.576563 36‚Ä¶\n\n\nAngola\n1\nMULTIPOLYGON (((13.07275 -4‚Ä¶\n\n\nBenin\n0\nMULTIPOLYGON (((1.622656 6‚Ä¶.\n\n\nBotswana\n0\nMULTIPOLYGON (((25.25879 -1‚Ä¶\n\n\nBurkina Faso\n0\nMULTIPOLYGON (((0.9004883 1‚Ä¶\n\n\nBurundi\n0\nMULTIPOLYGON (((30.55361 -2‚Ä¶"
  },
  {
    "objectID": "w05/slides.html#plotting-with-mapview",
    "href": "w05/slides.html#plotting-with-mapview",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Plotting with mapview",
    "text": "Plotting with mapview\n\n\nCode\nmapview(africa_sf, zcol=\"num_points\")"
  },
  {
    "objectID": "w05/slides.html#plotting-with-ggplot2",
    "href": "w05/slides.html#plotting-with-ggplot2",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Plotting with ggplot2",
    "text": "Plotting with ggplot2\nSince we‚Äôre starting to get into data attributes rather than geometric features, switching to ggplot2 is recommended!\n\n\nCode\nafrica_sf |&gt; ggplot(aes(fill=num_points)) +\n  geom_sf() +\n  theme_classic()"
  },
  {
    "objectID": "w05/slides.html#one-more-unary-operation-st_buffer",
    "href": "w05/slides.html#one-more-unary-operation-st_buffer",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "One More Unary Operation: st_buffer()",
    "text": "One More Unary Operation: st_buffer()\n\nThink about how you might answer questions like:\n\n‚ÄúHow far is your house (POINT) from Manhattan (POLYGON)?‚Äù\n‚ÄúAre there any chemical plants within a mile of this building (POLYGON) / stretch of road (LINESTRING)?‚Äù\n\nLazy mode (my favorite mode): Compute distances from the centroid\nGIS master mode: Construct the buffer!"
  },
  {
    "objectID": "w05/slides.html#on-polygons",
    "href": "w05/slides.html#on-polygons",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "On POLYGONs",
    "text": "On POLYGONs\nKey line: manhattan_buffer_sf &lt;- manhattan_union_sf |&gt; st_buffer(dist = 1609.34) (1 mile \\(\\approx\\) 1609.34 meters)\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(mapview)\noptions(tigris_use_cache = TRUE)\nmanhattan_sf &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  state = \"NY\",\n  county = \"New York\",\n  year = 2020,\n  geometry = TRUE,\n  cb = FALSE\n)\n# Erase the island tracts real quick\nisland_tracts &lt;- c(\n  \"Census Tract 1, New York County, New York\",\n  \"Census Tract 2.02, New York County, New York\"\n)\nmanhattan_sf &lt;- manhattan_sf |&gt; filter(\n  !(NAME %in% island_tracts)\n)\n# Union of all census tracts within the county\nmanhattan_union_sf &lt;- st_union(manhattan_sf)\nmanhattan_union_map &lt;- mapview(manhattan_union_sf, label=\"New York County\")\n# Construct buffer (1 mile ~= 1609.34 meters)\nmanhattan_buffer_sf &lt;- manhattan_union_sf |&gt; st_buffer(dist = 1609.34)\nmanhattan_buffer_map &lt;- mapview(manhattan_buffer_sf, label=\"Buffer (1 Mile)\", col.regions = cbPalette[1], legend = TRUE)\nmanhattan_buffer_map + manhattan_union_map"
  },
  {
    "objectID": "w05/slides.html#on-linestrings",
    "href": "w05/slides.html#on-linestrings",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "On LINESTRINGs",
    "text": "On LINESTRINGs\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\n## st_buffer, style options (taken from rgeos gBuffer)\nl1 = st_as_sfc(\"LINESTRING(0 0,1 5,4 5,5 2,8 2,9 4,4 6.5)\")\nop = par(mfrow=c(2,3))\nplot(st_buffer(l1, dist = 1, endCapStyle=\"ROUND\"), reset = FALSE, main = \"endCapStyle: ROUND\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, endCapStyle=\"FLAT\"), reset = FALSE, main = \"endCapStyle: FLAT\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, endCapStyle=\"SQUARE\"), reset = FALSE, main = \"endCapStyle: SQUARE\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, nQuadSegs=1), reset = FALSE, main = \"nQuadSegs: 1\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, nQuadSegs=2), reset = FALSE, main = \"nQuadSegs: 2\")\nplot(l1,col='blue',add=TRUE)\nplot(st_buffer(l1, dist = 1, nQuadSegs= 5), reset = FALSE, main = \"nQuadSegs: 5\")\nplot(l1,col='blue',add=TRUE)\n\n\n\nFrom the sf Documentation"
  },
  {
    "objectID": "w05/slides.html#what-makes-binary-operations-fancier",
    "href": "w05/slides.html#what-makes-binary-operations-fancier",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "What Makes Binary Operations ‚ÄúFancier‚Äù?",
    "text": "What Makes Binary Operations ‚ÄúFancier‚Äù?\n\n\n\nUnary\n\n\nst_centroid()\n\nPOLYGON \\(\\mapsto\\) POINT\nMULTIPOLYGON \\(\\mapsto\\) POINT\n\nst_convex_hull()\n\nPOLYGON \\(\\mapsto\\) POLYGON\nMULTIPOINT \\(\\mapsto\\) POLYGON\n\n\n\n\nBinary\n\n\nst_intersection()\n\n(POINT, POINT) \\(\\mapsto\\) POINT | POINT EMPTY\n(POLYGON, POLYGON) \\(\\mapsto\\) POLYGON | LINESTRING | POINT | POLYGON EMPTY\n\n\n\n\nst_is_empty() and st_dimension() become your new best friends üòâ\nst_is_empty(): Distinguishes between, e.g., POINT EMPTY and POINT(0 0)\nst_dimension(): NA for empty versions, otherwise\n\n2 for surfaces (POLYGON, MULTIPOLYGON)\n1 for lines (LINESTRING, MULTILINESTRING)\n0 for points (POINT, MULTIPOINT)"
  },
  {
    "objectID": "w05/slides.html#the-bad-kind-of-overthinking-will-my-life-just-get-harder-and-harder",
    "href": "w05/slides.html#the-bad-kind-of-overthinking-will-my-life-just-get-harder-and-harder",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "The Bad Kind of Overthinking: Will My Life Just Get Harder and Harder?",
    "text": "The Bad Kind of Overthinking: Will My Life Just Get Harder and Harder?\n\n\n\n\n\n\n\n\n\n\nUnary Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinary Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\nTernary Operations\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuaternary Operations"
  },
  {
    "objectID": "w05/slides.html#good-news-and-bad-news",
    "href": "w05/slides.html#good-news-and-bad-news",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Good News and Bad News",
    "text": "Good News and Bad News\n\nThe good news: No!\nThe bad news: You‚Äôll have to read the 465-page Volume I and then the 451-page Volume II and then to page 15 of Volume III of Cohn (1965) to know why:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(i spent 4 yrs of undergrad studying abstract algebra and now it all sits gathering dust somewhere deep within my brain plz just let me have this moment i‚Äôll never mention it again i promise)"
  },
  {
    "objectID": "w05/slides.html#the-good-kind-of-overthinking",
    "href": "w05/slides.html#the-good-kind-of-overthinking",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "The Good Kind of Overthinking‚Ä¶",
    "text": "The Good Kind of Overthinking‚Ä¶\n\nFor fancier geospatial operations, we‚Äôll need to start overthinking, about the possible relationships between two (or more) geometries! \\(\\leadsto\\) Relational Predicates:\n\n\nFigure 4.2 in Lovelace, Nowosad, and Muenchow (2024)"
  },
  {
    "objectID": "w05/slides.html#de-9im-strings",
    "href": "w05/slides.html#de-9im-strings",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "DE-9IM Strings",
    "text": "DE-9IM Strings\nEach cell here visualizes one component of the DE-9IM string 1020F1102, which describes the relationship between the following two geometries:\n\nBoxey McBoxface: POLYGON(0 0, 1 0, 1 1, 0 1, 0 0)\nLiney McLineface: LINESTRING(0.5 -0.5, 0.5 0.5)\n\n\n\nCode\nlibrary(sf)\npolygon &lt;- po &lt;- st_polygon(list(rbind(c(0,0), c(1,0), c(1,1), c(0,1), c(0,0))))\np0 &lt;- st_polygon(list(rbind(c(-1,-1), c(2,-1), c(2,2), c(-1,2), c(-1,-1))))\nline &lt;- li &lt;- st_linestring(rbind(c(.5, -.5), c(.5, 0.5)))\ns &lt;- st_sfc(po, li)\n\npar(mfrow = c(3,3))\npar(mar = c(1,1,1,1))\n\n# \"1020F1102\"\n# 1: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5,0), c(.5,.495)), col = 'red', lwd = 2)\npoints(0.5, 0.5, pch = 1)\n\n# 2: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"B(line) = 0\")))\npoints(0.5, 0.5, col = 'red', pch = 16)\n\n# 3: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"I(pol)\",intersect(),\"E(line) = 2\")))\nplot(po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n# 4: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"I(line) = 0\")))\npoints(.5, 0, col = 'red', pch = 16)\n\n# 5: F\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"B(line) = F\")))\n\n# 6: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"B(pol)\",intersect(),\"E(line) = 1\")))\nplot(po, border = 'red', col = NA, add = TRUE, lwd = 2)\n\n# 7: 1\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"I(line) = 1\")))\nlines(rbind(c(.5, -.5), c(.5, 0)), col = 'red', lwd = 2)\n\n# 8: 0\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"B(line) = 0\")))\npoints(.5, -.5, col = 'red', pch = 16)\n\n# 9: 2\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', main = expression(paste(\"E(pol)\",intersect(),\"E(line) = 2\")))\nplot(p0 / po, col = '#ff8888', add = TRUE)\nplot(s, col = c(NA, 'darkgreen'), border = 'blue', add = TRUE)\n\n\n\nCode from Pebesma and Bivand (2023)\nThe predicate equals corresponds to the DE-9IM string \"T*F**FFF*\". If any two geometries obey this relationship, they are (topologically) equal!"
  },
  {
    "objectID": "w05/slides.html#slowing-down-9im-no-de-yet",
    "href": "w05/slides.html#slowing-down-9im-no-de-yet",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Slowing Down: 9IM (no DE yet!)",
    "text": "Slowing Down: 9IM (no DE yet!)\n\n\n\n\n\n\n\n\n\n\n\n\n9IM\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\n¬†\n¬†\n¬†\n\n\nBoundary\n¬†\n¬†\n¬†\n\n\nExterior\n¬†\n¬†\n¬†\n\n\n\n\n\nTable¬†1: From OSGeo Project"
  },
  {
    "objectID": "w05/slides.html#dimensionally-extended-de-9im",
    "href": "w05/slides.html#dimensionally-extended-de-9im",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Dimensionally Extended (DE) 9IM",
    "text": "Dimensionally Extended (DE) 9IM\n\n\n\n\n\n\n\n\n\n\n\n\n9IM\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\n2\n1\n2\n\n\nBoundary\n1\n0\n1\n\n\nExterior\n2\n1\n2\n\n\n\n\n\nTable¬†2: From OSGeo Project"
  },
  {
    "objectID": "w05/slides.html#crunching-it-down-into-a-tiny-box",
    "href": "w05/slides.html#crunching-it-down-into-a-tiny-box",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "Crunching it Down into a Tiny Box",
    "text": "Crunching it Down into a Tiny Box\n\n\n\nDE-9IM\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\n2\n1\n2\n\n\nBoundary\n1\n0\n1\n\n\nExterior\n2\n1\n2\n\n\n\n\nAnd Then into a Tiny String\n\n\n212101212\n\n\nAnd Then into an Infinitesimally-Small Point"
  },
  {
    "objectID": "w05/slides.html#de-9im-masks",
    "href": "w05/slides.html#de-9im-masks",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "DE-9IM Masks",
    "text": "DE-9IM Masks\n\nNow terms can be given unambiguous, precise meaning!\n\n\n\n\nst_overlaps()\nInterior\nBoundary\nExterior\n\n\n\n\nInterior\nT\n*\nT\n\n\nBoundary\n*\n*\n*\n\n\nExterior\nT\n*\n*\n\n\n\n\nSpecial Values (besides 0, 1, 2):\n\nT: ‚ÄúTrue‚Äù (non-empty, st_dimension() &gt;= 0)\nF: ‚ÄúFalse‚Äù (empty, st_dimension() == NA)\n*: ‚ÄúWildcard‚Äù (Don‚Äôt care what the value is)\n\nst_overlaps(): T*T***T**, st_equals(): T*F**FFF*"
  },
  {
    "objectID": "w05/slides.html#de-9im-vs.-everyday-language",
    "href": "w05/slides.html#de-9im-vs.-everyday-language",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "DE-9IM vs.¬†Everyday Language",
    "text": "DE-9IM vs.¬†Everyday Language\n\nDE-9IM can (in theory) represent \\(6^9 = 10~077~696\\) possible geometric relationships!\nThe English language has like 10, and they‚Äôre ambiguous ‚ò†Ô∏è (Compromise employed by GIS systems: allow multiple masks for same English word:)\n\n\n\n\nEnglish\nMask\n212101212\nResult\n\n\n\n\n‚ÄúDisjoint‚Äù\nFF*FF****\nFALSE\nx not disjoint from y\n\n\n‚ÄúTouches‚Äù\nFT*******\nFALSE\nx doesn‚Äôt touch y\n\n\n‚ÄúTouches‚Äù\nF***T****\nFALSE\nx doesn‚Äôt touch y\n\n\n‚ÄúCrosses‚Äù\nT*T***T**\nTRUE\nx crosses y\n\n\n‚ÄúWithin‚Äù\nTF*F*****\nFALSE\nx is not within y\n\n\n‚ÄúOverlaps‚Äù\nT*T***T**\nTRUE\nx overlaps y"
  },
  {
    "objectID": "w05/slides.html#st_relate-the-ultimate-predicate",
    "href": "w05/slides.html#st_relate-the-ultimate-predicate",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "st_relate(): The Ultimate Predicate",
    "text": "st_relate(): The Ultimate Predicate\n\n\nCode\nlibrary(tidyverse)\nlibrary(rnaturalearth)\nus &lt;- ne_states(country=\"United States of America\")\ndc &lt;- us |&gt; filter(iso_3166_2 == \"US-DC\")\nus &lt;- us |&gt;\n  mutate(\n    de9im = st_relate(us, dc),\n    touch = st_touches(us, dc, sparse = F)\n  ) |&gt;\n  select(iso_3166_2, name, de9im, touch) |&gt;\n  arrange(name)\nus\n\n\n\n\n\n\n\n\n\n\n\n\n\niso_3166_2\nname\nde9im\ntouch\ngeometry\n\n\n\n\nUS-AL\nAlabama\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-87.41958 3‚Ä¶\n\n\nUS-AK\nAlaska\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-141.0056 6‚Ä¶\n\n\nUS-AZ\nArizona\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-111.0063 3‚Ä¶\n\n\nUS-AR\nArkansas\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-90.30422 3‚Ä¶\n\n\nUS-CA\nCalifornia\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-114.7243 3‚Ä¶\n\n\nUS-CO\nColorado\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-109.0463 4‚Ä¶\n\n\nUS-CT\nConnecticut\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-73.6417 41‚Ä¶\n\n\nUS-DE\nDelaware\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-75.05809 3‚Ä¶\n\n\nUS-DC\nDistrict of Columbia\n2FFF1FFF2\nFALSE\nMULTIPOLYGON (((-77.02293 3‚Ä¶\n\n\nUS-FL\nFlorida\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-87.44734 3‚Ä¶\n\n\nUS-GA\nGeorgia\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-80.89029 3‚Ä¶\n\n\nUS-HI\nHawaii\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-154.8996 1‚Ä¶\n\n\nUS-ID\nIdaho\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-117.0382 4‚Ä¶\n\n\nUS-IL\nIllinois\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-89.1237 36‚Ä¶\n\n\nUS-IN\nIndiana\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-84.80608 4‚Ä¶\n\n\nUS-IA\nIowa\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-96.48266 4‚Ä¶\n\n\nUS-KS\nKansas\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-102.0396 3‚Ä¶\n\n\nUS-KY\nKentucky\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-89.42446 3‚Ä¶\n\n\nUS-LA\nLouisiana\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-89.52599 3‚Ä¶\n\n\nUS-ME\nMaine\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.08495 4‚Ä¶\n\n\nUS-MD\nMaryland\nFF2F11212\nTRUE\nMULTIPOLYGON (((-75.64786 3‚Ä¶\n\n\nUS-MA\nMassachusetts\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.19396 4‚Ä¶\n\n\nUS-MI\nMichigan\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-84.4913 46‚Ä¶\n\n\nUS-MN\nMinnesota\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-97.22609 4‚Ä¶\n\n\nUS-MS\nMississippi\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-88.40221 3‚Ä¶\n\n\nUS-MO\nMissouri\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-95.31725 4‚Ä¶\n\n\nUS-MT\nMontana\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-116.0482 4‚Ä¶\n\n\nUS-NE\nNebraska\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-104.0537 4‚Ä¶\n\n\nUS-NV\nNevada\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-114.0425 4‚Ä¶\n\n\nUS-NH\nNew Hampshire\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.50585 4‚Ä¶\n\n\nUS-NJ\nNew Jersey\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-75.54133 3‚Ä¶\n\n\nUS-NM\nNew Mexico\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-108.1375 3‚Ä¶\n\n\nUS-NY\nNew York\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-79.06523 4‚Ä¶\n\n\nUS-NC\nNorth Carolina\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-76.03173 3‚Ä¶\n\n\nUS-ND\nNorth Dakota\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-104.0476 4‚Ä¶\n\n\nUS-OH\nOhio\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-80.52023 4‚Ä¶\n\n\nUS-OK\nOklahoma\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-103.0002 3‚Ä¶\n\n\nUS-OR\nOregon\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-124.4924 4‚Ä¶\n\n\nUS-PA\nPennsylvania\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-79.76301 4‚Ä¶\n\n\nUS-RI\nRhode Island\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-71.23686 4‚Ä¶\n\n\nUS-SC\nSouth Carolina\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-78.57316 3‚Ä¶\n\n\nUS-SD\nSouth Dakota\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-104.0567 4‚Ä¶\n\n\nUS-TN\nTennessee\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-90.30422 3‚Ä¶\n\n\nUS-TX\nTexas\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-103.3115 2‚Ä¶\n\n\nUS-UT\nUtah\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-111.0502 4‚Ä¶\n\n\nUS-VT\nVermont\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-73.35134 4‚Ä¶\n\n\nUS-VA\nVirginia\nFF2F11212\nTRUE\nMULTIPOLYGON (((-76.01325 3‚Ä¶\n\n\nUS-WA\nWashington\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-122.753 48‚Ä¶\n\n\nUS-WV\nWest Virginia\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-82.58945 3‚Ä¶\n\n\nUS-WI\nWisconsin\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-87.80425 4‚Ä¶\n\n\nUS-WY\nWyoming\nFF2FF1212\nFALSE\nMULTIPOLYGON (((-109.0463 4‚Ä¶"
  },
  {
    "objectID": "w05/slides.html#if-you-dont-want-to-scroll",
    "href": "w05/slides.html#if-you-dont-want-to-scroll",
    "title": "Week 5: Binary Operations and DE-9IM",
    "section": "(If You Don‚Äôt Want to Scroll)",
    "text": "(If You Don‚Äôt Want to Scroll)\n\n\nCode\nus |&gt; filter(touch)\n\n\n\n\n\n\n\n\n\n\n\n\n\niso_3166_2\nname\nde9im\ntouch\ngeometry\n\n\n\n\nUS-MD\nMaryland\nFF2F11212\nTRUE\nMULTIPOLYGON (((-75.64786 3‚Ä¶\n\n\nUS-VA\nVirginia\nFF2F11212\nTRUE\nMULTIPOLYGON (((-76.01325 3‚Ä¶\n\n\n\n\n\n\n\n\n\n\nCohn, P. M. 1965. Universal Algebra. Springer Science & Business Media.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2024. Geocomputation with R. CRC Press. https://r.geocompx.org/.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. CRC Press. https://r-spatial.org/book/."
  },
  {
    "objectID": "assignments/hw4/index.html",
    "href": "assignments/hw4/index.html",
    "title": "HW4: International Borders and the Ethnic Cleansing of Palestine",
    "section": "",
    "text": "You may have noticed, in the news, the ‚Äúsudden‚Äù eruption of violence between the Israeli Defense Forces (IDF) and the al-Qassam Brigades (the armed wing of Hamas, the democratically-elected government of the Occupied Palestinian Territories).\nIn this bonus homework you will use spatial point pattern analysis to understand a key piece of historical context which lies at the root of the present-day conflict, namely, the ethnic cleansing of Palestinian-populated villages in 1948, and Israel‚Äôs subsequent refusal to allow refugees from these villages to return to their homes, in violation of Article 49 of the Fourth Geneva Convention, the document which forms the basis for much of modern international law (see, e.g.¬†the 1998 Rome Statute of the International Criminal Court).\nThe centrality of this event for Palestinian refugees (who call it al-Nakba, or ‚ÄúThe Catastrophe‚Äù), and the importance of the Right to Return to their everyday lives, becomes immediately viscerally clear as you approach the UN-administered Aida camp in Beit Lahm, for example (the first refugee camp I ever worked in), and walk underneath the large key of return erected above its entrance Figure¬†1.\n\n\n\n\n\n\nFigure¬†1\n\n\n\nGiven that participants in armed attacks against Israeli occupying forces are disproportionately recruited from these very camps, understanding this linkage between al-Nakba and the present is crucial for understanding the conflict.\nThe data we‚Äôll be using can be understood through three key dates in this era of the conflict:\n\n29 November 1947: The UN announces its partition plan for the former British Mandate of Palestine\n15 May 1948: The armed Jewish groups throughout the former mandate declare independence for the State of Israel\n3 April 1949: Israel signs an armistice agreement with the Hashemite Kingdom of Jordan, leaving much of the present-day West Bank under Jordanian sovereignty (until its invasion and occupation by the IDF in 1967, which lasts to the present day)\n\nThese three dates will ‚Äúbookend‚Äù our hypotheses here, since the historiography of al-Nakba often involves debate around the following basic chronology:\n\nFrom 29 November 1947 until 15 May 1948, the Haganah (see below) conducted a campaign of terror and ethnic cleansing against Palestinian-populated villages, mainly targeting those located within the Jewish areas of the UN Partition Plan\nFrom 15 May 1948 until 3 April 1949, the IDF (see below again) conducted another campaign of terror and ethnic cleansing against Palestinian-populated villages, this time targeting those between the borders at the time of the declaration of independence and Jerusalem, the envisioned capital of Eretz Israel (‚ÄúGreater Israel‚Äù) in the eyes of the Zionist movement.\n\nBefore you begin, make sure to run the following code cell, which:\n\nSets R‚Äôs random seed,\nLoads the libraries we‚Äôll use,\nDefines a colorblind-friendly palette, and\nDefines a constant raster_eps which we‚Äôll use to determine the resolution of our intensity function estimates\n\nAlso, importantly, it switches off sf‚Äôs \\(S^2\\) (spherical geometry) mode, since the UN shapefiles here are incompatible with this mode (for reasons outlined here). Lastly, it defines a constant raster_eps\n\nset.seed(6805)\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\ncb_palette &lt;- c(\n  \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\",\"#0072B2\", \"#D55E00\", \"#CC79A7\"\n)\nraster_eps &lt;- 1000"
  },
  {
    "objectID": "assignments/hw4/index.html#overview",
    "href": "assignments/hw4/index.html#overview",
    "title": "HW4: International Borders and the Ethnic Cleansing of Palestine",
    "section": "",
    "text": "You may have noticed, in the news, the ‚Äúsudden‚Äù eruption of violence between the Israeli Defense Forces (IDF) and the al-Qassam Brigades (the armed wing of Hamas, the democratically-elected government of the Occupied Palestinian Territories).\nIn this bonus homework you will use spatial point pattern analysis to understand a key piece of historical context which lies at the root of the present-day conflict, namely, the ethnic cleansing of Palestinian-populated villages in 1948, and Israel‚Äôs subsequent refusal to allow refugees from these villages to return to their homes, in violation of Article 49 of the Fourth Geneva Convention, the document which forms the basis for much of modern international law (see, e.g.¬†the 1998 Rome Statute of the International Criminal Court).\nThe centrality of this event for Palestinian refugees (who call it al-Nakba, or ‚ÄúThe Catastrophe‚Äù), and the importance of the Right to Return to their everyday lives, becomes immediately viscerally clear as you approach the UN-administered Aida camp in Beit Lahm, for example (the first refugee camp I ever worked in), and walk underneath the large key of return erected above its entrance Figure¬†1.\n\n\n\n\n\n\nFigure¬†1\n\n\n\nGiven that participants in armed attacks against Israeli occupying forces are disproportionately recruited from these very camps, understanding this linkage between al-Nakba and the present is crucial for understanding the conflict.\nThe data we‚Äôll be using can be understood through three key dates in this era of the conflict:\n\n29 November 1947: The UN announces its partition plan for the former British Mandate of Palestine\n15 May 1948: The armed Jewish groups throughout the former mandate declare independence for the State of Israel\n3 April 1949: Israel signs an armistice agreement with the Hashemite Kingdom of Jordan, leaving much of the present-day West Bank under Jordanian sovereignty (until its invasion and occupation by the IDF in 1967, which lasts to the present day)\n\nThese three dates will ‚Äúbookend‚Äù our hypotheses here, since the historiography of al-Nakba often involves debate around the following basic chronology:\n\nFrom 29 November 1947 until 15 May 1948, the Haganah (see below) conducted a campaign of terror and ethnic cleansing against Palestinian-populated villages, mainly targeting those located within the Jewish areas of the UN Partition Plan\nFrom 15 May 1948 until 3 April 1949, the IDF (see below again) conducted another campaign of terror and ethnic cleansing against Palestinian-populated villages, this time targeting those between the borders at the time of the declaration of independence and Jerusalem, the envisioned capital of Eretz Israel (‚ÄúGreater Israel‚Äù) in the eyes of the Zionist movement.\n\nBefore you begin, make sure to run the following code cell, which:\n\nSets R‚Äôs random seed,\nLoads the libraries we‚Äôll use,\nDefines a colorblind-friendly palette, and\nDefines a constant raster_eps which we‚Äôll use to determine the resolution of our intensity function estimates\n\nAlso, importantly, it switches off sf‚Äôs \\(S^2\\) (spherical geometry) mode, since the UN shapefiles here are incompatible with this mode (for reasons outlined here). Lastly, it defines a constant raster_eps\n\nset.seed(6805)\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\nlibrary(spatstat) |&gt; suppressPackageStartupMessages()\ncb_palette &lt;- c(\n  \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\",\"#0072B2\", \"#D55E00\", \"#CC79A7\"\n)\nraster_eps &lt;- 1000"
  },
  {
    "objectID": "assignments/hw4/index.html#loading-and-preparing-the-data",
    "href": "assignments/hw4/index.html#loading-and-preparing-the-data",
    "title": "HW4: International Borders and the Ethnic Cleansing of Palestine",
    "section": "Loading and Preparing the Data",
    "text": "Loading and Preparing the Data\nHere, to avoid the midterm situation where loading and cleaning took up nearly the whole time for most students (üò≠), we carry out the data loading and cleaning for you!\nFirst, we download, unzip, and load the shapefile for the British Mandate of Palestine, as it was constituted in British colonial documents in 1948, on the eve of its (planned) transfer to UN jurisdiction. Since the shapefile corresponds to the Mandate‚Äôs border as it was defined earlier on by the League of Nations, we get a LINESTRING, which we convert to the POLYGON of the mandate using st_cast():\n\njpr_shapefile_url &lt;- \"https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/jpr_data.zip\"\ndownload.file(jpr_shapefile_url, destfile = \"jpr_data.zip\", quiet = TRUE)\nunzip(\"jpr_data.zip\")\n# Delete the Mac OSX metadata\nunlink(\"__MACOSX\", recursive = TRUE)\n\n\nmandate_border_sf &lt;- sf::st_read(\"jpr_data/shapefiles/outside_border.shp\", quiet=TRUE)\nmandate_sf &lt;- mandate_border_sf |&gt; sf::st_cast(\"POLYGON\")\nmandate_sf |&gt; ggplot() +\n  geom_sf() +\n  theme_classic(base_size=10) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n\nNext, we load the dataset on villages in 1947 from McAlexander (2023), where the resulting plot indicates the villages cleansed in each of the two durations mentioned above:\n\nphases &lt;- c(\n  \"Not Cleansed\",\n  \"29 Nov 1947 - 15 May 1948\",\n  \"15 May 1948 - 3 Apr 1949\"\n)\nvill_url &lt;- \"https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/villages_1947.gpkg\"\nvill_47_sf &lt;- sf::st_read(vill_url, quiet=TRUE)\nvill_47_sf &lt;- vill_47_sf |&gt; mutate(cleansed_phase = factor(cleansed_phase, levels=phases))\nggplot() +\n  geom_sf(data=mandate_sf) +\n  geom_sf(data=vill_47_sf, aes(color=cleansed_phase), size=0.5) +\n  scale_color_manual(values=c(\"black\", cb_palette[2], cb_palette[1])) +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n\nAs you can see from this overlay, however, there are no recorded villages in the southern ~half of the Mandate territory. Condensing lots of details, this is not because there were no people in this portion, but because this southern portion was mainly populated by ‚ÄúNegev Bedouin‚Äù, who typically practiced nomadic herding/agriculture rather than settling in one fixed location‚Äîwhich is why it‚Äôs important to keep in mind that the unit of analysis here is villages, not people!\nGiven that the ethnic cleansing of the Bedouin from Mandate Palestine followed its own, somewhat separate trajectory, we will focus in on the non-Bedouin Palestinian villages, and thus take our window of observation to be the northern portion of the Mandate, with the Palestinian village of Bir Seb‚Äôa (ÿ®ÿ¶ÿ± ÿßŸÑÿ≥ÿ®ÿπ) as the ‚Äúcutoff‚Äù point, below which there are no recorded villages in the data:\n\nvill_47_bbox &lt;- vill_47_sf |&gt; sf::st_bbox()\nvill_47_bbox[['xmin']] &lt;- 34.0\nvill_47_bbox[['ymin']] &lt;- 31.2\nnorth_sf &lt;- mandate_sf |&gt; sf::st_crop(vill_47_bbox)\n\nalthough coordinates are longitude/latitude, st_intersection assumes that they\nare planar\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\nggplot() +\n  geom_sf(data=north_sf) +\n  geom_sf(data=vill_47_sf, aes(color=cleansed_phase), size=0.65) +\n  theme_classic() +\n  scale_color_manual(values=c(\"black\", cb_palette[2], cb_palette[1])) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))"
  },
  {
    "objectID": "assignments/hw4/index.html#part-1-cleansing-by-the-yishuv-29-nov-1947-to-15-may-1948",
    "href": "assignments/hw4/index.html#part-1-cleansing-by-the-yishuv-29-nov-1947-to-15-may-1948",
    "title": "HW4: International Borders and the Ethnic Cleansing of Palestine",
    "section": "Part 1: Cleansing by the Yishuv, 29 Nov 1947 to 15 May 1948",
    "text": "Part 1: Cleansing by the Yishuv, 29 Nov 1947 to 15 May 1948\n\nBackground\nThe ‚ÄúYishuv‚Äù (◊ô◊©◊ï◊ë), Hebrew for ‚ÄúSettlement‚Äù, is a general term used to refer to the Jewish population of Ottoman (1881-1917) and British (1917-1948) Palestine, which increased dramatically between the First Aliyah (i.e., the first wave of European Jewish settlement in Palestine) onwards and the establishment of Israel on 15 May 1948, at which point various armed paramilitary groups of the Yishuv were unified to form the Israeli Defense Forces (IDF), the national army of the newly-formed State of Israel.\nThe reason we distinguish between the Yishuv groups and the IDF is precisely because of the tenets of international law (as described by the Fourth Geneva Convention) mentioned above: before 15 May 1948, these groups operated as non-state paramilitary forces within territory under British sovereignty, and therefore had a different legal status from the post-May 15th IDF, which obtained the legal status of ‚Äúofficial‚Äù state military (once Israel signed the Geneva Conventions and had its military and borders subsequently recognized by, e.g., the US, UK, USSR, and so on, leading to their accession to the United Nations less than a year later, on 11 May 1949).\nAs mentioned above, 29 Nov 1947 is our first key date, since it is the day that the UN Partition Plan for Palestine was announced. Skipping lots of details (as in pretty much every part of this assignment, so I‚Äôll stop providing this disclaimer from now on!): although the surrounding Arab nations rejected the UN plan, the Yishuv accepted it and recognized it as a crucial opportunity to gain international legitimacy as a soon-to-be nation-state.\nHowever, in the eyes of Yishuv leaders like David Ben-Gurion (who would become Israel‚Äôs first Prime Minister), this presented a dilemma:\n\nA key precondition of this international legitimacy would be to establish Israel as a ‚Äúdemocratic‚Äù state (and thus qualify for the post-WWII reconstruction efforts being granted to the ‚Äúfree world‚Äù by the United States, a la the Marshall Plan), but‚Ä¶\nThe goal of Zionism, since its inception, had been an ethnostate in Palestine: i.e., a state wherein the Jewish population held uncontested control over all political, economic, and military decisions.\n\nThe second point is perhaps best summarized by Ben-Gurion himself:\n\nIn the area allocated to the Jewish State [in the UN plan mentioned above] there are not more than 520,000 Jews and about 350,000 non-Jews, mostly Arabs. Such a population composition does not provide a stable basis for a Jewish State. With such a composition, there cannot even be absolute certainty that control will remain in the hands of the Jewish majority [‚Ä¶] There can be no stable and strong Jewish state so long as it has a Jewish majority of only 60%. (Source: Downes (2004), Targeting Civilians in War)\n\n\n\nThe Hypothesis\nGiven this dilemma, a natural hypothesis would be that the announcement of the UN plan would spark a campaign of intensified ethnic cleansing by the armed groups of the Yishuv, aiming to drive Palestinians out of villages within the UN-allotted Jewish region until a ‚Äúsafe‚Äù Jewish majority (well above the ‚Äúonly 60%‚Äù mentioned in the above quote) could be secured, at which point independence could be declared for a democratic State of Israel. And indeed, Ben-Gurion would refer to this goal somewhat indirectly as the ‚Äútransfer process‚Äù, a process which was codified in Plan Dalet and explored in McAlexander (2023), the article from which our dataset is drawn.\nThe operationalization of this hypothesis in terms of the data we have, therefore, would involve the null hypothesis that\nVillages were cleansed in proportion to their density across the Mandate, regardless of their position within or outside of the UN-allotted Jewish region\nwhich we compare with the alternative hypothesis that\nVillages within the UN-allotted Jewish region were disproportionately likely to be chosen for cleansing,\ni.e., that their probability of being chosen for cleansing was greater than their spatial density with respect to the distribution of villages across the Mandate.\nTo test this hypothesis, we will need to load the shapefiles corresponding to the UN partition plan, which are again helpfully provided by McAlexander (2023), in the form of the shapefiles for the UN-allotted Palestinian region specifically (the Jewish region being everything in the Mandate besides this territory and besides Jerusalem, which was to be internationally administered by the UN, which we‚Äôll see in Part 2 below). Then we plot the villages cleansed from 29 Nov 1947 to 15 May 1948, the points which we‚Äôll test for disproportionate appearance in the UN-allotted Jewish region:\n\nun_pal_url &lt;- \"https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/un_pal_crop.gpkg\"\nun_pal_sf &lt;- sf::st_read(un_pal_url)\n\nReading layer `un_pal_crop' from data source \n  `https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/un_pal_crop.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1 feature and 0 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 3806734 ymin: 3658750 xmax: 3960787 ymax: 3908699\nProjected CRS: WGS 84 / Pseudo-Mercator\n\nggplot() +\n  geom_sf(data=north_sf) +\n  geom_sf(data=un_pal_sf, fill=cb_palette[3], alpha=0.5) +\n  geom_sf(data=vill_47_sf, aes(color=cleansed_yish_4748), size=0.65) +\n  theme_classic() +\n  scale_color_manual(values=c('black', cb_palette[2], cb_palette[1])) +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n\n\n\nQuestion 1.1: Observed Region Counts\nWe start by computing the observed spatial distribution of (phase-1) cleansed villages, in terms of how many such villages were located in the UN-allotted Jewish and Palestinian regions, respectively. The following plot, therefore, represents the point pattern we‚Äôre hoping to test, in terms of how likely it would be to occur under our null hypothesis:\n\nvill_c4748_sf &lt;- vill_47_sf |&gt; filter(cleansed_yish_4748)\nnum_c4748 &lt;- nrow(vill_c4748_sf)\nplot_title &lt;- paste0(\"Yishuv-Cleansed Villages (N = \",num_c4748,\")\")\nplot_subtitle &lt;- \"15 May 1948 - 3 Apr 1949\"\nggplot() +\n  geom_sf(data=north_sf) +\n  geom_sf(data=un_pal_sf, fill=cb_palette[3], alpha=0.5) +\n  geom_sf(data=vill_c4748_sf, size=0.65) +\n  theme_classic() +\n  scale_color_manual(values=c('black', cb_palette[2], cb_palette[1])) +\n  theme(\n    axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),\n    title = element_text(size=10)\n  ) +\n  labs(title=plot_title, subtitle=plot_subtitle)\n\n\n\n\n\n\n\n\nUsing the above-created sf objects:\n\nnorth_sf, containing a POLYGON representing the northern ~half of the British Mandate of Palestine,\nun_pal_north_sf, containing MULTIPOLYGON representing the UN-allotted Palestinian regions, and\nvill_c4748_sf, containing POINTs representing the villages cleansed by the Yishuv from 29 Nov 1947 to 15 May 1948,\n\nYour goal is to compute the counts of how many villages in vill_c4748_sf fall within the UN-allotted Palestinian region and how many do not fall within this region.\nSince we are interested in the hypothesis that the number of cleansed villages in the UN-allotted Jewish region is disproportionate, we will use this number specifically as our test statistic: store this value in a variable named obs_nc4748_in_jewish.\n\n\n\n\n\n\nTipImplementing a Count Function\n\n\n\nThough it‚Äôs not required, it will save you time later on if you implement this by creating a function named compute_sf_jewish_count(), which takes in an sf object containing POINTs and returns the number of these points that fall outside of un_pal_north_sf.\nThough it requires more thought up-front, it will pay off when you construct the large number of Monte Carlo simulations in Questions 1.3 and 1.4, since you can convert these simulated ppp objects into sf objects (making sure to filter out the window and keep only the simulated POINT observations!), then use this function to compute counts for each simulation.\n\n\n\n# Your code here\n# Recommended, not required: a function for computing this count\ncompute_sf_jewish_count &lt;- function(village_sf) {\n  # Your (optional) code here: compute the number of points in village_sf lying\n  # outside of un_pal_north_sf.\n  return(NULL)\n}\n# Replace with count of cleansed villages in Jewish region\nobs_num_jewish_region &lt;- NULL\n\nYou should obtain the result that 159 villages, out of the 190 total that were cleansed between 29 Nov 1947 and 15 May 1948, were located within the UN-allotted Jewish region. In the remaining questions, you will compare this count with counts obtained via simulation under the null hypothesis.\n\n\nQuestion 1.2: Village Intensity Function\nNow that you have the observed count of how many of the 190 villages chosen for cleansing fell within the UN-allotted Jewish region, we need to evaluate whether this is higher or lower than the count we would expect to see under our null hypothesis!\nTo this end, the first step is to estimate an intensity function of villages across the Mandate territory as they existed in 1947, which will then allow us to simulate the spatial distribution of villages under the null, i.e., simulate what a choice of villages not affected by the UN partition plan would look like. Estimate this intensity function using the density() function from spatstat.random, and store the estimated intensity function in a variable named vill_47_int.\nRemember to use the raster_eps global parameter defined at the top of the notebook for the eps parameter of density()! Otherwise the estimated intensity function might be too coarse (too pixelated) or, even worse, too fine-grained (which might lead to your RAM quickly filling up).\n\nvill_47_int &lt;- NULL # Replace with call to\n\n\n\nQuestion 1.3: Simulated Region Counts\nNow that you have an intensity function for villages throughout the north of the Mandate, you have what you need to use the spatstat.random::rpoint() function to simulate 190 points drawn from this intensity function! Do this in the following code cell, saving the resulting ppp object as vill_c4748_sim_ppp (with this name chosen since we‚Äôre simulating the locations of cleansed villages between 29 Nov 1947 and 15 May 1948 under the null hypothesis):\n\nvill_c4748_sim_ppp &lt;- NULL # Replace with rpoint() call\n\nIf your ppp object was created as intended, running the following code cell should produce a plot of these simulated villages overlaid on the 1947 village intensity function, which you can use as a ‚Äúsanity check‚Äù (for example, if you observe a large number of villages in the blue low-intensity regions, something may be wrong with your call to rpoint()):\n\nif (!is.null(vill_c4748_sim_ppp)) {\n  vill_47_int_stars &lt;- stars::st_as_stars(vill_47_int)\n  vill_c4748_sim_points_sf &lt;- vill_c4748_sim_ppp |&gt;\n    sf::st_as_sf() |&gt;\n    sf::st_set_crs(3857) |&gt;\n    filter(label == \"point\")\n  ggplot() +\n    geom_stars(data=vill_47_int_stars) +\n    geom_sf(data=vill_c4748_sim_points_sf, size=0.65) +\n    geom_sf(data=un_pal_north_sf, alpha=0.4) +\n    theme_classic() +\n    scale_fill_viridis_c(option=\"C\", na.value=\"transparent\") +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n    labs(title = \"190 Intensity-Sampled Villages\")\n} else {\n  writeLines(\"vill_c4748_sim_ppp object must be created first!\")\n}\n\nvill_c4748_sim_ppp object must be created first!\n\n\n\n\nQuestion 1.4: Computing the Test Statistic\nGiven the resulting ppp object, you should be able to use code similar to the code you wrote in Question 1.1 to count the number of points in vill_47_sim_ppp that fall within the UN-allotted Jewish region of the Mandate. Store this value in a variable named sim_c4748_points and print its value at the end of your code cell.\n\n# Your code here\n\nYou should find that the number of simulated points falling within the UN-allotted Jewish region is lower than the observed number you computed at the end of Question 1.1.\nThis gives us a‚Ä¶ small hint that 159 might be a high number of villages, but we can‚Äôt evaluate the hypothesis on the basis of a single counterfactual simulation! The main point of this question, secretly, was to get you into the habit of writing code for a single simulation, and then plotting the results as a sanity-check that it works, before you think about running 999 of them.\n\n\nQuestion 1.5: Monte Carlo Hypothesis Testing\nHere, your job is to just take the simulation code that you‚Äôve now used to generate one simulation and run it 999 times, to generate 999 ppp objects and then extract the count of the number of cleansed villages in the UN-allotted Jewish area from each. Like in the midterm, this will give you a distribution of test statistics that you can use to judge how unlikely it would be to observe 159 cleansed villages within the UN-allotted Jewish region under the null hypothesis.\nSo, in the following code cell: compute these 999 simulations, derive the test statistic for each, and then use ggplot2 to create a density plot (using geom_density()) of the 999 simulated test statistics, on top of which you should superimpose a dashed line (preferably with the color from the first element of cb_palette) representing the observed test statistic of 159, to see how likely or unlikely this value would be under the null hypothesis.\nAs I‚Äôve mentioned (ranted about) in class, you don‚Äôt need to compute a \\(p\\)-value or confidence interval here. But, below the produced density plot, please provide a sentence or two describing your inference from the plot, in terms of the likelihood that the null hypothesis is true.\n\n# Your code here"
  },
  {
    "objectID": "assignments/hw4/index.html#part-2-cleansing-by-the-idf-15-may-1948-to-3-apr-1949",
    "href": "assignments/hw4/index.html#part-2-cleansing-by-the-idf-15-may-1948-to-3-apr-1949",
    "title": "HW4: International Borders and the Ethnic Cleansing of Palestine",
    "section": "Part 2: Cleansing by the IDF, 15 May 1948 to 3 Apr 1949",
    "text": "Part 2: Cleansing by the IDF, 15 May 1948 to 3 Apr 1949\n\nBackground\nOnce Israel had established itself as a democracy and signed onto the Fourth Geneva Convention, as mentioned above, the borders of the UN-allotted Jewish territory were accepted as the borders of the State of Israel by great powers like the US, UK, and USSR. However, the rejection of the plan by the surrounding Arab nations provided the newly-formed state with a fait accompli to conduct a second phase of the ethnic cleansing campaign, which could now be justified as essentially a ‚Äúside effect‚Äù of the inter-state wars between Israel and, for example:\n\nLebanon to the north,\nEgypt to the southwest (resulting in Egyptian sovereignty over the Gaza Strip), and\nJordan to the east (resulting in Jordanian sovereignty over the West Bank).\n\nHere we will focus on the war with Jordan in particular, for reasons that will become apparent once you visualize the spatial distribution of these phase-2 cleansed villages.\nAfter dropping the villages which had already been cleansed in the first phase (before 15 May 1948), a plot of those cleansed in this second phase immediately gives rise to a plausible hypothesis for their spatial distribution, revolving around the location of Jerusalem within the Jordanian-claimed portion of the UN-allotted Palestinian region.\n\n# Drop phase-1 cleansed villages\nvill_48_sf &lt;- vill_47_sf |&gt; filter(!cleansed_yish_4748)\n# Load POLYGON for Jordan-claimed portion\njord_url &lt;- \"https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/un_jordan_claimed.gpkg\"\njord_sf &lt;- sf::st_read(jord_url)\n\nReading layer `un_jordan_claimed' from data source \n  `https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/un_jordan_claimed.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 34.68605 ymin: 31.22123 xmax: 35.58035 ymax: 32.63122\nGeodetic CRS:  WGS 84\n\n# Load POLYGON for 2024 West Bank\nwb_url &lt;- \"https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/un_ocha_west_bank.gpkg\"\nwb_sf &lt;- sf::st_read(wb_url)\n\nReading layer `un_ocha_west_bank' from data source \n  `https://github.com/jpowerj/dsan-content/raw/refs/heads/main/2024-fall-ppol6805/hw5a/un_ocha_west_bank.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1 feature and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 34.88054 ymin: 31.34269 xmax: 35.57319 ymax: 32.55239\nGeodetic CRS:  WGS 84\n\n# Create sf containing a POINT corresponding to the centroid of the Old City\njeru_df &lt;- tibble::tribble(\n  ~lat, ~lon,\n  31.777908401571544, 35.23166035886802\n)\njeru_sf &lt;- jeru_df |&gt; sf::st_as_sf(\n  coords=c(\"lon\",\"lat\"),\n  crs=4326\n) |&gt; sf::st_transform(3857)\n\n\ngen_p2_plot &lt;- function(include_wb=FALSE) {\n  p2_obj &lt;- ggplot() +\n    geom_sf(data=north_sf, aes(fill=\"Mandate (1917)\"), alpha=0.0) +\n    geom_sf(data=jord_sf, aes(fill=\"UN-Allocated (1947)\"), alpha=0.3, linewidth=0.5) +\n    ifelse(\n      include_wb,\n      geom_sf(data=wb_sf, aes(fill=\"West Bank (2024)\"), alpha=0.6, linewidth=0.5),\n      element_blank()\n    ) +\n    geom_sf(data=vill_48_sf, aes(color=cleansed_idf_4849), size=0.65) +\n    geom_sf(data=jeru_sf, aes(shape=\"Jerusalem\"), fill=cb_palette[4], size=3, stroke=1) +\n    geom_sf(data=sf::st_boundary(north_sf), linewidth=1) +\n    scale_color_manual(\"Cleansed\", values=c(\"black\",cb_palette[1])) +\n    scale_fill_manual(element_blank(), values=c(\"white\",cb_palette[3],cb_palette[3])) +\n    scale_shape_manual(element_blank(), values=21) +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n    labs(title=\"Cleansed Villages, 1948-1949\")\n  return(p2_obj)\n}\ngen_p2_plot()\n\n\n\n\n\n\n\n\nAnd, by overlaying the POLYGON for the modern (2024) West Bank, you can also see how these IDF cleansings essentially determined the final armistice line which divides Israel from the Occupied West Bank to this day:\n\ngen_p2_plot(include_wb=TRUE)\n\n\n\n\n\n\n\n\n\n\nThe Hypothesis\nThough the UN Partition Plan designated Jerusalem as an internationally-administered territory (rather than placing it within the Jewish or Palestinian ‚Äúsides‚Äù), our hypothesis for the second phase is that the IDF wanted to clear a ‚Äúroad to Jerusalem‚Äù from the newly-formed State of Israel, as proposed by (newly-elected Prime Minister) David Ben-Gurion:\n\nIf we defeat them and capture western Galilee or territory on both sides of the road to Jerusalem, these areas will become part of the state. Why should we obligate ourselves to accept boundaries that in any case the Arabs don‚Äôt accept?‚Äù\n\nCleansing the villages which had the misfortune of existing on this ‚Äúroad to Jerusalem‚Äù would, ostensibly, make it easier to wrest Jerusalem from international or Jordanian control via military conquest, which was indeed achieved 19 years later.\nThus our null hypothesis in this part is that:\nVillages were cleansed in proportion to their density within the Jordanian-claimed portion of the UN-allotted Palestinian region, regardless of their distance to Jerusalem\nwhich we compare with the alternative hypothesis that\nVillages closer to Jerusalem were disproportionately likely to be chosen for cleansing.\nTo test this hypothesis, like on the midterm and the previous problem, your job is to conduct 999 Monte Carlo simulations of the null hypothesis, and see how different the observed average distance from Jerusalem is from the 999 simulated average distances.\nNotice that our observation window here is different from the previous part: wheres before we were considering the British Mandate territory as a whole, here we are ‚Äúzooming in‚Äù on just the Jordanian-claimed portion of the UN-allotted Palestinian region. The following code cells set up the necessary sf objects that you‚Äôll use for the remainder of the questions.\nFirst, the collection of all villages in the Jordanian-claimed region (the observation window for this question), which you‚Äôll use to estimate a new ‚Äúvillage intensity function‚Äù for this hypothesis:\n\n# All remaining (non-previously-cleansed) villages in Jordanian-claimed region\nvill_jord_sf &lt;- vill_48_sf |&gt; sf::st_filter(jord_sf)\n\nalthough coordinates are longitude/latitude, st_intersects assumes that they\nare planar\nalthough coordinates are longitude/latitude, st_intersects assumes that they\nare planar\n\nggplot() +\n  geom_sf(data=jord_sf) +\n  geom_sf(data=vill_jord_sf, aes(color=cleansed_idf_4849), size=0.7) +\n  geom_sf(data=jeru_sf, aes(shape=\"Jerusalem\"), fill=cb_palette[4], size=3, stroke=1) +\n  scale_color_manual(values=c(\"black\",cb_palette[1])) +\n  scale_shape_manual(element_blank(), values=21) +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n\n\n\n\n\n\n\nAnd now the subset of just the post-15 May 1848 cleansed villages, the observed point pattern that you will test on the basis of the village intensity function:\n\n# Villages cleansed by IDF, post-15 May 1948\nvill_c4849_sf &lt;- vill_jord_sf |&gt; filter(cleansed_idf_4849)\nnum_c4849 &lt;- nrow(vill_c4849_sf)\nplot_title &lt;- paste0(\"IDF-Cleansed Villages (N = \",num_c4849,\")\")\nplot_subtitle &lt;- \"15 May 1948 - 3 Apr 1949\"\nggplot() +\n  geom_sf(data=jord_sf) +\n  geom_sf(data=vill_c4849_sf, size=0.7) +\n  geom_sf(data=jeru_sf, aes(shape=\"Jerusalem\"), fill=cb_palette[4], size=3, stroke=1) +\n  scale_shape_manual(element_blank(), values=21) +\n  theme_classic() +\n  theme(\n    axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),\n    plot.title = element_text(size=12),\n    plot.subtitle = element_text(size=10)\n  ) +\n  labs(title=plot_title, subtitle=plot_subtitle)\n\n\n\n\n\n\n\n\n\n\nQuestion 2.1: Observed Distances\nYour job in this question is to compute the observed test statistic: in this case, the mean distance between the cleansed villages and the centroid of the Old City of Jerusalem. You can call this obs_mean_dist.\n\nobs_mean_dist &lt;- NULL # Replace with computation of observed mean distance\n\nYou should obtain a value of about 30843.81. Is this low or high? Let‚Äôs use point-process simulation to check!\n\n\nQuestion 2.2: Village Intensity Function\nLike in the Question 1.2, your job here is to use the collection of all remaining villages within the Jordanian-claimed region (the points stored in vill_jord_sf above) to estimate and plot an intensity function, which you should call vill_jord_int.\nAnd, as in Question 1.2 again, please make sure to use the eps parameter when you call density() to ensure a reasonable level of resolution for the (raster-data) intensity function.\n\nvill_jord_int &lt;- NULL # Replace with density() call\n\n\n\nQuestion 2.3: Simulated Points\nHere, as you did in Question 1.3, use the estimated intensity function vill_jord_int to simulate num_c4849 points (num_c4849 is defined above, in the code cell with label q2-cleansed-villages), and store the results of this simulation in a ppp object named vill_c4849_sim_ppp.\n\nvill_c4849_sim_ppp &lt;- NULL # Replace with density() call\n\nLike in Question 1.3, if the intensity function was estimated correctly and the simulation ran as intended, the following code cell should plot the simulated points in vill_c4849_sim_ppp over top of the heatmap based on vill_jord_int, as a sanity check (you can run the q2-3-response code cell and then the following code multiple times, for example, to make sure that points tend to be generated in the regions with greater intensity!)\n\nif (!is.null(vill_c4849_sim_ppp)) {\n  vill_jord_int_stars &lt;- stars::st_as_stars(vill_jord_int)\n  vill_c4849_sim_points_sf &lt;- vill_c4849_sim_ppp |&gt; sf::st_as_sf() |&gt;\n    sf::st_set_crs(3857) |&gt; filter(label == \"point\")\n  ggplot() +\n    geom_stars(data=vill_jord_int_stars) +\n    geom_sf(data=vill_c4849_sim_points_sf, size=0.65) +\n    theme_classic() +\n    scale_fill_viridis_c(option=\"C\", na.value=\"transparent\") +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n    labs(title = \"100 Intensity-Sampled Villages\")\n} else {\n  writeLines(\"vill_c4849_sim_ppp object must be created first!\")\n}\n\nvill_c4849_sim_ppp object must be created first!\n\n\n\n\nQuestion 2.4: Computing the Test Statistic\nThis is where your code will start to differ from the code in Question 1. Here, your job is to compute the new distance-based test statistic in this part‚Äìthe mean distance from the simulated villages to Jerusalem‚Äîfor the simulated ppp object you just created. Store this value in a variable named sim_c4849_mean and print its value at the end of your code cell.\n\n# Your code here\nsim_c4849_mean &lt;- NULL # Replace with calculated mean distance from Jerusalem\nprint(sim_c4849_mean)\n\nNULL\n\n\nOnce again, you should get a mean distance here that is lower than the observed mean distance, but (as before) we can‚Äôt evaluate the hypothesis on the basis of a single counterfactual simulation! So, in the next question, you will re-run this simulation, 999 times, and then create a density plot to see how likely or unlikely our observed value of 30843.81 is relative to the mean distances resulting from these 999 simulations.\n\n\nQuestion 2.5: Monte Carlo Hypothesis Testing\nHere, like in Question 1.5, your job is to just take the simulation code that you‚Äôve now used to generate one simulation and run it 999 times, computing the mean distance from Jerusalem for each (on the basis of the centroid in jeru_sf).\nLike in Question 1.5, this will give you a distribution of test statistics that you can use to judge how unlikely it would be to observe a mean distance of 30843.81 under the null hypothesis.\nSo, in the following code cell: compute these 999 simulations, derive the test statistic for each, and then use ggplot2 to create a density plot (using geom_density()) of the 999 simulated test statistics, on top of which you should superimpose a dashed line (preferably with the color from the first element of cb_palette) representing the observed test statistic of 30843.81, to see how likely or unlikely this value would be under the null hypothesis.\nAs before, you don‚Äôt need to compute an exact \\(p\\)-value or confidence interval here. But, below the produced density plot, please provide a sentence or two describing your inference from the plot, in terms of the likelihood that the null hypothesis is true.\n\n# Your code here\n\nThank you for your work! As with all of the other assignments, I hope they can be helpful as e.g.¬†starter code for stuff you may find yourself working on in the future üèÉ"
  },
  {
    "objectID": "assignments/index.html",
    "href": "assignments/index.html",
    "title": "Assignments: Due Dates and Point Distributions",
    "section": "",
    "text": "The following is a quick overview of the due dates for each homework assignment. Then, for each, you can use the tabs below the table to see exactly how many points are allocated for each question.\n\n\n\n\n\n\n\n\nAssignment\nRelease Date\nDue Date\n\n\n\n\nHW1: GIS Concepts: Fun with Vectors and Rasters\nTuesday, September 9\nWednesday, September 24\n\n\nHW2: Unary and Binary Operations, Spatial Joins\nThursday, September 25\nWednesday, October 8\n\n\nHW3: Autocorrelation, Clustering, and Point Processes\nSunday, October 12\nWednesday, October 29\n\n\nHW4: Spatial Regression\nWednesday, November 13\nWednesday, November 27\n\n\nHW5A: Spatial Regression\nWednesday, November 19\nFriday, December 5\n\n\nHW5B: Remote Sensing and Raster Data\nWednesday, November 19\nFriday, December 5",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#due-dates",
    "href": "assignments/index.html#due-dates",
    "title": "Assignments: Due Dates and Point Distributions",
    "section": "",
    "text": "The following is a quick overview of the due dates for each homework assignment. Then, for each, you can use the tabs below the table to see exactly how many points are allocated for each question.\n\n\n\n\n\n\n\n\nAssignment\nRelease Date\nDue Date\n\n\n\n\nHW1: GIS Concepts: Fun with Vectors and Rasters\nTuesday, September 9\nWednesday, September 24\n\n\nHW2: Unary and Binary Operations, Spatial Joins\nThursday, September 25\nWednesday, October 8\n\n\nHW3: Autocorrelation, Clustering, and Point Processes\nSunday, October 12\nWednesday, October 29\n\n\nHW4: Spatial Regression\nWednesday, November 13\nWednesday, November 27\n\n\nHW5A: Spatial Regression\nWednesday, November 19\nFriday, December 5\n\n\nHW5B: Remote Sensing and Raster Data\nWednesday, November 19\nFriday, December 5",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#points-per-question",
    "href": "assignments/index.html#points-per-question",
    "title": "Assignments: Due Dates and Point Distributions",
    "section": "Points Per Question",
    "text": "Points Per Question\nThe following point distributions are imported from Google Sheets mainly for transparency: so that you can see exactly how totals are computed as a sum of the individual points allocated for each test!\n\nHW1HW2\n\n\n\n\n\n\n\n\n\nquestion\nqid\npoints\nsection_total\n\n\n\n\n1\nQ1.1\n4\n\n\n\n\nQ1.2\n4\n\n\n\n\nQ1.3\n4\n\n\n\n\nQ1.4\n4\n\n\n\n\nQ1.5\n4\n\n\n\n\nQ1.6\n4\n\n\n\n\nQ1.7\n4\n\n\n\n\nQ1.8\n4\n32\n\n\n2\nQ2.1\n9\n\n\n\n\nQ2.2\n9\n\n\n\n\nQ2.3\n9\n\n\n\n\nQ2.4\n8\n35\n\n\n3\nQ3.1\n11\n\n\n\n\nQ3.2\n11\n\n\n\n\nQ3.3\n11\n33\n\n\n\nTotal\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquestion\nqid\npoints\nsection_total\n\n\n\n\n1\nQ1.1\n5\n\n\n\n\nQ1.2\n5\n\n\n\n\nQ1.3\n5\n\n\n\n\nQ1.4\n6\n\n\n\n\nQ1.5\n6\n\n\n\n\nQ1.6\n5\n32\n\n\n2\nQ2.1\n4\n\n\n\n\nQ2.2\n4\n\n\n\n\nQ2.3\n4\n\n\n\n\nQ2.4\n4\n\n\n\n\nQ2.5\n4\n\n\n\n\nQ2.6\n4\n\n\n\n\nQ2.7\n4\n\n\n\n\nQ2.8\n5\n\n\n\n\nQ2.9\n5\n\n\n\n\nQ2.10\n4\n42\n\n\n3\nQ3.1\n4\n\n\n\n\nQ3.2\n6\n\n\n\n\nQ3.3\n3\n\n\n\n\nQ3.4\n3\n\n\n\n\nQ3.5\n5\n\n\n\n\nQ3.6\n5\n26\n\n\n\nTotal\n100",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "assignments/index.html#past-assignments-archive",
    "href": "assignments/index.html#past-assignments-archive",
    "title": "Assignments: Due Dates and Point Distributions",
    "section": "Past Assignments Archive",
    "text": "Past Assignments Archive\nLong story short, since we sometimes get requests for copies of the assignments from students after they‚Äôve completed the course, or just from interested people in general, the following listing contains ‚Äúfrozen‚Äù, archived versions of assignments from previous years in the course.\nYou can use these to get a preview for what a particular assignment might be about, but please keep in mind that the ‚Äúofficial‚Äù, updated assignments for the current semester ‚Äì the assignments you‚Äôll be completing for a grade ‚Äì are hosted on Positron! So, for example, you won‚Äôt be able to download an older version of an assignment from here and submit it for a grade, since the contents change year-by-year.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "writeups/positron/index.html",
    "href": "writeups/positron/index.html",
    "title": "Connecting to Positron and Accessing Assignments",
    "section": "",
    "text": "For both MacOS and Windows, you can download the latest version of Positron from its homepage. Once you have downloaded and installed it follow these instructions to connect to your JupyterHub space through Positron:\nFirst things first, note that this guide used a brand new installation of MacOS Sequioa 15.6.1 from scratch:\nBut also that, a fresh install of Windows 11 was used separately to test that the steps here work on Windows as well!\nMy hope is that the screenshots generated with this clean installation will therefore better resemble what you see when you first go to connect!"
  },
  {
    "objectID": "writeups/positron/index.html#footnotes",
    "href": "writeups/positron/index.html#footnotes",
    "title": "Connecting to Positron and Accessing Assignments",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn class I walked through a more laborious process, where we set up and added an entry into a special config file, but since lots of people are having issues with this approach, here we‚Äôre skipping the config file entirely, and instead just entering the two pieces of information manually into the Command Palette‚Ü©Ô∏é\nYou can also check the ‚ÄúTrust the authors of all files in the parent folder‚Äù checkbox, if you‚Äôd like, though it‚Äôs irrelevant since we won‚Äôt be loading or executing any files from that parent folder.‚Ü©Ô∏é"
  },
  {
    "objectID": "writeups/random-fields/index.html",
    "href": "writeups/random-fields/index.html",
    "title": "Visualizing Random Fields",
    "section": "",
    "text": "The following initialization code is actually doing A LOT under the hood. On top of starting R within your browser and importing the libraries specified in the code block, it also loads the elevation data for all of Tanzania, so that it can re-generate as many geospatial data realizations as you‚Äôd like (Click the ‚ÄúRun Code‚Äù button in the non-initialization cell below, to generate new realizations!)"
  },
  {
    "objectID": "writeups/random-fields/index.html#initialization-code",
    "href": "writeups/random-fields/index.html#initialization-code",
    "title": "Visualizing Random Fields",
    "section": "",
    "text": "The following initialization code is actually doing A LOT under the hood. On top of starting R within your browser and importing the libraries specified in the code block, it also loads the elevation data for all of Tanzania, so that it can re-generate as many geospatial data realizations as you‚Äôd like (Click the ‚ÄúRun Code‚Äù button in the non-initialization cell below, to generate new realizations!)"
  },
  {
    "objectID": "writeups/random-fields/index.html#base-r-and-ggplot2-visualizations",
    "href": "writeups/random-fields/index.html#base-r-and-ggplot2-visualizations",
    "title": "Visualizing Random Fields",
    "section": "Base R and ggplot2 Visualizations",
    "text": "Base R and ggplot2 Visualizations\nFeel free to modify the code however you‚Äôd like, then click the ‚ÄúRun Code‚Äù button to generate and visualize new realizations of the geospatial process! (You can click ‚ÄúStart Over‚Äù to reset the code to its original state)"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n      Default\n      \n        Last Updated - Oldest\n      \n      \n        Last Updated - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nLast Updated\n\n\n\nRelevant Assignments\n\n\n\nCategory\n\n\n\n\n\n\n\n\nWhy Poisson Processes are ‚ÄòThe‚Äô Null Model for Testing Spatial Hypotheses\n\n\nOct 16, 2025\n\n\nAll\n\n\nExtra Writeups\n\n\n\n\n\n\nUnambiguous Neighborhoods with sfdep\n\n\nOct 14, 2025\n\n\nHW3\n\n\nExtra Writeups\n\n\n\n\n\n\nVisualizing Random Fields\n\n\nOct 12, 2025\n\n\nAll\n\n\nExtra Writeups\n\n\n\n\n\n\nWorking with Coordinate Reference Systems (CRS)\n\n\nOct 1, 2025\n\n\nHW2\n\n\nExtra Writeups\n\n\n\n\n\n\nPPOL 6805 Week 6 Lab: Interpolating Kurdistan\n\n\nOct 1, 2025\n\n\nHW2\n\n\nLabs\n\n\n\n\n\n\nHW1 Hints\n\n\nSep 19, 2025\n\n\nHW1\n\n\nAssignment Hints\n\n\n\n\n\n\nThings We Put On Maps\n\n\nSep 17, 2025\n\n\nAll\n\n\nExtra Writeups\n\n\n\n\n\n\nFinding GIS Data\n\n\nSep 17, 2025\n\n\nAll\n\n\nExtra Writeups\n\n\n\n\n\n\nConnecting to Positron and Accessing Assignments\n\n\nSep 7, 2025\n\n\nHW1\n\n\nExtra Writeups\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Writeups"
    ]
  },
  {
    "objectID": "writeups/things-on-maps/index.html",
    "href": "writeups/things-on-maps/index.html",
    "title": "Things We Put On Maps",
    "section": "",
    "text": "Scales\nPoints\nLines\nAreas\n\n\n\n\n\n\nFrom Krygier and Wood (2016)\n\n\nThis comes up immediately, since we‚Äôll be using Natural Earth data more and more (via the rnaturalearth library) to obtain country POLYGONs\n\n\n\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#scales-wrules-of-thumb",
    "href": "writeups/things-on-maps/index.html#scales-wrules-of-thumb",
    "title": "Things We Put On Maps",
    "section": "",
    "text": "From Krygier and Wood (2016)\n\n\nThis comes up immediately, since we‚Äôll be using Natural Earth data more and more (via the rnaturalearth library) to obtain country POLYGONs"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#the-three-key-elements",
    "href": "writeups/things-on-maps/index.html#the-three-key-elements",
    "title": "Things We Put On Maps",
    "section": "",
    "text": "From Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#what-can-happen-to-points",
    "href": "writeups/things-on-maps/index.html#what-can-happen-to-points",
    "title": "Things We Put On Maps",
    "section": "What Can Happen to Points?",
    "text": "What Can Happen to Points?\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#what-can-happen-to-lines",
    "href": "writeups/things-on-maps/index.html#what-can-happen-to-lines",
    "title": "Things We Put On Maps",
    "section": "What Can Happen to Lines?",
    "text": "What Can Happen to Lines?\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#what-can-happen-to-lines-1",
    "href": "writeups/things-on-maps/index.html#what-can-happen-to-lines-1",
    "title": "Things We Put On Maps",
    "section": "What Can Happen to Lines?",
    "text": "What Can Happen to Lines?\n\n\nSelection\n\n\n\nIn any map, most features from the human or natural environment are eliminated! (Krygier and Wood 2016)\n\n\n\nSimplification\n\n\n\nWithin the features that do remain, eliminate details that are unnecessary with respect to audience/context (Krygier and Wood 2016)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#what-can-happen-to-areas",
    "href": "writeups/things-on-maps/index.html#what-can-happen-to-areas",
    "title": "Things We Put On Maps",
    "section": "What Can Happen to Areas?",
    "text": "What Can Happen to Areas?\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#areal-dimension-change",
    "href": "writeups/things-on-maps/index.html#areal-dimension-change",
    "title": "Things We Put On Maps",
    "section": "Areal Dimension Change",
    "text": "Areal Dimension Change\n\n\n\nFrom Krygier and Wood (2016)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#what-is-gained",
    "href": "writeups/things-on-maps/index.html#what-is-gained",
    "title": "Things We Put On Maps",
    "section": "What Is Gained?",
    "text": "What Is Gained?\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#what-is-lost",
    "href": "writeups/things-on-maps/index.html#what-is-lost",
    "title": "Things We Put On Maps",
    "section": "What Is Lost?",
    "text": "What Is Lost?\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/things-on-maps/index.html#who-is-affected",
    "href": "writeups/things-on-maps/index.html#who-is-affected",
    "title": "Things We Put On Maps",
    "section": "Who Is Affected?",
    "text": "Who Is Affected?\n\n\n\nFrom Monmonier (2018)"
  },
  {
    "objectID": "writeups/interpolation/index.html",
    "href": "writeups/interpolation/index.html",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "",
    "text": "First, check out this amazing ESRI StoryMap, which we‚Äôll cite as Hanson and Hinsdale (2023). If you‚Äôre interested, you can read a bunch more about the modern history of the Kurds in McDowall (2021).\nFor the sake of this assignment, though, we‚Äôll focus in on the following 1946 map, which Jeff will give the fuller details of (condensing McDowall (2021) into less than 5 minutes, hopefully!) in class:\n\n\n\n\n\n\n\n\nDigging into the code using Developer Tools reveals the magical API endpoint: https://services.arcgis.com/3xOwF6p0r7IHIjfn/arcgis/rest/services/Kurdistan1947Boundaries\nWe could wrestle with ESRI‚Äôs API, but, there‚Äôs an even more fun way, which I learned about via this blog post. Reading that will lead you on to the pyesridump library, which I use within Python to download the layers of that StoryMap as .geojson files.\nThe details of how pyesridump converts ESRI StoryMap Features into ‚Äústandard‚Äù WKT Geometries can be fun to learn but are a bit outside of the scope of this writeup. But, from the following output you can see that ESRI Features can contain the WKT geometry types we‚Äôve seen (like POINT, LINESTRING, or POLYGON), and in this case the feature we download does indeed correspond to a collection of POLYGONs (here we print just its first coordinate):\n\n\n\nESRI Type: Feature\nESRI Properties: {'OBJECTID': 1, 'area': 41360557.05027756, 'Shape__Area': 413605942350.6803, 'Shape__Length': 4362383.882545892}\nGeometry Type: Polygon\nFirst Coordinate: [37.6952778, 39.2168218]\n\n\nSource: Scraping Data from ArcGIS StoryMaps\nThe remainder of the lab uses these files, along with rnaturalearth!\n\n\n\n\nlibrary(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(rnaturalearth) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\n\n\ncountry_list &lt;- c(\n  \"Turkey\",\n  \"Iran\",\n  \"Iraq\",\n  \"Syria\"\n)\ncountries_sf &lt;- rnaturalearth::ne_countries(\n  scale=50,\n  type=\"countries\",\n  country=country_list\n)\n\nFrom among allll the variables in countries_sf, we‚Äôre only going to need geounit and (later) pop_est!\n\ncountries_sf &lt;- countries_sf |&gt;\n  select(geounit, pop_est)\n\n\ncountries_map &lt;- mapview(\n  countries_sf,\n  zcol='geounit'\n)\ncountries_map\n\n\n\n\n\nAnd now the 1946 .geojson file, from the ESRI StoryMap, as discussed above!\n\nprint(getwd())\n\n[1] \"/Users/jpj/gtown-local/ppol6805/writeups/interpolation\"\n\nif (endsWith(getwd(), \"ppol6805\")) {\n  setwd(\"./writeups/interpolation/\")\n}\nkrd_sf &lt;- sf::st_read(\"data/krd_46.geojson\") |&gt;\n  mutate(label=\"Kurdistan 1946\")\n\nReading layer `krd_46' from data source \n  `/Users/jpj/gtown-local/ppol6805/writeups/interpolation/data/krd_46.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 36.25249 ymin: 31.58789 xmax: 50.9462 ymax: 40.05815\nGeodetic CRS:  WGS 84\n\n\n\nkrd_map &lt;- mapview(krd_sf, zcol='label')\nkrd_map\n\n\n\n\n\n\ncountries_map + krd_map"
  },
  {
    "objectID": "writeups/interpolation/index.html#historical-kurdistan-geoms-from-esri",
    "href": "writeups/interpolation/index.html#historical-kurdistan-geoms-from-esri",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "",
    "text": "First, check out this amazing ESRI StoryMap, which we‚Äôll cite as Hanson and Hinsdale (2023). If you‚Äôre interested, you can read a bunch more about the modern history of the Kurds in McDowall (2021).\nFor the sake of this assignment, though, we‚Äôll focus in on the following 1946 map, which Jeff will give the fuller details of (condensing McDowall (2021) into less than 5 minutes, hopefully!) in class:"
  },
  {
    "objectID": "writeups/interpolation/index.html#from-esri-storymaps-to-sf-objects",
    "href": "writeups/interpolation/index.html#from-esri-storymaps-to-sf-objects",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "",
    "text": "Digging into the code using Developer Tools reveals the magical API endpoint: https://services.arcgis.com/3xOwF6p0r7IHIjfn/arcgis/rest/services/Kurdistan1947Boundaries\nWe could wrestle with ESRI‚Äôs API, but, there‚Äôs an even more fun way, which I learned about via this blog post. Reading that will lead you on to the pyesridump library, which I use within Python to download the layers of that StoryMap as .geojson files.\nThe details of how pyesridump converts ESRI StoryMap Features into ‚Äústandard‚Äù WKT Geometries can be fun to learn but are a bit outside of the scope of this writeup. But, from the following output you can see that ESRI Features can contain the WKT geometry types we‚Äôve seen (like POINT, LINESTRING, or POLYGON), and in this case the feature we download does indeed correspond to a collection of POLYGONs (here we print just its first coordinate):\n\n\n\nESRI Type: Feature\nESRI Properties: {'OBJECTID': 1, 'area': 41360557.05027756, 'Shape__Area': 413605942350.6803, 'Shape__Length': 4362383.882545892}\nGeometry Type: Polygon\nFirst Coordinate: [37.6952778, 39.2168218]\n\n\nSource: Scraping Data from ArcGIS StoryMaps\nThe remainder of the lab uses these files, along with rnaturalearth!"
  },
  {
    "objectID": "writeups/interpolation/index.html#now-modern-border-geoms",
    "href": "writeups/interpolation/index.html#now-modern-border-geoms",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "",
    "text": "library(tidyverse) |&gt; suppressPackageStartupMessages()\nlibrary(sf) |&gt; suppressPackageStartupMessages()\nlibrary(rnaturalearth) |&gt; suppressPackageStartupMessages()\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\n\n\ncountry_list &lt;- c(\n  \"Turkey\",\n  \"Iran\",\n  \"Iraq\",\n  \"Syria\"\n)\ncountries_sf &lt;- rnaturalearth::ne_countries(\n  scale=50,\n  type=\"countries\",\n  country=country_list\n)\n\nFrom among allll the variables in countries_sf, we‚Äôre only going to need geounit and (later) pop_est!\n\ncountries_sf &lt;- countries_sf |&gt;\n  select(geounit, pop_est)\n\n\ncountries_map &lt;- mapview(\n  countries_sf,\n  zcol='geounit'\n)\ncountries_map\n\n\n\n\n\nAnd now the 1946 .geojson file, from the ESRI StoryMap, as discussed above!\n\nprint(getwd())\n\n[1] \"/Users/jpj/gtown-local/ppol6805/writeups/interpolation\"\n\nif (endsWith(getwd(), \"ppol6805\")) {\n  setwd(\"./writeups/interpolation/\")\n}\nkrd_sf &lt;- sf::st_read(\"data/krd_46.geojson\") |&gt;\n  mutate(label=\"Kurdistan 1946\")\n\nReading layer `krd_46' from data source \n  `/Users/jpj/gtown-local/ppol6805/writeups/interpolation/data/krd_46.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 36.25249 ymin: 31.58789 xmax: 50.9462 ymax: 40.05815\nGeodetic CRS:  WGS 84\n\n\n\nkrd_map &lt;- mapview(krd_sf, zcol='label')\nkrd_map\n\n\n\n\n\n\ncountries_map + krd_map"
  },
  {
    "objectID": "writeups/interpolation/index.html#first-splitting-krd",
    "href": "writeups/interpolation/index.html#first-splitting-krd",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "First: Splitting KRD",
    "text": "First: Splitting KRD\nIntersects as the default predicate‚Ä¶ not very helpful here!\n\ndefault_sf &lt;- countries_sf[krd_sf,]\nmapview(default_sf)\n\n\n\n\n\nBut, intersection, via st_intersection(), does give us what we want!\n\n# inter_sf &lt;- st_as_sf(st_union(st_intersection(countries_sf, krd_sf)))\ninter_sf &lt;- st_intersection(countries_sf, krd_sf)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\nmapview(inter_sf)"
  },
  {
    "objectID": "writeups/interpolation/index.html#new-name-column",
    "href": "writeups/interpolation/index.html#new-name-column",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "New Name Column",
    "text": "New Name Column\n\ninter_sf &lt;- inter_sf |&gt; mutate(\n  krd_name = paste0(geounit, \" Kurdistan\")\n)\n\nNow let‚Äôs view the four rows of the sf object individually:\n\nmapview(inter_sf[1,], zcol='krd_name')\n\n\n\n\n\n\nmapview(inter_sf[2,], zcol='krd_name')\n\n\n\n\n\n\nmapview(inter_sf[3,], zcol='krd_name')\n\n\n\n\n\n\nmapview(inter_sf[4,], zcol='krd_name')"
  },
  {
    "objectID": "writeups/interpolation/index.html#and-all-at-once",
    "href": "writeups/interpolation/index.html#and-all-at-once",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "‚Ä¶And All at Once",
    "text": "‚Ä¶And All at Once\n\nmapview(inter_sf, zcol='krd_name')\n\n\n\n\n\nVery cool, but, we haven‚Äôt taken population into account at all, which was the whole point of this exercise‚Ä¶ spatial join / interpolation time!"
  },
  {
    "objectID": "writeups/interpolation/index.html#spatial-join-interpolation",
    "href": "writeups/interpolation/index.html#spatial-join-interpolation",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "Spatial Join / Interpolation",
    "text": "Spatial Join / Interpolation\nAgain drawing on McDowall (2021) (this table is on page 4), we can estimate that the overall population across the four modern countries is approximately 32 million:\n\n\n\nCountry\n% of Country\nCount\n\n\n\n\nTurkey\n18\n15 million\n\n\nIran\n10\n8 million\n\n\nIraq\n18\n7.2 million\n\n\nSyria\n9\n1.8 million\n\n\nDiaspora and Caucasus\n-\n2 million\n\n\nTotal\n-\n34 million\n\n\n\nSo, given this estimate, we can now ‚Äústart over‚Äù, this time with the goal of keeping track of the population as we do our operations:\n\nfmt_pop &lt;- function(x) formatC(x,big.mark=\",\",format='d')\nkrd_sf &lt;- krd_sf |&gt; mutate(\n  pop = 32000000,\n  pop_str = fmt_pop(pop)\n)\nmapview(krd_sf, zcol='pop_str')\n\n\n\n\n\nNow, if we just use st_intersection()‚Ä¶ it doesn‚Äôt know that it should pay attention to pop (even if it did know that, it wouldn‚Äôt know exactly how you want to split it up‚Ä¶ we‚Äôll get there)\n\npop_intersected_sf &lt;- st_intersection(countries_sf, krd_sf) |&gt;\n  mutate(\n    pop_str = fmt_pop(pop),\n    map_label = paste0(geounit, ' ', pop_str)\n  )\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\nmapview(pop_intersected_sf, zcol='pop', label='map_label')\n\n\n\n\n\nSo‚Ä¶ what do we do? The binary operations we‚Äôve learned so far won‚Äôt cut it, sadly.\nSo, we need to cap off the binary operations portion of the class with the fanciest operation we‚Äôll need: spatial joins, though more specifically we‚Äôll want an interpolation. The function in sf is called st_interpolate_aw().\nLet‚Äôs add that to our toolkit and get to spatial statistics/data science!\n\npop_interpolated_sf &lt;- st_interpolate_aw(\n  krd_sf['pop'],\n  countries_sf,\n  extensive=TRUE\n)\n\nWarning in st_interpolate_aw.sf(krd_sf[\"pop\"], countries_sf, extensive = TRUE):\nst_interpolate_aw assumes attributes are constant or uniform over areas of x\n\npop_interpolated_sf\n\n\n\n\n\npop\ngeometry\n\n\n\n\n13967353\nMULTIPOLYGON (((25.97002 40‚Ä¶\n\n\n749878\nMULTIPOLYGON (((35.89268 35‚Ä¶\n\n\n5987342\nMULTIPOLYGON (((42.35898 37‚Ä¶\n\n\n11295426\nMULTIPOLYGON (((56.18799 26‚Ä¶\n\n\n\n\n\n\nAnd let‚Äôs visualize it!\n\npop_interpolated_sf &lt;- pop_interpolated_sf |&gt; mutate(\n  pop_rounded = round(pop, 0),\n  pop_str = fmt_pop(pop_rounded)\n)\nmapview(pop_interpolated_sf, zcol='pop', label='pop_str')\n\n\n\n\n\nCool, this tells us, if we didn‚Äôt create a Kurdistan, and just drew the borders of the four states (hypothetically‚Ä¶‚Ä¶.), how many Kurds would be in each country (again, assuming uniform distribution across 1947 Kurdistan!)\n\npop_interpolated_sf\n\n\n\n\n\npop\ngeometry\npop_rounded\npop_str\n\n\n\n\n13967353\nMULTIPOLYGON (((25.97002 40‚Ä¶\n13967353\n13,967,353\n\n\n749878\nMULTIPOLYGON (((35.89268 35‚Ä¶\n749878\n749,878\n\n\n5987342\nMULTIPOLYGON (((42.35898 37‚Ä¶\n5987342\n5,987,342\n\n\n11295426\nMULTIPOLYGON (((56.18799 26‚Ä¶\n11295426\n11,295,426\n\n\n\n\n\npop_interpolated_sf$pop |&gt; sum() |&gt; fmt_pop()\n\n[1] \"32,000,000\""
  },
  {
    "objectID": "writeups/interpolation/index.html#now-interpolating-over-the-intersection",
    "href": "writeups/interpolation/index.html#now-interpolating-over-the-intersection",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "Now Interpolating Over the Intersection",
    "text": "Now Interpolating Over the Intersection\nI think of the above as kind of a‚Ä¶ ‚Äúpartially-spatially-aware‚Äù interpolation. This isn‚Äôt a great description, but, what I‚Äôm getting at is the fact that:\n\nIt does successfully compute how our population (of 1947 Kurdistan) proportionally distributes across the four national borders, but\nIt then represents the output, geometrically (as in, the geometry column), as just the original four countries, now with an additional non-spatial property: the Kurdish population in that country\n\nSo, for what I‚Äôll call a ‚Äúfully-spatially-aware‚Äù interpolation, we‚Äôll combine the two things we figured out above:\n\nSpatial intersection between 1947 Kurdistan and the four countries (producing Turkish, Iranian, Syrian, and Iraqi Kurdistan), plus\nThe areal-weighted interpolation we just did above\n\nAnd it turns out, all that we really need to change is which sf object we‚Äôre spatially interpolating across! Meaning, this is the above code, copied-and-pasted, with countries_sf now replaced by inter_sf:\n\nfully_joined_sf &lt;- st_interpolate_aw(\n  krd_sf['pop'],\n  inter_sf,\n  extensive=TRUE\n)\n\nWarning in st_interpolate_aw.sf(krd_sf[\"pop\"], inter_sf, extensive = TRUE):\nst_interpolate_aw assumes attributes are constant or uniform over areas of x\n\nmapview(fully_joined_sf)\n\n\n\n\n\nAlso take note of something here: how did mapview ‚Äúknow‚Äù to color the four regions by population (using the viridis scheme, the default in mapview!), when we didn‚Äôt specify anything for the zcol argument?\nThis happens because, st_interpolate_aw() is solely dedicated to computing a single piece of information: the population that results from distributing the first argument (numeric) across the second argument (an sf, with a geometry column)! It‚Äôs technically not intended to carry out a full-on join.\nSo, if you find yourself needing to keep all the other information along with the new areal-weighted population (which will usually be the case), just make sure you add the new areal-weighted population column in fully_joined_sf back into the sf object you passed as the second argument to st_interpolate_aw(), as a new column:\n\ninter_sf &lt;- inter_sf |&gt; mutate(\n  interpolated_pop = fully_joined_sf$pop\n)\ninter_sf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeounit\npop_est\nOBJECTID\narea\nShape__Area\nShape__Length\nlabel\ngeometry\nkrd_name\ninterpolated_pop\n\n\n\n\n37\nTurkey\n83429615\n1\n41360557\n413605942351\n4362384\nKurdistan 1946\nMULTIPOLYGON (((37.746 39.1‚Ä¶\nTurkey Kurdistan\n13967353\n\n\n47\nSyria\n17070135\n1\n41360557\n413605942351\n4362384\nKurdistan 1946\nMULTIPOLYGON (((41.81781 36‚Ä¶\nSyria Kurdistan\n749878\n\n\n142\nIraq\n39309783\n1\n41360557\n413605942351\n4362384\nKurdistan 1946\nMULTIPOLYGON (((46.56862 32‚Ä¶\nIraq Kurdistan\n5987342\n\n\n143\nIran\n82913906\n1\n41360557\n413605942351\n4362384\nKurdistan 1946\nMULTIPOLYGON (((44.54024 39‚Ä¶\nIran Kurdistan\n11295426\n\n\n\n\n\n\nAnd now we can use all the other info, like the name, for the rest of our analysis! For example, when making an interactive map!\n\ninter_sf &lt;- inter_sf |&gt; mutate(\n  krd_name = paste0(geounit, ' Kurdistan'),\n  pop_str = fmt_pop(interpolated_pop),\n  krd_label = paste0(krd_name, ': ', pop_str)\n)\nmapview(inter_sf, zcol='interpolated_pop', label='krd_label')"
  },
  {
    "objectID": "writeups/interpolation/index.html#part-3.1-estimating-kurdistan-population-from-country-populations",
    "href": "writeups/interpolation/index.html#part-3.1-estimating-kurdistan-population-from-country-populations",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "Part 3.1: Estimating Kurdistan Population from Country Populations",
    "text": "Part 3.1: Estimating Kurdistan Population from Country Populations\nHere, we pretend we don‚Äôt know the population of Kurdistan, and try to estimate it from the four country populations, based on how much of each country POLYGONs overlap with the Kurdistan POLYGON:\n\ncountries_sf\n\n\n\n\n\n\ngeounit\npop_est\ngeometry\n\n\n\n\n37\nTurkey\n83429615\nMULTIPOLYGON (((25.97002 40‚Ä¶\n\n\n47\nSyria\n17070135\nMULTIPOLYGON (((35.89268 35‚Ä¶\n\n\n142\nIraq\n39309783\nMULTIPOLYGON (((42.35898 37‚Ä¶\n\n\n143\nIran\n82913906\nMULTIPOLYGON (((56.18799 26‚Ä¶\n\n\n\n\n\n\nVisualized:\n\ncountries_sf &lt;- countries_sf |&gt; mutate(\n  pop_str = fmt_pop(pop_est),\n  pop_label = paste0(geounit, \": \", pop_str)\n)\nmapview(countries_sf, zcol=\"pop_est\", label=\"pop_label\") + krd_map\n\n\n\n\n\n\nkrd_pop_est_sf &lt;- st_interpolate_aw(\n  countries_sf['pop_est'],\n  krd_sf,\n  extensive = TRUE\n)\n\nWarning in st_interpolate_aw.sf(countries_sf[\"pop_est\"], krd_sf, extensive =\nTRUE): st_interpolate_aw assumes attributes are constant or uniform over areas\nof x\n\nkrd_sf &lt;- krd_sf |&gt; mutate(\n  pop_est = krd_pop_est_sf$pop_est,\n  pop_str = fmt_pop(pop_est),\n  geounit = \"Kurdistan\",\n  pop_label = paste0(\"Kurdistan Est: \", pop_str)\n)\nkrd_sf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\narea\nShape__Area\nShape__Length\ngeometry\nlabel\npop\npop_str\npop_est\ngeounit\npop_label\n\n\n\n\n1\n41360557\n413605942351\n4362384\nPOLYGON ((37.69528 39.21682‚Ä¶\nKurdistan 1946\n3.2e+07\n34,607,914\n34607915\nKurdistan\nKurdistan Est: 34,607,914\n\n\n\n\n\n\nAnd, visualized!\n\nmapview(countries_sf, zcol=\"pop_est\", label=\"pop_label\") + mapview(krd_sf, zcol=\"pop_est\", label=\"pop_label\")\n\n\n\n\n\nWe can also just combine our estimated Kurdistan data with the country data into one, big sf object with 5 rows, where we just have to keep in mind that we‚Äôve technically changed the unit of observation in each row from ‚ÄúUN-recognized country‚Äù to essentially ‚ÄúGeopolitical entity of some sort‚Äù\n\nkrd_sub_sf &lt;- krd_sf |&gt; select(\n  geounit, pop_est, pop_str, pop_label\n)\npol_ent_sf &lt;- rbind(countries_sf, krd_sub_sf)\npol_ent_sf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeounit\npop_est\npop_str\npop_label\ngeometry\n\n\n\n\n37\nTurkey\n83429615\n83,429,615\nTurkey: 83,429,615\nMULTIPOLYGON (((25.97002 40‚Ä¶\n\n\n47\nSyria\n17070135\n17,070,135\nSyria: 17,070,135\nMULTIPOLYGON (((35.89268 35‚Ä¶\n\n\n142\nIraq\n39309783\n39,309,783\nIraq: 39,309,783\nMULTIPOLYGON (((42.35898 37‚Ä¶\n\n\n143\nIran\n82913906\n82,913,906\nIran: 82,913,906\nMULTIPOLYGON (((56.18799 26‚Ä¶\n\n\n1\nKurdistan\n34607915\n34,607,914\nKurdistan Est: 34,607,914\nPOLYGON ((37.69528 39.21682‚Ä¶\n\n\n\n\n\n\nAnd now, with a single mapview call:\n\nmapview(pol_ent_sf, zcol='pop_est', label='pop_label')"
  },
  {
    "objectID": "writeups/interpolation/index.html#footnotes",
    "href": "writeups/interpolation/index.html#footnotes",
    "title": "PPOL 6805 Week 6 Lab: Interpolating Kurdistan",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere is also a ‚ÄúSouthern‚Äù Kurdish language called Xwarin‚Ü©Ô∏é"
  },
  {
    "objectID": "w10/index.html",
    "href": "w10/index.html",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#null-models",
    "href": "w10/index.html#null-models",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Null Models",
    "text": "Null Models\n\nGiven an intensity function, we can compute a bunch of simulated point patterns (inhomogeneous Poisson Point Process)‚Ä¶\nHow does an observed point pattern differ from the simulated point patterns?",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#constant-risk-hypothesis-motivation",
    "href": "w10/index.html#constant-risk-hypothesis-motivation",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Constant Risk Hypothesis: Motivation",
    "text": "Constant Risk Hypothesis: Motivation\n\nHere is a (fictional) map of flu cases in the US ‚ÄúMidwest‚Äù\nAre people in Chicago and Detroit equally ‚Äúat risk‚Äù?\n\n\n\nCode\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\ncity_df &lt;- tibble::tribble(\n  ~city, ~lon, ~lat, ~pop,\n  \"Chicago\", 41.950567516553896, -87.93011127491978, 2746388,\n  \"Detroit\", 42.45123004999075, -83.18402319217698, 631524\n)\ncity_sf &lt;- sf::st_as_sf(\n  city_df,\n  coords = c(\"lat\", \"lon\"),\n  crs=4326\n)\ncity_buf_sf &lt;- city_sf |&gt; sf::st_buffer(20000)\ncity_cases_sf &lt;- city_buf_sf |&gt; sf::st_sample(size=rep(10,2)) |&gt; sf::st_as_sf()\ncity_cases_sf$city &lt;- \"Detroit (10 Cases)\"\ncity_cases_sf[1:10, 'city'] &lt;- \"Chicago (10 Cases)\"\ncity_cases_sf$sample &lt;- \"Flu\"\nmapview(city_cases_sf, zcol=\"city\")",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#constant-risk-hypothesis-base-rates",
    "href": "w10/index.html#constant-risk-hypothesis-base-rates",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Constant Risk Hypothesis: Base Rates",
    "text": "Constant Risk Hypothesis: Base Rates\n\n\n\n\nChicago\nDetroit\n\n\n\n\nPopulation\n2,746,388\n631,524\n\n\n\n\n\nCode\nlibrary(leaflet) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet.extras2) |&gt; suppressPackageStartupMessages()\ncity_pop_sf &lt;- city_buf_sf |&gt; sf::st_sample(size=c(16, 4)) |&gt; sf::st_as_sf()\ncity_pop_sf$city &lt;- \"Detroit\"\ncity_pop_sf[1:16, 'city'] &lt;- \"Chicago\"\ncity_pop_sf$sample &lt;- \"People\"\ncity_combined_sf &lt;- bind_rows(city_cases_sf, city_pop_sf)\n# mapview(city_combined_sf, zcol=\"city\", marker=\"sample\")\nFlu = makeIcon(\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/240px-Maki2-danger-24.svg.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/24px-Maki2-danger-24.svg.png\",\n    20,\n    20\n)\nPeople = makeIcon(\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  20,\n  20\n)\n\ncity_combined_sf$r &lt;- ifelse(city_combined_sf$sample == \"Flu\", 0, 4)\ncity_flu_sf &lt;- city_combined_sf |&gt; filter(sample == \"Flu\")\ncity_ppl_sf &lt;- city_combined_sf |&gt; filter(sample == \"People\")\nleaflet(city_flu_sf) |&gt;\n  addProviderTiles(\"CartoDB.Positron\") |&gt;\n  addMarkers(data=city_flu_sf, icon = Flu) |&gt;\n  addMarkers(data=city_ppl_sf, icon = People)",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#meaningful-results-leftrightarrow-comparisons-with-null-models",
    "href": "w10/index.html#meaningful-results-leftrightarrow-comparisons-with-null-models",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Meaningful Results \\(\\leftrightarrow\\) Comparisons with Null Model(s)",
    "text": "Meaningful Results \\(\\leftrightarrow\\) Comparisons with Null Model(s)\n\nCases of disease form an intensity function \\(\\lambda(\\mathbf{s})\\)\nControls form an ‚Äúambient‚Äù intensity function \\(\\lambda_0(\\mathbf{s})\\)\n\\(\\implies\\) The following model allows us to separate the quantities we really care about from the base rate information:\n\\[\n  \\lambda(\\mathbf{s}) = \\alpha \\overbrace{\\lambda_0(\\mathbf{s})}^{\\mathclap{\\text{Base Rate}}} \\underbrace{\\rho(\\mathbf{s})}_{\\mathclap{\\text{Relative Risk}}},\n  \\]\nwhere\n\\[\n  \\alpha = \\frac{\\# \\text{Cases}}{\\# \\text{Controls}}\n  \\]\n(Remember: unit of \\(\\lambda(\\mathbf{s})\\) is number of cases; not a probability density!)",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#example-from-moraga-2024",
    "href": "w10/index.html#example-from-moraga-2024",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Example from Moraga (2024)",
    "text": "Example from Moraga (2024)\n\nData: 761 primary biliary cirrhosis (PBC) cases, 3020 controls, England 1987-94\n\n\n\n\n\nCode\nlibrary(sparr) |&gt; suppressPackageStartupMessages()\ndata(pbc)\ncontrols &lt;- unmark(pbc[which(pbc$marks == \"control\"), ])\ncontrols |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic() +\n  labs(title=\"Controls (Population Sample)\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncases &lt;- unmark(pbc[which(pbc$marks == \"case\"), ])\ncases |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic() +\n  labs(title=\"PBC Cases\")",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#estimating-comparable-intensity-surfaces",
    "href": "w10/index.html#estimating-comparable-intensity-surfaces",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Estimating Comparable Intensity Surfaces",
    "text": "Estimating Comparable Intensity Surfaces\n\nTo ensure comparable intensity functions, need a common bandwidth value\ndensity() from spatstat makes ‚Äúsmart‚Äù choices for this bandwidth, so for now we just average the bandwidths estimated for cases and controls:\n\n\n\nCode\nlibrary(sparr)\ndata(pbc)\ncases &lt;- unmark(pbc[which(pbc$marks == \"case\"), ])\ncontrols &lt;- unmark(pbc[which(pbc$marks == \"control\"), ])\nbwcases &lt;- attr(density(cases), \"sigma\")\nbwcontr &lt;- attr(density(controls), \"sigma\")\n(bw &lt;- (bwcases + bwcontr)/2)\n\n\n[1] 11.45837\n\n\n\n\n\n\nCode\nint_controls &lt;- density(controls, sigma = bw, eps=0.25)\nplot(int_controls, main = \"Control Intensity\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nint_cases &lt;- density(cases, sigma = bw, eps=0.25)\nplot(int_cases, main = \"Case Intensity\")",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#visualizing-relative-risk-surface",
    "href": "w10/index.html#visualizing-relative-risk-surface",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Visualizing Relative Risk Surface",
    "text": "Visualizing Relative Risk Surface\n\nAll that‚Äôs left is \\(\\alpha = \\# \\text{Controls} / \\# \\text{Cases}\\)!\n\n\n\nCode\nlibrary(fields)\n(alpha_hat &lt;- cases$n/controls$n)\n\n\n[1] 0.2519868\n\n\nCode\nx &lt;- int_cases$xcol\ny &lt;- int_cases$yrow\nrr &lt;- t(int_cases$v)/t(alpha_hat * int_controls$v)\nimage.plot(x, y, rr, asp = 1)\ntitle(xlab = \"Easting\", ylab = \"Northing\")",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#null-model-csr",
    "href": "w10/index.html#null-model-csr",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Null Model: CSR",
    "text": "Null Model: CSR\n\n\n\nFigure from Gimond (2024)",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#the-random-labeling-hypothesis",
    "href": "w10/index.html#the-random-labeling-hypothesis",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "The Random Labeling Hypothesis",
    "text": "The Random Labeling Hypothesis\n\n\nRandomly apply 761 ‚Äúsick‚Äù labels to the 3781 points!\n\n\n\n\n\n\nCode\nplot_rlabel &lt;- function(rl_ppp) {\n  rl_win_sf &lt;- window_to_sf(rl_ppp)\n  rl_points_sf &lt;- points_to_sf(rl_ppp) |&gt;\n    rename(\n      type = spatstat.geom..marks.x.\n    )\n  rl_plot &lt;- ggplot() +\n    geom_sf(\n      data=rl_win_sf,\n      alpha=0.3\n    ) +\n    geom_sf(\n      mapping=aes(fill=type, alpha=type),\n      data=rl_points_sf,\n      size=2,\n      # alpha=0.75,\n      shape=21,\n      stroke=0.1,\n      # color='white',\n    ) +\n    # scale_color_manual(\n    #   \"Point Type\",\n    #   values=c(\"control\"=\"gray\",\"case\"=cb_palette[1])\n    # ) +\n    scale_fill_manual(\n      \"Type\",\n      values=c(\"control\"=\"gray\",\"case\"=cb_palette[1])\n    ) +\n    scale_alpha_manual(\n      \"Type\",\n      values=c(\"control\"=0.5, \"case\"=1.0)\n    ) +\n    theme_classic(base_size=16) +\n    labs(\n      title=\"NE Britain Disease Cases\"\n    )\n  return(rl_plot)\n}\nset.seed(6810)\nrl1_ppp &lt;- rlabel(pbc)\nplot_rlabel(rl1_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(6811)\npbc_2 &lt;- rlabel(pbc)\nplot_rlabel(pbc_2)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(6812)\npbc_3 &lt;- rlabel(pbc)\nplot_rlabel(pbc_3)",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#the-constant-risk-hypothesis",
    "href": "w10/index.html#the-constant-risk-hypothesis",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "The Constant Risk Hypothesis",
    "text": "The Constant Risk Hypothesis\n\nEveryone equally at risk of contracting disease, regardless of location: \\(\\rho(\\mathbf{s}) = 1\\)\nIn this case: \\(\\lambda_{CR}(\\mathbf{s}) = \\alpha \\lambda_0(\\mathbf{s})\\)\n\n\n\n\n\nCode\npbc_win_sf &lt;- pbc |&gt; sf::st_as_sf() |&gt; filter(label == \"window\")\nplot_pbc_sim &lt;- function() {\n    pbc_sim &lt;- spatstat.random::rpoispp(\n        lambda = alpha_hat * int_controls\n    )\n    # Separate window and points\n    pbc_sf &lt;- pbc_sim |&gt; sf::st_as_sf()\n    pbc_point_sf &lt;- pbc_sf |&gt; filter(label == \"point\")\n    pbc_win_sf &lt;- pbc_sf |&gt; filter(label == \"window\")\n    pbc_plot &lt;- ggplot() +\n      geom_sf(data=pbc_win_sf) +\n      geom_sf(data=pbc_point_sf, size=0.5, alpha=0.5) +\n      theme_classic()\n    return(pbc_plot)\n}\nplot_pbc_sim()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_pbc_sim()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_pbc_sim()",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#aggregating-point-processes",
    "href": "w10/index.html#aggregating-point-processes",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Aggregating Point Processes",
    "text": "Aggregating Point Processes\n\nRecall the two ‚Äústages‚Äù of our Poisson-based point processes\n\nA Poisson-distributed number of points, then\nUniformly-distributed coordinates for each point\n\nOne way to see areal data modeling: we keep the Poisson part, but we no longer observe the coordinates for the points!\nSo‚Ä¶ why is it still helpful for you to have sat through those lectures on Point Processes? Two reasons‚Ä¶",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#areal-patterns-aggregated-point-patterns",
    "href": "w10/index.html#areal-patterns-aggregated-point-patterns",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "(1) Areal Patterns = Aggregated Point Patterns",
    "text": "(1) Areal Patterns = Aggregated Point Patterns\n\nOne application, mentioned last week: areal-weighted interpolation using actual models of how the points are distributed within the area!\nRegularly-spaced points is rarely a good ‚Äúdefault‚Äù model!\nHumans, for example, rarely live at perfect evenly-spaced intervals‚Ä¶ they form households, villages, cities\nRegularly-spaced points (we now know) \\(\\implies\\) negative autocorrelation \\(\\implies\\) typically due to inhibition process (competition)",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#spatial-scan-statistics",
    "href": "w10/index.html#spatial-scan-statistics",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "(2) Spatial Scan Statistics",
    "text": "(2) Spatial Scan Statistics\n\nAreal regions often the result of artificial / ‚Äúarbitrary‚Äù human divisions\n\n(Particulate matter doesn‚Äôt pass through customs)\n\n\\(\\implies\\) If we care about processes which don‚Äôt ‚Äúadhere to‚Äù borders (like disease spread), we want to ‚Äúscan‚Äù buffers around points regardless of areal borders",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#hierarchical-bayesian-smoothing",
    "href": "w10/index.html#hierarchical-bayesian-smoothing",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "(3) Hierarchical Bayesian Smoothing",
    "text": "(3) Hierarchical Bayesian Smoothing\n\nThe issue might just be not enough data for some areas, while we have an abundance of data in nearby areas‚Ä¶\n\n\n\n\nFrom Kramer (2023), Spatial Epidemiology",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#autocorrelation-reminder-weight-matrix-defines-neighbors",
    "href": "w10/index.html#autocorrelation-reminder-weight-matrix-defines-neighbors",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Autocorrelation Reminder: Weight Matrix Defines ‚ÄúNeighbors‚Äù",
    "text": "Autocorrelation Reminder: Weight Matrix Defines ‚ÄúNeighbors‚Äù\n\n\n\nFrom Canadian Rockies Exploration Guide",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#choices-available-in-spdep",
    "href": "w10/index.html#choices-available-in-spdep",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Choices Available in spdep",
    "text": "Choices Available in spdep\n\n\\(w_{ij} = 1\\) if \\(i\\) and \\(j\\) ‚Äútouch‚Äù\n\nRook: Overlap is 1 or 2-dimensional\nQueen: Overlap is 0, 1, or 2-dimensional\n\n\\(w_{ij} = \\frac{1}{\\text{dist}(i, j)}\\)\n\n\\(w(\\textsf{Seoul}, \\textsf{Incheon})\\) &gt; \\(w(\\textsf{Seoul}, \\textsf{Busan})\\) &gt; \\(w(\\textsf{Seoul}, \\textsf{Jeju})\\)\n\n\\(w_{ij} = 1\\) if \\(dist(i, j) &lt; \\overline{D}\\)\n\\(w_{ij} = 1\\) for \\(K\\) nearest neighbors",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#morans-i-one-more-time",
    "href": "w10/index.html#morans-i-one-more-time",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Moran‚Äôs \\(I\\) One More Time",
    "text": "Moran‚Äôs \\(I\\) One More Time\n\nRound 1 (Week 6): Moran‚Äôs \\(I\\) as ‚Äúthermometer‚Äù\nRound 2 (Today): Could an \\(I\\) value this extreme occur due to random noise?",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/index.html#references",
    "href": "w10/index.html#references",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "References",
    "text": "References\n\n\nGimond, Manuel. 2024. Introduction to GIS and Spatial Analysis. Colby College (ES214).",
    "crumbs": [
      "Week 10: Oct 29"
    ]
  },
  {
    "objectID": "w10/slides.html#null-models",
    "href": "w10/slides.html#null-models",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Null Models",
    "text": "Null Models\n\nGiven an intensity function, we can compute a bunch of simulated point patterns (inhomogeneous Poisson Point Process)‚Ä¶\nHow does an observed point pattern differ from the simulated point patterns?"
  },
  {
    "objectID": "w10/slides.html#constant-risk-hypothesis-motivation",
    "href": "w10/slides.html#constant-risk-hypothesis-motivation",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Constant Risk Hypothesis: Motivation",
    "text": "Constant Risk Hypothesis: Motivation\n\nHere is a (fictional) map of flu cases in the US ‚ÄúMidwest‚Äù\nAre people in Chicago and Detroit equally ‚Äúat risk‚Äù?\n\n\n\nCode\nlibrary(mapview) |&gt; suppressPackageStartupMessages()\ncity_df &lt;- tibble::tribble(\n  ~city, ~lon, ~lat, ~pop,\n  \"Chicago\", 41.950567516553896, -87.93011127491978, 2746388,\n  \"Detroit\", 42.45123004999075, -83.18402319217698, 631524\n)\ncity_sf &lt;- sf::st_as_sf(\n  city_df,\n  coords = c(\"lat\", \"lon\"),\n  crs=4326\n)\ncity_buf_sf &lt;- city_sf |&gt; sf::st_buffer(20000)\ncity_cases_sf &lt;- city_buf_sf |&gt; sf::st_sample(size=rep(10,2)) |&gt; sf::st_as_sf()\ncity_cases_sf$city &lt;- \"Detroit (10 Cases)\"\ncity_cases_sf[1:10, 'city'] &lt;- \"Chicago (10 Cases)\"\ncity_cases_sf$sample &lt;- \"Flu\"\nmapview(city_cases_sf, zcol=\"city\")"
  },
  {
    "objectID": "w10/slides.html#constant-risk-hypothesis-base-rates",
    "href": "w10/slides.html#constant-risk-hypothesis-base-rates",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Constant Risk Hypothesis: Base Rates",
    "text": "Constant Risk Hypothesis: Base Rates\n\n\n\n\nChicago\nDetroit\n\n\n\n\nPopulation\n2,746,388\n631,524\n\n\n\n\n\nCode\nlibrary(leaflet) |&gt; suppressPackageStartupMessages()\nlibrary(leaflet.extras2) |&gt; suppressPackageStartupMessages()\ncity_pop_sf &lt;- city_buf_sf |&gt; sf::st_sample(size=c(16, 4)) |&gt; sf::st_as_sf()\ncity_pop_sf$city &lt;- \"Detroit\"\ncity_pop_sf[1:16, 'city'] &lt;- \"Chicago\"\ncity_pop_sf$sample &lt;- \"People\"\ncity_combined_sf &lt;- bind_rows(city_cases_sf, city_pop_sf)\n# mapview(city_combined_sf, zcol=\"city\", marker=\"sample\")\nFlu = makeIcon(\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/240px-Maki2-danger-24.svg.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Maki2-danger-24.svg/24px-Maki2-danger-24.svg.png\",\n    20,\n    20\n)\nPeople = makeIcon(\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Maki2-pitch-24.svg/24px-Maki2-pitch-24.svg.png\",\n  20,\n  20\n)\n\ncity_combined_sf$r &lt;- ifelse(city_combined_sf$sample == \"Flu\", 0, 4)\ncity_flu_sf &lt;- city_combined_sf |&gt; filter(sample == \"Flu\")\ncity_ppl_sf &lt;- city_combined_sf |&gt; filter(sample == \"People\")\nleaflet(city_flu_sf) |&gt;\n  addProviderTiles(\"CartoDB.Positron\") |&gt;\n  addMarkers(data=city_flu_sf, icon = Flu) |&gt;\n  addMarkers(data=city_ppl_sf, icon = People)"
  },
  {
    "objectID": "w10/slides.html#meaningful-results-leftrightarrow-comparisons-with-null-models",
    "href": "w10/slides.html#meaningful-results-leftrightarrow-comparisons-with-null-models",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Meaningful Results \\(\\leftrightarrow\\) Comparisons with Null Model(s)",
    "text": "Meaningful Results \\(\\leftrightarrow\\) Comparisons with Null Model(s)\n\nCases of disease form an intensity function \\(\\lambda(\\mathbf{s})\\)\nControls form an ‚Äúambient‚Äù intensity function \\(\\lambda_0(\\mathbf{s})\\)\n\\(\\implies\\) The following model allows us to separate the quantities we really care about from the base rate information:\n\\[\n  \\lambda(\\mathbf{s}) = \\alpha \\overbrace{\\lambda_0(\\mathbf{s})}^{\\mathclap{\\text{Base Rate}}} \\underbrace{\\rho(\\mathbf{s})}_{\\mathclap{\\text{Relative Risk}}},\n  \\]\nwhere\n\\[\n  \\alpha = \\frac{\\# \\text{Cases}}{\\# \\text{Controls}}\n  \\]\n(Remember: unit of \\(\\lambda(\\mathbf{s})\\) is number of cases; not a probability density!)"
  },
  {
    "objectID": "w10/slides.html#example-from-moraga-2024",
    "href": "w10/slides.html#example-from-moraga-2024",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Example from Moraga (2024)",
    "text": "Example from Moraga (2024)\n\nData: 761 primary biliary cirrhosis (PBC) cases, 3020 controls, England 1987-94\n\n\n\n\n\nCode\nlibrary(sparr) |&gt; suppressPackageStartupMessages()\ndata(pbc)\ncontrols &lt;- unmark(pbc[which(pbc$marks == \"control\"), ])\ncontrols |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic() +\n  labs(title=\"Controls (Population Sample)\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncases &lt;- unmark(pbc[which(pbc$marks == \"case\"), ])\ncases |&gt; sf::st_as_sf() |&gt; ggplot() +\n  geom_sf() +\n  theme_classic() +\n  labs(title=\"PBC Cases\")"
  },
  {
    "objectID": "w10/slides.html#estimating-comparable-intensity-surfaces",
    "href": "w10/slides.html#estimating-comparable-intensity-surfaces",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Estimating Comparable Intensity Surfaces",
    "text": "Estimating Comparable Intensity Surfaces\n\nTo ensure comparable intensity functions, need a common bandwidth value\ndensity() from spatstat makes ‚Äúsmart‚Äù choices for this bandwidth, so for now we just average the bandwidths estimated for cases and controls:\n\n\n\nCode\nlibrary(sparr)\ndata(pbc)\ncases &lt;- unmark(pbc[which(pbc$marks == \"case\"), ])\ncontrols &lt;- unmark(pbc[which(pbc$marks == \"control\"), ])\nbwcases &lt;- attr(density(cases), \"sigma\")\nbwcontr &lt;- attr(density(controls), \"sigma\")\n(bw &lt;- (bwcases + bwcontr)/2)\n\n\n[1] 11.45837\n\n\n\n\n\n\nCode\nint_controls &lt;- density(controls, sigma = bw, eps=0.25)\nplot(int_controls, main = \"Control Intensity\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nint_cases &lt;- density(cases, sigma = bw, eps=0.25)\nplot(int_cases, main = \"Case Intensity\")"
  },
  {
    "objectID": "w10/slides.html#visualizing-relative-risk-surface",
    "href": "w10/slides.html#visualizing-relative-risk-surface",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Visualizing Relative Risk Surface",
    "text": "Visualizing Relative Risk Surface\n\nAll that‚Äôs left is \\(\\alpha = \\# \\text{Controls} / \\# \\text{Cases}\\)!\n\n\n\nCode\nlibrary(fields)\n(alpha_hat &lt;- cases$n/controls$n)\n\n\n[1] 0.2519868\n\n\nCode\nx &lt;- int_cases$xcol\ny &lt;- int_cases$yrow\nrr &lt;- t(int_cases$v)/t(alpha_hat * int_controls$v)\nimage.plot(x, y, rr, asp = 1)\ntitle(xlab = \"Easting\", ylab = \"Northing\")"
  },
  {
    "objectID": "w10/slides.html#null-model-csr",
    "href": "w10/slides.html#null-model-csr",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Null Model: CSR",
    "text": "Null Model: CSR\n\nFigure from Gimond (2024)"
  },
  {
    "objectID": "w10/slides.html#the-random-labeling-hypothesis",
    "href": "w10/slides.html#the-random-labeling-hypothesis",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "The Random Labeling Hypothesis",
    "text": "The Random Labeling Hypothesis\n\n\nRandomly apply 761 ‚Äúsick‚Äù labels to the 3781 points!\n\n\n\n\n\n\nCode\nplot_rlabel &lt;- function(rl_ppp) {\n  rl_win_sf &lt;- window_to_sf(rl_ppp)\n  rl_points_sf &lt;- points_to_sf(rl_ppp) |&gt;\n    rename(\n      type = spatstat.geom..marks.x.\n    )\n  rl_plot &lt;- ggplot() +\n    geom_sf(\n      data=rl_win_sf,\n      alpha=0.3\n    ) +\n    geom_sf(\n      mapping=aes(fill=type, alpha=type),\n      data=rl_points_sf,\n      size=2,\n      # alpha=0.75,\n      shape=21,\n      stroke=0.1,\n      # color='white',\n    ) +\n    # scale_color_manual(\n    #   \"Point Type\",\n    #   values=c(\"control\"=\"gray\",\"case\"=cb_palette[1])\n    # ) +\n    scale_fill_manual(\n      \"Type\",\n      values=c(\"control\"=\"gray\",\"case\"=cb_palette[1])\n    ) +\n    scale_alpha_manual(\n      \"Type\",\n      values=c(\"control\"=0.5, \"case\"=1.0)\n    ) +\n    theme_classic(base_size=16) +\n    labs(\n      title=\"NE Britain Disease Cases\"\n    )\n  return(rl_plot)\n}\nset.seed(6810)\nrl1_ppp &lt;- rlabel(pbc)\nplot_rlabel(rl1_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(6811)\npbc_2 &lt;- rlabel(pbc)\nplot_rlabel(pbc_2)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(6812)\npbc_3 &lt;- rlabel(pbc)\nplot_rlabel(pbc_3)"
  },
  {
    "objectID": "w10/slides.html#the-constant-risk-hypothesis",
    "href": "w10/slides.html#the-constant-risk-hypothesis",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "The Constant Risk Hypothesis",
    "text": "The Constant Risk Hypothesis\n\nEveryone equally at risk of contracting disease, regardless of location: \\(\\rho(\\mathbf{s}) = 1\\)\nIn this case: \\(\\lambda_{CR}(\\mathbf{s}) = \\alpha \\lambda_0(\\mathbf{s})\\)\n\n\n\n\n\nCode\npbc_win_sf &lt;- pbc |&gt; sf::st_as_sf() |&gt; filter(label == \"window\")\nplot_pbc_sim &lt;- function() {\n    pbc_sim &lt;- spatstat.random::rpoispp(\n        lambda = alpha_hat * int_controls\n    )\n    # Separate window and points\n    pbc_sf &lt;- pbc_sim |&gt; sf::st_as_sf()\n    pbc_point_sf &lt;- pbc_sf |&gt; filter(label == \"point\")\n    pbc_win_sf &lt;- pbc_sf |&gt; filter(label == \"window\")\n    pbc_plot &lt;- ggplot() +\n      geom_sf(data=pbc_win_sf) +\n      geom_sf(data=pbc_point_sf, size=0.5, alpha=0.5) +\n      theme_classic()\n    return(pbc_plot)\n}\nplot_pbc_sim()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_pbc_sim()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_pbc_sim()"
  },
  {
    "objectID": "w10/slides.html#aggregating-point-processes",
    "href": "w10/slides.html#aggregating-point-processes",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Aggregating Point Processes",
    "text": "Aggregating Point Processes\n\nRecall the two ‚Äústages‚Äù of our Poisson-based point processes\n\nA Poisson-distributed number of points, then\nUniformly-distributed coordinates for each point\n\nOne way to see areal data modeling: we keep the Poisson part, but we no longer observe the coordinates for the points!\nSo‚Ä¶ why is it still helpful for you to have sat through those lectures on Point Processes? Two reasons‚Ä¶"
  },
  {
    "objectID": "w10/slides.html#areal-patterns-aggregated-point-patterns",
    "href": "w10/slides.html#areal-patterns-aggregated-point-patterns",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "(1) Areal Patterns = Aggregated Point Patterns",
    "text": "(1) Areal Patterns = Aggregated Point Patterns\n\nOne application, mentioned last week: areal-weighted interpolation using actual models of how the points are distributed within the area!\nRegularly-spaced points is rarely a good ‚Äúdefault‚Äù model!\nHumans, for example, rarely live at perfect evenly-spaced intervals‚Ä¶ they form households, villages, cities\nRegularly-spaced points (we now know) \\(\\implies\\) negative autocorrelation \\(\\implies\\) typically due to inhibition process (competition)"
  },
  {
    "objectID": "w10/slides.html#spatial-scan-statistics",
    "href": "w10/slides.html#spatial-scan-statistics",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "(2) Spatial Scan Statistics",
    "text": "(2) Spatial Scan Statistics\n\nAreal regions often the result of artificial / ‚Äúarbitrary‚Äù human divisions\n\n(Particulate matter doesn‚Äôt pass through customs)\n\n\\(\\implies\\) If we care about processes which don‚Äôt ‚Äúadhere to‚Äù borders (like disease spread), we want to ‚Äúscan‚Äù buffers around points regardless of areal borders"
  },
  {
    "objectID": "w10/slides.html#hierarchical-bayesian-smoothing",
    "href": "w10/slides.html#hierarchical-bayesian-smoothing",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "(3) Hierarchical Bayesian Smoothing",
    "text": "(3) Hierarchical Bayesian Smoothing\n\nThe issue might just be not enough data for some areas, while we have an abundance of data in nearby areas‚Ä¶\n\n\nFrom Kramer (2023), Spatial Epidemiology"
  },
  {
    "objectID": "w10/slides.html#autocorrelation-reminder-weight-matrix-defines-neighbors",
    "href": "w10/slides.html#autocorrelation-reminder-weight-matrix-defines-neighbors",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Autocorrelation Reminder: Weight Matrix Defines ‚ÄúNeighbors‚Äù",
    "text": "Autocorrelation Reminder: Weight Matrix Defines ‚ÄúNeighbors‚Äù\n\nFrom Canadian Rockies Exploration Guide"
  },
  {
    "objectID": "w10/slides.html#choices-available-in-spdep",
    "href": "w10/slides.html#choices-available-in-spdep",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Choices Available in spdep",
    "text": "Choices Available in spdep\n\n\\(w_{ij} = 1\\) if \\(i\\) and \\(j\\) ‚Äútouch‚Äù\n\nRook: Overlap is 1 or 2-dimensional\nQueen: Overlap is 0, 1, or 2-dimensional\n\n\\(w_{ij} = \\frac{1}{\\text{dist}(i, j)}\\)\n\n\\(w(\\textsf{Seoul}, \\textsf{Incheon})\\) &gt; \\(w(\\textsf{Seoul}, \\textsf{Busan})\\) &gt; \\(w(\\textsf{Seoul}, \\textsf{Jeju})\\)\n\n\\(w_{ij} = 1\\) if \\(dist(i, j) &lt; \\overline{D}\\)\n\\(w_{ij} = 1\\) for \\(K\\) nearest neighbors"
  },
  {
    "objectID": "w10/slides.html#morans-i-one-more-time",
    "href": "w10/slides.html#morans-i-one-more-time",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "Moran‚Äôs \\(I\\) One More Time",
    "text": "Moran‚Äôs \\(I\\) One More Time\n\nRound 1 (Week 6): Moran‚Äôs \\(I\\) as ‚Äúthermometer‚Äù\nRound 2 (Today): Could an \\(I\\) value this extreme occur due to random noise?"
  },
  {
    "objectID": "w10/slides.html#references",
    "href": "w10/slides.html#references",
    "title": "Week 10: Evaluating Spatial Hypotheses II: Areal Data",
    "section": "References",
    "text": "References\n\n\nGimond, Manuel. 2024. Introduction to GIS and Spatial Analysis. Colby College (ES214)."
  },
  {
    "objectID": "w07/index.html",
    "href": "w07/index.html",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#key-notation-definition",
    "href": "w07/index.html#key-notation-definition",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Key Notation / Definition",
    "text": "Key Notation / Definition\n\n2-Dimensional Spatial Process (Schabenberger and Gotway 2004, 6)\n\\[\n\\text{Data} = \\left\\{Z(\\mathbf{s}) \\mid \\mathbf{s} \\in D \\subset \\mathbb{R}^d\\right\\}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nGeostatistical Data\nLattice/Region Data\nPoint Pattern\n\n\n\n\nCriteria\nFixed \\(D\\), Continuous\nFixed \\(D\\), Discrete\nRandom subset \\(D^* \\subseteq D\\)\n\n\n\nWhat's Random?\nValue of \\(Z\\) at POINT \\(\\mathbf{s}_i \\in D\\)\nValue of \\(Z\\) across POLYGON \\(\\mathbf{r}_i \\subseteq D\\)\nSubset \\(D^*\\) formed by events\n\n\nInterest\nInfer non-observed parts of \\(D\\)\nAutocorrelation, clustering\nPoint-generating process\n\n\nExample\n\nDumping sand on a table \\(D = \\{(x,y) \\mid x \\in [0,2], y \\in [0,1]\\}\\)\n\\(Z(\\mathbf{s}_i)\\): Attribute(s) at site \\(\\mathbf{s}_i\\) (at coordinate \\(\\mathbf{s}_i = (x_i,y_i)\\))\nExample: Height of sand. \\(Z(\\mathbf{s}_1) = 500\\text{m}\\), \\(Z(\\mathbf{s}_2) = 850\\text{m}\\), \\(\\ldots\\)\n\n\n\\(Z(\\mathbf{s})\\) observed over \\(N \\times N\\) grid of plots\nWell-defined ‚ÄòNeighbors‚Äô (next section!)\nAutocorrelation: Are points around \\(\\mathbf{s}_i\\) likely to have values similar to \\(Z(\\mathbf{s}_i)\\)?\n\n\nUnknown number of lightning strikes \\(\\mathbf{s}_1, \\mathbf{s}_2, \\ldots\\)\nAll of \\(D\\) is observed, but what determines subset \\(D^*\\) where events occur?\nUnmarked: Locations only\nMarked: Locations+info (e.g., intensity of strike)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#geostatistical-data-dumping-sand-onto-a-table",
    "href": "w07/index.html#geostatistical-data-dumping-sand-onto-a-table",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geostatistical Data: Dumping Sand onto a Table!",
    "text": "Geostatistical Data: Dumping Sand onto a Table!\n\nDomain \\(D\\): tabletop; Random process: dumping sand onto the tabletop\n\\(\\Omega\\): All possible realizations of process. \\(\\omega_i \\in \\Omega\\) Particular realization\n\n\n\n\n\n\n\nFigure¬†1: \\(\\omega_1 \\in \\Omega\\)\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: \\(\\omega_2 \\in \\Omega\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: \\(\\omega_3 \\in \\Omega\\)\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: \\(\\omega_4 \\in \\Omega\\)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#example-water-coverage-in-bhola-bangladesh",
    "href": "w07/index.html#example-water-coverage-in-bhola-bangladesh",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Example: Water Coverage in Bhola, Bangladesh",
    "text": "Example: Water Coverage in Bhola, Bangladesh\n\n\n\n\n\n\nArcGIS: Sea Level Rise in Bangladesh (See also)\n\n\n\n\n\n\n\nParenti (2011)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#geostatistical-modeling-terrains-are-not-spiky-chaotic-landscapes",
    "href": "w07/index.html#geostatistical-modeling-terrains-are-not-spiky-chaotic-landscapes",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geostatistical Modeling: Terrains Are Not Spiky Chaotic Landscapes!",
    "text": "Geostatistical Modeling: Terrains Are Not Spiky Chaotic Landscapes!",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#geostatistical-data-rightarrow-point-pattern",
    "href": "w07/index.html#geostatistical-data-rightarrow-point-pattern",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geostatistical Data \\(\\rightarrow\\) Point Pattern",
    "text": "Geostatistical Data \\(\\rightarrow\\) Point Pattern\n\n\n\nIndicator function: \\(\\mathbb{1}\\left[Z(\\mathbf{s}) &gt; 860\\text{m}\\right]\\)\n\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse)\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.4     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(sf)\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\nCode\nlibrary(terra)\n\n\nterra 1.8.60\n\nAttaching package: 'terra'\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nCode\nlibrary(latex2exp)\n#### Define area\nlat_range &lt;- c(-5.0, -6.0)\nlon_range &lt;- c(15, 20)\n#lon_center &lt;- -5.4\n#lat_center &lt;- 36.75\n# And the window around this centroid\nlat_radius &lt;- 0.05\nlon_radius &lt;- 0.1\n\ngen_random_table &lt;- function(world_num=1, return_data=FALSE, rand_seed=NULL) {\n  if (!is.null(rand_seed)) {\n    set.seed(rand_seed)\n  } else {\n    rand_seed &lt;- sample(1:9999, size=1)\n    set.seed(rand_seed)\n  }\n  lat_center &lt;- runif(1, min=min(lat_range), max=max(lat_range))\n  lon_center &lt;- runif(1, min=min(lon_range), max=max(lon_range))\n  lon_lower &lt;- lon_center - lon_radius\n  lon_upper &lt;- lon_center + lon_radius\n  lat_lower &lt;- lat_center - lat_radius\n  lat_upper &lt;- lat_center + lat_radius\n  coords &lt;- data.frame(x = c(lon_lower, lon_lower, lon_upper, lon_upper),\n                       y = c(lat_lower, lat_upper, lat_lower, lat_upper))\n  coords_sf &lt;- st_as_sf(coords, coords = c(\"x\", \"y\"), crs = 4326)\n  # Using geodata\n  elev &lt;- geodata::elevation_3s(lon = lon_center, lat = lat_center, res=2.5, path = getwd())\n  elev &lt;- terra::crop(elev, coords_sf)\n  return(elev)\n}\n\ncompute_hillshade &lt;- function(elev) {\n  # Calculate hillshade\n  slopes &lt;- terra::terrain(elev, \"slope\", unit = \"radians\")\n  aspect &lt;- terra::terrain(elev, \"aspect\", unit = \"radians\")\n  hs &lt;- terra::shade(slopes, aspect)\n  return(hs)\n}\n\nplot_hillshade &lt;- function(elev, hs, title=NULL) {\n  ## Plot hillshading as basemap\n  # (here using terra::plot, but could use tmap)\n  # lat_upper_trimmed &lt;- lat_upper - 0.001*lat_upper\n  # lat_lower_trimmed &lt;- lat_lower - 0.001*lat_lower\n  base_plot &lt;- terra::plot(\n    hs, col = gray(0:100 / 100), legend = FALSE, axes = FALSE, mar=c(0,0,1,0), grid=TRUE\n  )\n  #    xlim = c(elev_xmin, elev_xmax), ylim = c(elev_ymin, elev_ymax))\n  # overlay with elevation\n  \n  color_vec &lt;- terrain.colors(25)\n  plot(elev, col = color_vec, alpha = 0.5, legend = FALSE, axes = FALSE, add = TRUE)\n  \n  # add contour lines\n  terra::contour(elev, col = \"grey30\", add = TRUE)\n  if (!is.null(title)) {\n    world_name &lt;- TeX(sprintf(r\"(World $\\omega_{%d} \\in \\Omega$)\", world_num))\n    title(world_name)\n  }\n}\nelev_r1 &lt;- gen_random_table(rand_seed=6810)\nhs_r1 &lt;- compute_hillshade(elev_r1)\nplot_hillshade(elev_r1, hs_r1)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nterra::ifel(\n  elev_r1 &gt; 860, elev_r1, NA\n) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nelev_r2 &lt;- gen_random_table(rand_seed=6815)\nhs_r2 &lt;- compute_hillshade(elev_r2)\nplot_hillshade(elev_r2, hs_r2)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmy_quant &lt;- function(x) quantile(x, 0.99)\nelev_99 &lt;- terra::global(elev_r2, my_quant)[1,1]\nelev_indic_r2 &lt;- terra::ifel(\n  elev_r2 &gt; elev_99, elev_r2, NA\n)\nplot(elev_indic_r2)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#geospatial-data-rightarrow-latticeregion-data",
    "href": "w07/index.html#geospatial-data-rightarrow-latticeregion-data",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geospatial Data \\(\\rightarrow\\) Lattice/Region Data",
    "text": "Geospatial Data \\(\\rightarrow\\) Lattice/Region Data\n\n\n\n\nCode\ntable_elev &lt;- gen_random_table(rand_seed=6805)\ntable_hs &lt;- compute_hillshade(table_elev)\n#plot_hillshade(table_elev, table_hs)\n#par(mfrow=c(1,2), mar=c(0,0,1,1))\nplot(table_elev)\n\n\n\n\n\n(Pretend this is infinite-resolution) Infinite number of neighbors around each point!\n\n\n\n\n\n\n\nCode\nelev_coarse &lt;- terra::aggregate(table_elev, 12)\nplot(elev_coarse)\n\n\n\n\n\nFinite number of neighbors around each observation \\(\\implies\\) Can study correlations between neighboring cells!",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#who-are-my-neighbors",
    "href": "w07/index.html#who-are-my-neighbors",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Who Are My Neighbors?",
    "text": "Who Are My Neighbors?\n\nContiguity-Based:\n\n\n\n\n\n\n\n\nDistance-Based\n\\(K\\)-Nearest Neighbors",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#distance-based-neighbors",
    "href": "w07/index.html#distance-based-neighbors",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Distance-Based Neighbors",
    "text": "Distance-Based Neighbors\n\n\n\nFrom Xie (2022)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#spatial-autocorrelation",
    "href": "w07/index.html#spatial-autocorrelation",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nLocation \\(i\\) has high value \\(\\implies\\) locations near \\(i\\) more likely to have high values",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#morans-i",
    "href": "w07/index.html#morans-i",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Moran‚Äôs \\(I\\)",
    "text": "Moran‚Äôs \\(I\\)\n\\[\nI =\n\\underset{\\text{Inverse of Variance}}{\\boxed{\\frac{n}{\\sum_{i=1}^{n}(y_i - \\overline{y})^2}}}\n\\frac\n  {\\overbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}(y_i - \\overline{y})(y_j - \\overline{y})}^{\\text{Weighted Covariance}}}\n  {\\underbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}}_{\\text{Normalize Weights}}}\n\\]\n\n\\(I\\) is Large when:\n\n\\(y_i\\) and \\(y_j\\) are neighbors: \\(w_{ij}\\), and\n\\(y_i\\) and \\(y_j\\) large at the same time: \\((y_i - \\overline{y})(y_j - \\overline{y})\\)",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#local-indicators-of-spatial-autocorrelation-lisa",
    "href": "w07/index.html#local-indicators-of-spatial-autocorrelation-lisa",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Local Indicators of Spatial Autocorrelation (LISA)",
    "text": "Local Indicators of Spatial Autocorrelation (LISA)\n\ntldr: See how much a given location \\(\\mathbf{s}\\) contributes to overall Moran‚Äôs \\(I\\)\nLocal Moran‚Äôs \\(I\\):\n\n\\[\nI_i = \\frac{y_i - \\overline{y}}{S_i^2}\\sum_{j=1}^{n}w_{ij}(y_j - \\overline{y})\n\\]",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/index.html#references",
    "href": "w07/index.html#references",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "References",
    "text": "References\n\n\nParenti, Christian. 2011. Tropic of Chaos: Climate Change and the New Geography of Violence. PublicAffairs.\n\n\nSchabenberger, Oliver, and Carol A. Gotway. 2004. Statistical Methods for Spatial Data Analysis. CRC Press.\n\n\nXie, Sherrie. 2022. ‚ÄúAnalyzing Geospatial Data in R.‚Äù R/Medicine Virtual Conference: YouTube.",
    "crumbs": [
      "Week 7: Oct 8"
    ]
  },
  {
    "objectID": "w07/slides.html#key-notation-definition",
    "href": "w07/slides.html#key-notation-definition",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Key Notation / Definition",
    "text": "Key Notation / Definition\n\n2-Dimensional Spatial Process (Schabenberger and Gotway 2004, 6)\n\\[\n\\text{Data} = \\left\\{Z(\\mathbf{s}) \\mid \\mathbf{s} \\in D \\subset \\mathbb{R}^d\\right\\}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nGeostatistical Data\nLattice/Region Data\nPoint Pattern\n\n\n\n\nCriteria\nFixed \\(D\\), Continuous\nFixed \\(D\\), Discrete\nRandom subset \\(D^* \\subseteq D\\)\n\n\n\nWhat's Random?\nValue of \\(Z\\) at POINT \\(\\mathbf{s}_i \\in D\\)\nValue of \\(Z\\) across POLYGON \\(\\mathbf{r}_i \\subseteq D\\)\nSubset \\(D^*\\) formed by events\n\n\nInterest\nInfer non-observed parts of \\(D\\)\nAutocorrelation, clustering\nPoint-generating process\n\n\nExample\n\nDumping sand on a table \\(D = \\{(x,y) \\mid x \\in [0,2], y \\in [0,1]\\}\\)\n\\(Z(\\mathbf{s}_i)\\): Attribute(s) at site \\(\\mathbf{s}_i\\) (at coordinate \\(\\mathbf{s}_i = (x_i,y_i)\\))\nExample: Height of sand. \\(Z(\\mathbf{s}_1) = 500\\text{m}\\), \\(Z(\\mathbf{s}_2) = 850\\text{m}\\), \\(\\ldots\\)\n\n\n\\(Z(\\mathbf{s})\\) observed over \\(N \\times N\\) grid of plots\nWell-defined ‚ÄòNeighbors‚Äô (next section!)\nAutocorrelation: Are points around \\(\\mathbf{s}_i\\) likely to have values similar to \\(Z(\\mathbf{s}_i)\\)?\n\n\nUnknown number of lightning strikes \\(\\mathbf{s}_1, \\mathbf{s}_2, \\ldots\\)\nAll of \\(D\\) is observed, but what determines subset \\(D^*\\) where events occur?\nUnmarked: Locations only\nMarked: Locations+info (e.g., intensity of strike)"
  },
  {
    "objectID": "w07/slides.html#geostatistical-data-dumping-sand-onto-a-table",
    "href": "w07/slides.html#geostatistical-data-dumping-sand-onto-a-table",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geostatistical Data: Dumping Sand onto a Table!",
    "text": "Geostatistical Data: Dumping Sand onto a Table!\n\nDomain \\(D\\): tabletop; Random process: dumping sand onto the tabletop\n\\(\\Omega\\): All possible realizations of process. \\(\\omega_i \\in \\Omega\\) Particular realization\n\n\n\n\n\n\n\nFigure¬†1: \\(\\omega_1 \\in \\Omega\\)\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: \\(\\omega_2 \\in \\Omega\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: \\(\\omega_3 \\in \\Omega\\)\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: \\(\\omega_4 \\in \\Omega\\)"
  },
  {
    "objectID": "w07/slides.html#example-water-coverage-in-bhola-bangladesh",
    "href": "w07/slides.html#example-water-coverage-in-bhola-bangladesh",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Example: Water Coverage in Bhola, Bangladesh",
    "text": "Example: Water Coverage in Bhola, Bangladesh\n\n\n\n\n\n\nArcGIS: Sea Level Rise in Bangladesh (See also)\n\n\n\n\n\n\n\nParenti (2011)"
  },
  {
    "objectID": "w07/slides.html#geostatistical-modeling-terrains-are-not-spiky-chaotic-landscapes",
    "href": "w07/slides.html#geostatistical-modeling-terrains-are-not-spiky-chaotic-landscapes",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geostatistical Modeling: Terrains Are Not Spiky Chaotic Landscapes!",
    "text": "Geostatistical Modeling: Terrains Are Not Spiky Chaotic Landscapes!"
  },
  {
    "objectID": "w07/slides.html#geostatistical-data-rightarrow-point-pattern",
    "href": "w07/slides.html#geostatistical-data-rightarrow-point-pattern",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geostatistical Data \\(\\rightarrow\\) Point Pattern",
    "text": "Geostatistical Data \\(\\rightarrow\\) Point Pattern\n\n\n\nIndicator function: \\(\\mathbb{1}\\left[Z(\\mathbf{s}) &gt; 860\\text{m}\\right]\\)\n\n\n\nCode\nset.seed(6805)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(terra)\nlibrary(latex2exp)\n#### Define area\nlat_range &lt;- c(-5.0, -6.0)\nlon_range &lt;- c(15, 20)\n#lon_center &lt;- -5.4\n#lat_center &lt;- 36.75\n# And the window around this centroid\nlat_radius &lt;- 0.05\nlon_radius &lt;- 0.1\n\ngen_random_table &lt;- function(world_num=1, return_data=FALSE, rand_seed=NULL) {\n  if (!is.null(rand_seed)) {\n    set.seed(rand_seed)\n  } else {\n    rand_seed &lt;- sample(1:9999, size=1)\n    set.seed(rand_seed)\n  }\n  lat_center &lt;- runif(1, min=min(lat_range), max=max(lat_range))\n  lon_center &lt;- runif(1, min=min(lon_range), max=max(lon_range))\n  lon_lower &lt;- lon_center - lon_radius\n  lon_upper &lt;- lon_center + lon_radius\n  lat_lower &lt;- lat_center - lat_radius\n  lat_upper &lt;- lat_center + lat_radius\n  coords &lt;- data.frame(x = c(lon_lower, lon_lower, lon_upper, lon_upper),\n                       y = c(lat_lower, lat_upper, lat_lower, lat_upper))\n  coords_sf &lt;- st_as_sf(coords, coords = c(\"x\", \"y\"), crs = 4326)\n  # Using geodata\n  elev &lt;- geodata::elevation_3s(lon = lon_center, lat = lat_center, res=2.5, path = getwd())\n  elev &lt;- terra::crop(elev, coords_sf)\n  return(elev)\n}\n\ncompute_hillshade &lt;- function(elev) {\n  # Calculate hillshade\n  slopes &lt;- terra::terrain(elev, \"slope\", unit = \"radians\")\n  aspect &lt;- terra::terrain(elev, \"aspect\", unit = \"radians\")\n  hs &lt;- terra::shade(slopes, aspect)\n  return(hs)\n}\n\nplot_hillshade &lt;- function(elev, hs, title=NULL) {\n  ## Plot hillshading as basemap\n  # (here using terra::plot, but could use tmap)\n  # lat_upper_trimmed &lt;- lat_upper - 0.001*lat_upper\n  # lat_lower_trimmed &lt;- lat_lower - 0.001*lat_lower\n  base_plot &lt;- terra::plot(\n    hs, col = gray(0:100 / 100), legend = FALSE, axes = FALSE, mar=c(0,0,1,0), grid=TRUE\n  )\n  #    xlim = c(elev_xmin, elev_xmax), ylim = c(elev_ymin, elev_ymax))\n  # overlay with elevation\n  \n  color_vec &lt;- terrain.colors(25)\n  plot(elev, col = color_vec, alpha = 0.5, legend = FALSE, axes = FALSE, add = TRUE)\n  \n  # add contour lines\n  terra::contour(elev, col = \"grey30\", add = TRUE)\n  if (!is.null(title)) {\n    world_name &lt;- TeX(sprintf(r\"(World $\\omega_{%d} \\in \\Omega$)\", world_num))\n    title(world_name)\n  }\n}\nelev_r1 &lt;- gen_random_table(rand_seed=6810)\nhs_r1 &lt;- compute_hillshade(elev_r1)\nplot_hillshade(elev_r1, hs_r1)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nterra::ifel(\n  elev_r1 &gt; 860, elev_r1, NA\n) |&gt; plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nelev_r2 &lt;- gen_random_table(rand_seed=6815)\nhs_r2 &lt;- compute_hillshade(elev_r2)\nplot_hillshade(elev_r2, hs_r2)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nmy_quant &lt;- function(x) quantile(x, 0.99)\nelev_99 &lt;- terra::global(elev_r2, my_quant)[1,1]\nelev_indic_r2 &lt;- terra::ifel(\n  elev_r2 &gt; elev_99, elev_r2, NA\n)\nplot(elev_indic_r2)"
  },
  {
    "objectID": "w07/slides.html#geospatial-data-rightarrow-latticeregion-data",
    "href": "w07/slides.html#geospatial-data-rightarrow-latticeregion-data",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Geospatial Data \\(\\rightarrow\\) Lattice/Region Data",
    "text": "Geospatial Data \\(\\rightarrow\\) Lattice/Region Data\n\n\n\n\nCode\ntable_elev &lt;- gen_random_table(rand_seed=6805)\ntable_hs &lt;- compute_hillshade(table_elev)\n#plot_hillshade(table_elev, table_hs)\n#par(mfrow=c(1,2), mar=c(0,0,1,1))\nplot(table_elev)\n\n\n\n\n\n(Pretend this is infinite-resolution) Infinite number of neighbors around each point!\n\n\n\n\n\n\n\nCode\nelev_coarse &lt;- terra::aggregate(table_elev, 12)\nplot(elev_coarse)\n\n\n\n\n\nFinite number of neighbors around each observation \\(\\implies\\) Can study correlations between neighboring cells!"
  },
  {
    "objectID": "w07/slides.html#who-are-my-neighbors",
    "href": "w07/slides.html#who-are-my-neighbors",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Who Are My Neighbors?",
    "text": "Who Are My Neighbors?\n\nContiguity-Based:\n\n\n\n\n\n\n\n\nDistance-Based\n\\(K\\)-Nearest Neighbors"
  },
  {
    "objectID": "w07/slides.html#distance-based-neighbors",
    "href": "w07/slides.html#distance-based-neighbors",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Distance-Based Neighbors",
    "text": "Distance-Based Neighbors\n\nFrom Xie (2022)"
  },
  {
    "objectID": "w07/slides.html#spatial-autocorrelation",
    "href": "w07/slides.html#spatial-autocorrelation",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nLocation \\(i\\) has high value \\(\\implies\\) locations near \\(i\\) more likely to have high values"
  },
  {
    "objectID": "w07/slides.html#morans-i",
    "href": "w07/slides.html#morans-i",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Moran‚Äôs \\(I\\)",
    "text": "Moran‚Äôs \\(I\\)\n\\[\nI =\n\\underset{\\text{Inverse of Variance}}{\\boxed{\\frac{n}{\\sum_{i=1}^{n}(y_i - \\overline{y})^2}}}\n\\frac\n  {\\overbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}(y_i - \\overline{y})(y_j - \\overline{y})}^{\\text{Weighted Covariance}}}\n  {\\underbrace{\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{ij}}_{\\text{Normalize Weights}}}\n\\]\n\n\\(I\\) is Large when:\n\n\\(y_i\\) and \\(y_j\\) are neighbors: \\(w_{ij}\\), and\n\\(y_i\\) and \\(y_j\\) large at the same time: \\((y_i - \\overline{y})(y_j - \\overline{y})\\)"
  },
  {
    "objectID": "w07/slides.html#local-indicators-of-spatial-autocorrelation-lisa",
    "href": "w07/slides.html#local-indicators-of-spatial-autocorrelation-lisa",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "Local Indicators of Spatial Autocorrelation (LISA)",
    "text": "Local Indicators of Spatial Autocorrelation (LISA)\n\ntldr: See how much a given location \\(\\mathbf{s}\\) contributes to overall Moran‚Äôs \\(I\\)\nLocal Moran‚Äôs \\(I\\):\n\n\\[\nI_i = \\frac{y_i - \\overline{y}}{S_i^2}\\sum_{j=1}^{n}w_{ij}(y_j - \\overline{y})\n\\]"
  },
  {
    "objectID": "w07/slides.html#references",
    "href": "w07/slides.html#references",
    "title": "Week 7: Spatial Data Science: Three Forms of Spatial Autocorrelation",
    "section": "References",
    "text": "References\n\n\nParenti, Christian. 2011. Tropic of Chaos: Climate Change and the New Geography of Violence. PublicAffairs.\n\n\nSchabenberger, Oliver, and Carol A. Gotway. 2004. Statistical Methods for Spatial Data Analysis. CRC Press.\n\n\nXie, Sherrie. 2022. ‚ÄúAnalyzing Geospatial Data in R.‚Äù R/Medicine Virtual Conference: YouTube."
  },
  {
    "objectID": "final-project.html",
    "href": "final-project.html",
    "title": "Final Project Details",
    "section": "",
    "text": "Feel free to add this calendar to your own GCal/Apple Calendar/etc., to see each important milestone and deadline date related to the final project!",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#final-project-timeline-google-calendar",
    "href": "final-project.html#final-project-timeline-google-calendar",
    "title": "Final Project Details",
    "section": "",
    "text": "Feel free to add this calendar to your own GCal/Apple Calendar/etc., to see each important milestone and deadline date related to the final project!",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#example-final-project-submission",
    "href": "final-project.html#example-final-project-submission",
    "title": "Final Project Details",
    "section": "Example Final Project Submission",
    "text": "Example Final Project Submission\nFirst things first, to jump right into an example of what the final project can end up looking like, click the following link to see an example final project in the required Quarto Manuscript format:\n\nExample Project: ‚ÄúCoup-Proofing via Capital Relocation‚Äù",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#project-overview",
    "href": "final-project.html#project-overview",
    "title": "Final Project Details",
    "section": "Project Overview",
    "text": "Project Overview\nYour job, for the final project, will be to\n\nChoose an application area that you are interested in (this can be drawn from the list in the ‚ÄúApplication Areas‚Äù section below, but doesn‚Äôt have to be! You are very welcome to choose any area that is of interest to you!)\nDevelop a hypothesis about some spatial phenomena within that application area, which can be addressed using the GIS/Spatial Data Science tools we‚Äôve learned in the course. You will need to be specific about whether your hypothesis relates to a first-order property of the observations in your dataset, a second-order property of these observations, or both.\nPresent some initial evidence regarding your hypothesis, whether in the form of visualizations or na√Øve clustering measures such as the global or local versions of Moran‚Äôs \\(I\\).\nAssess the veracity of the hypothesis using formal hypothesis-evaluation approaches. The general ‚Äútemplate‚Äù for this formal hypothesis-evaluation would be to:\n\nCompute and visualize the intensity function and/or Pairwise Correlation Function for your observed data,\nRun 999 Monte Carlo simulations of the spatial patterns that would result from your null hypothesis, then\nCompare the the intensity functions or Pairwise Correlation Functions for these 999 simulations with those of your observed spatial pattern from step (a).\n\nDraw an initial conclusion regarding your hypothesis from Step 2, on the basis of the analysis carried out in Step 4.\nConclude with a ‚Äúroadmap‚Äù of the next steps that you would need to take to further explore and/or refine your initial conclusion from Step 5.\n\nFor example, if your dataset had missing values for important regions/time periods, here you can discuss how you might go about collecting observations to form a better dataset that would allow you to evaluate your hypothesis with greater confidence!",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#application-areas",
    "href": "final-project.html#application-areas",
    "title": "Final Project Details",
    "section": "Application Areas",
    "text": "Application Areas\n\nUrban Planning\nI put this here first only as, the application area where I have the most experience, so can probably be most helpful in terms of project guidance!\nThough it is a broad topic, one way to narrow your scope to make it feasible in the time we have left is to choose between a comparative approach and a case study approach:\nComparative Approach:\nHere the idea is to understand a spatial phenomenon by analyzing how it is implemented across different urban areas. For example, you could choose a measure of transportation efficiency (on-time rate, proportion of urban population living within walking distance of a subway/bus stop, etc.), then see how it is distributed across different urban areas, whether within a specific country or internationally. Then, the project could be rooted in a hypothesis regarding why some urban areas have high efficiency and others have low efficiency.\nCase Study Approach:\nHere, rather than comparing across different urban areas, the idea would be more focused on telling a story about a particular city or urban area. The reason this approach is mentioned after the Comparative Approach is because, in reality, what you‚Äôre doing here is still comparative! It‚Äôs just that, in this case, the comparisons are being made between e.g.¬†subregions of the urban area, or between the urban area observed at different time periods.\nFor example, a famous instance of the use of GIS to study a particular urban area is the Massachusetts state government‚Äôs Logan Airport Health Study, which found significantly higher rates of asthma among children living closer to Logan Airport. Here the point is that the rates were higher for these children relative to children living in other parts of the same urban area. That is, it‚Äôs still a ‚Äúcomparative‚Äù approach, just comparing areas-near-Logan with areas-not-near-Logan!\n\n\n\n\n\n\nFigure¬†1: Pollution expsure areas, as estimated in (Massachusetts Bureau of Environmental Health 2014, 46)\n\n\n\n\n\nClimate Change / Renewable Energy\n\n\nPublic Policy Evaluation\nHere, I specify policy evaluation rather than just public policy studies in general, since I think that some of the tools we‚Äôve learned in class can be particularly helpful for spatially-based comparison of the effectiveness of a given policy choice.\nThat‚Äôs a fairly vague statement so, as a concrete example,\n\n\nInternational Relations\n\n\nPublic Health / Global Health\n\n\nDiffusion Processes",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "final-project.html#gis-datasetsproject-ideas-collection",
    "href": "final-project.html#gis-datasetsproject-ideas-collection",
    "title": "Final Project Details",
    "section": "GIS Datasets/Project Ideas Collection",
    "text": "GIS Datasets/Project Ideas Collection\nOnce we get to the Spatial Data Science unit, I‚Äôm hoping that you will have lots of inspiration in terms of the different methods that can be used for drawing inferences about spatial phenomena! Until then, me and TA Billy will add links to the following Raindrop.io collection, which you can browse to potentially draw inspiration for your own final project topic:",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Introduction to GIS",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#your-final-project",
    "href": "w01/index.html#your-final-project",
    "title": "Week 1: Introduction to GIS",
    "section": "Your Final Project",
    "text": "Your Final Project",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#unit-1-maps",
    "href": "w01/index.html#unit-1-maps",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 1: Maps",
    "text": "Unit 1: Maps\n\n\nsource(\"../dsan-globals/_globals.r\")\n\n\n\nYour least favorite part of the course (per survey üòú)\nMy favorite part of the course (because I love overthinking things)\nMy goal given survey results: Let‚Äôs think of this unit like learning languages for expressing spatial information:\n\n\nlibrary(sf)\nlibrary(svglite)\nsvglite(\"images/st_polygon.svg\", width = 6, height = 4.5)\npoly_blob &lt;- st_polygon(\n  list(\n    rbind(c(2,1), c(3,1), c(5,2), c(6,3), c(5,3), c(4,4), c(3,4), c(1,3), c(2,1)),\n    rbind(c(2,2), c(3,3), c(4,3), c(4,2), c(2,2))\n  )\n)\nplot(poly_blob,\n  border = 'black', col = '#ff8888', lwd = 4\n)\ndev.off()\n\n\n\n\n\n\n\n\nTemporal Information\nSpatial Information\n\n\n\n\n\n\n\n\n\\(\\Rightarrow\\) 22.5 seconds\n\\(\\Rightarrow\\) POLYGON ((2 1, 3 1, 5 2, 6 3, 5 3, 4 4, 3 4, 1 3, 2 1),(2 2, 3 3, 4 3, 4 2, 2 2))\n\n\n\n\nI think you‚Äôll be surprised at how, complexity of geospatial/spatio-temporal data \\(\\implies\\) need for programming-language-independent representations",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#unit-2-using-code-to-make-maps",
    "href": "w01/index.html#unit-2-using-code-to-make-maps",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 2: Using Code to Make Maps",
    "text": "Unit 2: Using Code to Make Maps\n\n(More on this in Prereqs section below!)\nGiven representations from Part 1, the task of coding becomes task of finding ‚Äúbest‚Äù library for loading/manipulating/plotting them\n\nWhere ‚Äúbest‚Äù = best for you!\n\nIn R: sf and friends (tidyverse)\nIn Python: geopandas",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#unit-3-spatial-data-science",
    "href": "w01/index.html#unit-3-spatial-data-science",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 3: Spatial Data Science",
    "text": "Unit 3: Spatial Data Science\n\nDrawing inferences about spatial phenomena\nThe meat of the course\nHow can we write code (Unit 2) to analyze a map (Unit 1) so as to‚Ä¶\n\nDiscover patterns (EDA: Exploratory Data Analysis) or\nTest hypotheses (CDA: Confirmatory Data Analysis)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#unit-4-applications-final-project",
    "href": "w01/index.html#unit-4-applications-final-project",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 4: Applications / Final Project",
    "text": "Unit 4: Applications / Final Project\n\nTake everything you‚Äôve learned in Units 1-3 and Kamehameha them onto something you care about in the world!\nPublic Policy: Which counties are most in need of more transportation infrastructure?\nUrban Planning: Which neighborhoods are most in need of a new bus stop?\nEpidemiology: What properties of a region make it more/less susceptible to infectious diseases? Where should we intervene to ‚Äúcut the chain‚Äù of a disease vector?",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#who-am-i-why-am-i-teaching-you",
    "href": "w01/index.html#who-am-i-why-am-i-teaching-you",
    "title": "Week 1: Introduction to GIS",
    "section": "Who Am I? Why Am I Teaching You?",
    "text": "Who Am I? Why Am I Teaching You?\n\nStarted out as PhD student in Computer Science\n\nUCLA: Algorithmic Game Theory\nStanford (MS): Economic Network Analysis\n\nEnded up with PhD in Political Economy\n\nColumbia: ‚ÄúComputational Political Theory‚Äù",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#my-gis-adventures",
    "href": "w01/index.html#my-gis-adventures",
    "title": "Week 1: Introduction to GIS",
    "section": "My GIS Adventures",
    "text": "My GIS Adventures\n\nHigh school project: mine defusal in Indochina\nAs a Telecommunications Engineer for Huawei (HKUST)\nAs an Urban Economist at UC Berkeley\n\nUsed, e.g., Google Maps API to evaluate effects of Suburbanization of Poverty",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#my-gis-moment",
    "href": "w01/index.html#my-gis-moment",
    "title": "Week 1: Introduction to GIS",
    "section": "My GIS ü§Ø Moment",
    "text": "My GIS ü§Ø Moment\n\n\n\nHorrors of ‚ÄúVietnam War‚Äù did not end in 1975‚Ä¶\nCasualties from unexploded ordnance (cluster bombs) continue to devastate the region, over 220,000 victims:\n\n&gt;105K in Vietnam\n&gt;50K in Laos\n&gt;65K in Cambodia\n\n\n\n\n\n\nFrom Robert (2016)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#huawei-optimizing-cell-tower-placement",
    "href": "w01/index.html#huawei-optimizing-cell-tower-placement",
    "title": "Week 1: Introduction to GIS",
    "section": "Huawei: Optimizing Cell Tower Placement",
    "text": "Huawei: Optimizing Cell Tower Placement\n\n\n\nFrom LTE 4G/5G Self-Organizing Networks",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#the-suburbanization-of-poverty",
    "href": "w01/index.html#the-suburbanization-of-poverty",
    "title": "Week 1: Introduction to GIS",
    "section": "The Suburbanization of Poverty",
    "text": "The Suburbanization of Poverty\n\nSince 2008, a person living in poverty in the US is more likely to be in a suburb than an ‚Äúinner city‚Äù\nWhat does this mean for‚Ä¶\n\nAccess to Food / Public Services?\nFinding a job \\(\\leadsto\\) Commuting?\n\nMy job: computing ‚Äúsuburban accessibility indices‚Äù\nDoes commuting = straight line distance?",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#distance-vs.-distance",
    "href": "w01/index.html#distance-vs.-distance",
    "title": "Week 1: Introduction to GIS",
    "section": "‚ÄúDistance‚Äù vs.¬†Distance!",
    "text": "‚ÄúDistance‚Äù vs.¬†Distance!\nYou‚Äôve just been hired as a fine art curator at The Whitney‚Ä¶ Congratulations!\n\n\n\n\n\n\n\nCommuting 1 mile to the Whitney\n\n\n\nAlso commuting 1 mile to the Whitney",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#as-humans",
    "href": "w01/index.html#as-humans",
    "title": "Week 1: Introduction to GIS",
    "section": "As Humans",
    "text": "As Humans\n\nTo understand the world around you!\n\n\n\n\nCharles Dupin, Carte figurative de l‚Äôinstruction populaire de la France (1826)\n\n\n\n\\(\\implies\\) Crucial landmark in the genesis of social science",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#as-data-scientists",
    "href": "w01/index.html#as-data-scientists",
    "title": "Week 1: Introduction to GIS",
    "section": "As Data Scientists",
    "text": "As Data Scientists\n\nAll data scientists are expected to know how to analyze ‚Äústandard‚Äù types of data: tabular, numeric data (think spreadsheets)\nHowever, you can differentiate yourself in the scary scary job market by developing a particular focus on some ‚Äúnon-standard‚Äù type:\n\n\nHello Mrs.¬†Google Meta OpenAI, yes, indeed, I have a wealth of experience working with [text data / temporal data / signal processing / geospatial data]. This job will be no problem for me.",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#as-public-policy-experts",
    "href": "w01/index.html#as-public-policy-experts",
    "title": "Week 1: Introduction to GIS",
    "section": "As Public Policy Experts",
    "text": "As Public Policy Experts\n\nOftentimes, all it takes is one map to see why a policy has failed üò±\n\n\n\n\nWho can guess what this map represents? (Source)\n\n\n\nhttp://www.radicalcartography.net/index.html?chicagodots, then adapted to DC: ‚Äú[Eric Fisher] was astounded by Bill Rankin‚Äôs map of Chicago‚Äôs racial and ethnic divides and wanted to see what other cities looked like mapped the same way. To match his map, Red is White, Blue is Black, Green is Asian, Orange is Hispanic, Gray is Other, and each dot is 25 people. Data from Census 2000. Base map ¬© OpenStreetMap, CC-BY-SA‚Äù https://commons.wikimedia.org/wiki/File:Race_and_ethnicity_map_of_Washington,_D.C..png",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#gis-as-an-umbrella-term",
    "href": "w01/index.html#gis-as-an-umbrella-term",
    "title": "Week 1: Introduction to GIS",
    "section": "GIS as an ‚ÄúUmbrella Term‚Äù",
    "text": "GIS as an ‚ÄúUmbrella Term‚Äù\n\nLibraries and tools we‚Äôll use: specific systems/methods for geospatial analysis\nGIS is an ‚Äúumbrella term‚Äù, which just vaguely refers to this entire universe of libraries/tools/techniques/approaches\n\n\n\n\n\n\n\n\n\nUmbrella Term\nConcepts\nSpecific Skills\n\n\n\n\nCoding\n\nVariables\nControl Flow\nAlgorithms\n\n\nPython\nR\nJavaScript\n\n\n\nGIS\n\nProjections\nVector vs.¬†Raster\nSpatial Data Formats (shapefiles, .geojson)\n\n\nArcGIS\nGeoPandas (Python)\nsf (R)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#arcgis",
    "href": "w01/index.html#arcgis",
    "title": "Week 1: Introduction to GIS",
    "section": "ArcGIS‚Ä¶",
    "text": "ArcGIS‚Ä¶\n\nFor info on Georgetown‚Äôs provision of ArcGIS (Online, Pro, and Desktop), see the Library Guide\n\n\n\n\nUkraine Level-1 Administrative Regions Map (see CDTO talk)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#then-why-cant-we-just-use-arcgis",
    "href": "w01/index.html#then-why-cant-we-just-use-arcgis",
    "title": "Week 1: Introduction to GIS",
    "section": "Then‚Ä¶ Why Can‚Äôt We Just Use ArcGIS?",
    "text": "Then‚Ä¶ Why Can‚Äôt We Just Use ArcGIS?\nAnalogy from non-geospatial data science:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText\nDrawn Map\n‚Üí\nSpeadsheet\nDigital Map\n‚Üí\nEquations\nMaps w/ArcGIS\n‚Üí\nCode\nThis Class\n\n\n\n\n Start writing\n\n\ninfo.txt\n\nI gave Ana $3, then Ana paid me back $2. [...]\n\n Realize there‚Äôs regularity/structure ü§î\n Start entering info in rows\n\n\n\nFr\nTo\nAmt\nBal\n\n\n\n\nMe\nAna\n$3\n-$3\n\n\nAna\nMe\n$2\n-$1\n\n\n\n Realize you‚Äôre manually computing things that could be automated ü§î\n Start using equations\n\n\n\nFr\nTo\nAmt\nBal\n\n\n\n\nMe\nAna\n$3\n=0-C1\n\n\nAna\nMe\n$2\n=D1-C2\n\n\n\n Realize you need fancier equations, and/or need to coordinate with inputs (APIs), outputs (plotting libraries) ü§î\n Write code\n\n\nplot_balance.py\n\nimport pandas as pd\ndf = pd.read_csv(...)\ncalc_weekly_balance()\ndf.plot()\n\n \n Profit üí≤üí∞ü§ëüí∞üí≤",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#the-spatial-data-science-universe",
    "href": "w01/index.html#the-spatial-data-science-universe",
    "title": "Week 1: Introduction to GIS",
    "section": "The Spatial Data Science Universe",
    "text": "The Spatial Data Science Universe\n\n\n\n\n\n\nWe‚Äôll cover key pieces:  GDAL (Geospatial Data Abstraction Library),  PROJ to convert between projections,  GEOS for computational geometry",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#pedagogical-principles",
    "href": "w01/index.html#pedagogical-principles",
    "title": "Week 1: Introduction to GIS",
    "section": "Pedagogical Principles",
    "text": "Pedagogical Principles\n\nThere‚Äôs literally no such thing as ‚Äúintelligence‚Äù\nAnyone is capable of learning anything (neural plasticity)\nGrowth mindset: ‚ÄúI can‚Äôt do this‚Äù \\(\\leadsto\\) ‚ÄúI can‚Äôt do this yet!‚Äù\nThe point of a class is learning: understanding something about the world, either (a) For its own sake (end in itself) or (b) Because it‚Äôs relevant to something you care about (means to an end)\n\n\n\nOur teaching should be governed, not by a desire to make students learn things, but by the endeavor to keep burning within them that light which is called curiosity. (Montessori 1916)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#chatgpt-and-whatnot",
    "href": "w01/index.html#chatgpt-and-whatnot",
    "title": "Week 1: Introduction to GIS",
    "section": "ChatGPT and Whatnot",
    "text": "ChatGPT and Whatnot\n\nIf you feel like ChatGPT will help you learn something in the course, then use it!\nIf you feel like you‚Äôre using it as a ‚Äúcrutch‚Äù, try to hold yourself accountable for not using it!\n\n\n\n\n\n\n\n\nTake the time/energy you're using to worry about...\nUse it instead to worry about...\n\n\n\n\n\nChatGPT\nCollaboration Policies\nPlagiarism\n\nLearning GIS",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#on-not-worrying-about-prereqs",
    "href": "w01/index.html#on-not-worrying-about-prereqs",
    "title": "Week 1: Introduction to GIS",
    "section": "On Not Worrying About Prereqs",
    "text": "On Not Worrying About Prereqs\n\nI genuinely believe that I can make the course accessible to you, meeting you wherever you‚Äôre at, no matter what!\nEveryone learns at their own pace (who says 14 weeks is ‚Äúcorrect‚Äù amount of time to learn GIS?), and I structure my courses as best as I possibly can to adapt to your pace\n\\(\\Rightarrow\\) Assessments (HW, Midterm) valuable in two ways:\n[Valuable for you] As an accountability mechanism to make sure you‚Äôre learn the material (how do we know when we‚Äôve learned something? When we can answer questions about it / use it to accomplish things!)\n[Valuable for me] For assessing and updating pace",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#r-andor-python-andor-js",
    "href": "w01/index.html#r-andor-python-andor-js",
    "title": "Week 1: Introduction to GIS",
    "section": "R and/or Python and/or JS",
    "text": "R and/or Python and/or JS\n\nMy Geometry vs.¬†Algebra Rant‚Ä¶ Euclid‚Äôs Elements, Book VI, Proposition 28.\nThe problem: Divide a given straight line so that the rectangle contained by its segments may be equal to a given area, not exceeding the square of half the line.\n\n\n\nGeometers solved w/geometry (300 BC)‚Ä¶\n\n\n\n\n\n\n‚Ä¶Algebraists solved w/algebra (2000 BC)‚Ä¶\n\\[\n\\begin{align*}\n&ax^2 + bx + c = 0 \\\\\n\\Rightarrow \\; & x_+ = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}\n\\end{align*}\n\\]\n‚Ä¶From 1637 onwards, whichever is easier! ü§Øü§Øü§Ø (Isomorphism)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFig¬†1: Circle with radius 1? Or \\((x,y)\\) satisfying \\(x^2 + y^2 = 1\\)?",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#learning-how-to-learn",
    "href": "w01/index.html#learning-how-to-learn",
    "title": "Week 1: Introduction to GIS",
    "section": "Learning How To Learn",
    "text": "Learning How To Learn\n\n\n\n\n\n\nFig¬†2: From The Carter (Documentary)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#hes-literally-extremely-correct",
    "href": "w01/index.html#hes-literally-extremely-correct",
    "title": "Week 1: Introduction to GIS",
    "section": "He‚Äôs Literally Extremely Correct!",
    "text": "He‚Äôs Literally Extremely Correct!\n\n\n\nFrom Elsevier Osmosis: Spaced Repetition",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#our-first-map-polygons",
    "href": "w01/index.html#our-first-map-polygons",
    "title": "Week 1: Introduction to GIS",
    "section": "Our First Map: Polygons!",
    "text": "Our First Map: Polygons!\n(Quick demo adapted from Sherry Xie‚Äôs R Consortium Workshop: Analyzing Geospatial Data in R, using DC rather than Philadelphia open data.)\n\n\nCode\nlibrary(sf)\n# Load DC tracts data\ndc_sf_fpath &lt;- \"data/DC_Census_2020/Census_Tracts_in_2020.shp\"\ndc_sf &lt;- st_read(dc_sf_fpath);\n\n\nReading layer `Census_Tracts_in_2020' from data source \n  `/Users/jpj/gtown-local/ppol6805/w01/data/DC_Census_2020/Census_Tracts_in_2020.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 206 features and 315 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8584933 ymin: 4691871 xmax: -8561515 ymax: 4721078\nProjected CRS: WGS 84 / Pseudo-Mercator\n\n\nCode\ncols_to_keep &lt;- c(\"OBJECTID\", \"TRACT\", \"GEOID\", \"ALAND\", \"AWATER\", \"STUSAB\", \"SUMLEV\", \"GEOCODE\", \"STATE\", \"NAME\", \"POP100\", \"HU100\", \"geometry\")\ndc_sf &lt;- dc_sf |&gt; select(cols_to_keep)\n\n\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\n‚Ñπ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %&gt;% select(cols_to_keep)\n\n  # Now:\n  data %&gt;% select(all_of(cols_to_keep))\n\nSee &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#sf-objects",
    "href": "w01/index.html#sf-objects",
    "title": "Week 1: Introduction to GIS",
    "section": "sf Objects",
    "text": "sf Objects\ndc_sf is an object of type sf (short for ‚Äúsimple feature‚Äù), which extends data.frame, and contains features which have type POLYGON\n\nclass(dc_sf)\n\n[1] \"sf\"         \"data.frame\"\n\nhead(dc_sf)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nTRACT\nGEOID\nALAND\nAWATER\nSTUSAB\nSUMLEV\nGEOCODE\nSTATE\nNAME\nPOP100\nHU100\ngeometry\n\n\n\n\n1\n002002\n11001002002\n849376\n0\nDC\n140\n11001002002\n11\nCensus Tract 20.02\n4072\n1532\nPOLYGON ((-8575655 4714476,‚Ä¶\n\n\n2\n002101\n11001002101\n600992\n0\nDC\n140\n11001002101\n11\nCensus Tract 21.01\n5687\n2335\nPOLYGON ((-8574745 4715676,‚Ä¶\n\n\n3\n002102\n11001002102\n725975\n0\nDC\n140\n11001002102\n11\nCensus Tract 21.02\n5099\n2221\nPOLYGON ((-8573824 4715684,‚Ä¶\n\n\n4\n002201\n11001002201\n415173\n0\nDC\n140\n11001002201\n11\nCensus Tract 22.01\n3485\n1229\nPOLYGON ((-8574654 4714781,‚Ä¶\n\n\n5\n002202\n11001002202\n698895\n566\nDC\n140\n11001002202\n11\nCensus Tract 22.02\n3339\n1454\nPOLYGON ((-8573792 4714811,‚Ä¶\n\n\n6\n000101\n11001000101\n199776\n5261\nDC\n140\n11001000101\n11\nCensus Tract 1.01\n1406\n999\nPOLYGON ((-8577962 4708867,‚Ä¶",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#working-with-sf-objects",
    "href": "w01/index.html#working-with-sf-objects",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\nWith some rare but important exceptions (which we‚Äôll learn!), can be used just like a data.frame / tibble:\n\n\nCode\nstr(dc_sf)   # view structure\n\n\nClasses 'sf' and 'data.frame':  206 obs. of  13 variables:\n $ OBJECTID: int  1 2 3 4 5 6 7 8 9 10 ...\n $ TRACT   : chr  \"002002\" \"002101\" \"002102\" \"002201\" ...\n $ GEOID   : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ ALAND   : int  849376 600992 725975 415173 698895 199776 1706484 505004 776435 1042157 ...\n $ AWATER  : int  0 0 0 0 566 5261 516665 0 439661 2305 ...\n $ STUSAB  : chr  \"DC\" \"DC\" \"DC\" \"DC\" ...\n $ SUMLEV  : int  140 140 140 140 140 140 140 140 140 140 ...\n $ GEOCODE : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ STATE   : int  11 11 11 11 11 11 11 11 11 11 ...\n $ NAME    : chr  \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\" \"Census Tract 22.01\" ...\n $ POP100  : int  4072 5687 5099 3485 3339 1406 3417 4108 4672 6161 ...\n $ HU100   : int  1532 2335 2221 1229 1454 999 2053 11 2169 2845 ...\n $ geometry:sfc_POLYGON of length 206; first list element: List of 1\n  ..$ : num [1:155, 1:2] -8575655 -8575655 -8575655 -8575655 -8575655 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:12] \"OBJECTID\" \"TRACT\" \"GEOID\" \"ALAND\" ...",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#working-with-sf-objects-1",
    "href": "w01/index.html#working-with-sf-objects-1",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf)  # view first several rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nTRACT\nGEOID\nALAND\nAWATER\nSTUSAB\nSUMLEV\nGEOCODE\nSTATE\nNAME\nPOP100\nHU100\ngeometry\n\n\n\n\n1\n002002\n11001002002\n849376\n0\nDC\n140\n11001002002\n11\nCensus Tract 20.02\n4072\n1532\nPOLYGON ((-8575655 4714476,‚Ä¶\n\n\n2\n002101\n11001002101\n600992\n0\nDC\n140\n11001002101\n11\nCensus Tract 21.01\n5687\n2335\nPOLYGON ((-8574745 4715676,‚Ä¶\n\n\n3\n002102\n11001002102\n725975\n0\nDC\n140\n11001002102\n11\nCensus Tract 21.02\n5099\n2221\nPOLYGON ((-8573824 4715684,‚Ä¶\n\n\n4\n002201\n11001002201\n415173\n0\nDC\n140\n11001002201\n11\nCensus Tract 22.01\n3485\n1229\nPOLYGON ((-8574654 4714781,‚Ä¶\n\n\n5\n002202\n11001002202\n698895\n566\nDC\n140\n11001002202\n11\nCensus Tract 22.02\n3339\n1454\nPOLYGON ((-8573792 4714811,‚Ä¶\n\n\n6\n000101\n11001000101\n199776\n5261\nDC\n140\n11001000101\n11\nCensus Tract 1.01\n1406\n999\nPOLYGON ((-8577962 4708867,‚Ä¶",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#working-with-sf-objects-2",
    "href": "w01/index.html#working-with-sf-objects-2",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\ndim(dc_sf)   # view dimensions\n\n\n[1] 206  13\n\n\nCode\ndc_sf[1,]    # select first row\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nTRACT\nGEOID\nALAND\nAWATER\nSTUSAB\nSUMLEV\nGEOCODE\nSTATE\nNAME\nPOP100\nHU100\ngeometry\n\n\n\n\n1\n002002\n11001002002\n849376\n0\nDC\n140\n11001002002\n11\nCensus Tract 20.02\n4072\n1532\nPOLYGON ((-8575655 4714476,‚Ä¶",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#working-with-sf-objects-3",
    "href": "w01/index.html#working-with-sf-objects-3",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf$NAME)  # select column by name  \n\n\n[1] \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\"\n[4] \"Census Tract 22.01\" \"Census Tract 22.02\" \"Census Tract 1.01\" \n\n\nCode\nhead(dc_sf[,4])         # select column by number\n\n\n\n\n\n\nALAND\ngeometry\n\n\n\n\n849376\nPOLYGON ((-8575655 4714476,‚Ä¶\n\n\n600992\nPOLYGON ((-8574745 4715676,‚Ä¶\n\n\n725975\nPOLYGON ((-8573824 4715684,‚Ä¶\n\n\n415173\nPOLYGON ((-8574654 4714781,‚Ä¶\n\n\n698895\nPOLYGON ((-8573792 4714811,‚Ä¶\n\n\n199776\nPOLYGON ((-8577962 4708867,‚Ä¶",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#and-actually-displaying-the-map",
    "href": "w01/index.html#and-actually-displaying-the-map",
    "title": "Week 1: Introduction to GIS",
    "section": "And‚Ä¶ Actually Displaying the Map!",
    "text": "And‚Ä¶ Actually Displaying the Map!\n\n\nCode\n# We can extract the geometry with the st_geometry function\ndc_geo &lt;- st_geometry(dc_sf)\n#pt_geo\n\n# Plot the geometry with base R's plot() function\nplot(dc_geo)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#key-notation-definition",
    "href": "w01/index.html#key-notation-definition",
    "title": "Week 1: Introduction to GIS",
    "section": "Key Notation / Definition",
    "text": "Key Notation / Definition\n\n\n\\(d\\)-Dimensional ‚ÄúSpatial Process‚Äù (Schabenberger and Gotway 2004, 6)\n\n\\[\n\\text{Data} = \\left\\{Z(\\mathbf{s}) \\mid \\mathbf{s} \\in D \\subset \\mathbb{R}^d\\right\\}\n\\]\n\n\\(d &gt; 1\\): Data forms a Random Field (this class: \\(d = 2\\)!)\n\n\n\n\n\n\n\n\n\n\n\n\nGeostatistical Data\nLattice/Region Data\nPoint Pattern\n\n\n\n\nCriteria\nFixed \\(D\\), Continuous\nFixed \\(D\\), Discrete\nRandom subset \\(D^* \\subseteq D\\)\n\n\nInterest\nInfer non-observed parts of \\(D\\)\nAutocorrelation, clustering\nPoint-generating process\n\n\nExample\n\n\\(N\\) trees \\(\\mathbf{s}_1, \\mathbf{s}_2, \\ldots, \\mathbf{s}_N\\), observed within a sample window \\(D \\subset \\mathbb{R}^2\\), (\\(D\\) some finite plot of land)\n\\(Z(\\mathbf{s}_i)\\): Attribute(s) at site \\(\\mathbf{s}_i\\)\nExample: Height. \\(Z(\\mathbf{s}_1) = 500\\text{m}\\), \\(Z(\\mathbf{s}_2) = 850\\text{m}\\), \\(\\ldots\\)\n\n\n\\(Z(\\mathbf{s})\\) observed over \\(N \\times N\\) grid of plots\n\\(\\Rightarrow\\) Contiguity, Neighbors (next section of slides!)\n\\(\\Rightarrow\\) Autocorrelation: Are points around \\(\\mathbf{s}_i\\) likely to have values similar to \\(Z(\\mathbf{s}_i)\\)?\n\n\nUnknown number of lightning strikes \\(\\mathbf{s}_1, \\mathbf{s}_2, \\ldots\\)\nContrast with geostatistical: all of \\(D\\) is observed, but what determines the subset \\(D^*\\) where events occur?\n‚ÄúUnmarked‚Äù: Just locations\n‚ÄúMarked‚Äù: Locations+info (e.g., intensity of strike)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#spatial-randomness",
    "href": "w01/index.html#spatial-randomness",
    "title": "Week 1: Introduction to GIS",
    "section": "Spatial Randomness",
    "text": "Spatial Randomness\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6805)\nN &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n#reg_sims &lt;- rMaternI(N, r=r_core, win=obs_window)\ncond_reg_sims &lt;- rSSI(r=r_core, N)\n# CSR data\n#csr_sims &lt;- rpoispp(N, win=obs_window)\ncond_sr_sims &lt;- rpoint(N, win=obs_window)\n### Clustered data\n#clust_sims &lt;- rMatClust(kappa=6, r=2.5*r_core, mu=10, win=obs_window)\n#clust_sims &lt;- rMatClust(mu=5, kappa=1, scale=0.1, win=obs_window, n.cond=N, w.cond=obs_window)\n#clust_sims &lt;- rclusterBKBC(clusters=\"MatClust\", kappa=10, mu=10, scale=0.05, verbose=FALSE)\n# Each cluster consist of 10 points in a disc of radius 0.2\nnclust &lt;- function(x0, y0, radius, n) {\n    #print(n)\n    return(runifdisc(10, radius, centre=c(x0, y0)))\n}\ncond_clust_sims &lt;- rNeymanScott(kappa=5, expand=0.0, rclust=nclust, radius=2*r_core, n=10)\n# And PLOT\nplot_w &lt;- 400\nplot_h &lt;- 400\nplot_scale &lt;- 2.25\ncond_reg_plot &lt;- cond_reg_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_reg.png\", cond_reg_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncond_sr_plot &lt;- cond_sr_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_sr.png\", cond_sr_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncond_clust_plot &lt;- cond_clust_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  dsan_theme()\nggsave(\"images/cond_clust.png\", cond_clust_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed \\(N\\)\n60\n\n60\n\n60",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#complete-spatial-randomness-csr",
    "href": "w01/index.html#complete-spatial-randomness-csr",
    "title": "Week 1: Introduction to GIS",
    "section": "Complete Spatial Randomness (CSR)",
    "text": "Complete Spatial Randomness (CSR)\n\n\nCode\nlibrary(tidyverse)\nlibrary(spatstat)\nset.seed(6807)\nlambda &lt;- 60\nr_core &lt;- 0.05\nobs_window &lt;- square(1)\n# Regularity via Inhibition\n# Regularity via Inhibition\nreg_sims &lt;- rMaternI(lambda, r=r_core, win=obs_window)\n# CSR data\ncsr_sims &lt;- rpoispp(N, win=obs_window)\n### Clustered data\nclust_mu &lt;- 10\nclust_sims &lt;- rMatClust(kappa=lambda / clust_mu, scale=2*r_core, mu=10, win=obs_window)\n# And PLOT\nplot_w &lt;- 400\nplot_h &lt;- 400\nplot_scale &lt;- 2.25\nreg_plot &lt;- reg_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",reg_sims$n)) +\n  dsan_theme()\nggsave(\"images/reg.png\", reg_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\ncsr_plot &lt;- csr_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",csr_sims$n)) +\n  dsan_theme()\nggsave(\"images/csr.png\", csr_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\nclust_plot &lt;- clust_sims |&gt; sf::st_as_sf() |&gt;\n  ggplot() +\n  geom_sf() +\n  labs(title=paste0(\"N = \",clust_sims$n)) +\n  dsan_theme()\nggsave(\"images/clust.png\", clust_plot, width=plot_w, height=plot_h, units=\"px\", scale=plot_scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed Intensity \\(\\lambda\\)\n60\n\n60\n\n60\n\n\nRandom \\(N\\)",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/index.html#references",
    "href": "w01/index.html#references",
    "title": "Week 1: Introduction to GIS",
    "section": "References",
    "text": "References\n\n\nMontessori, Maria. 1916. Spontaneous Activity in Education: A Basic Guide to the Montessori Methods of Learning in the Classroom. Lulu Press.\n\n\nRobert, Am√©lie. 2016. ‚ÄúAt the Heart of the Vietnam War: Herbicides, Napalm and Bulldozers Against the A L∆∞·ªõi Mountains.‚Äù Journal of Alpine Research Revue de G√©ographie Alpine, no. 104-1 (April). https://doi.org/10.4000/rga.3266.\n\n\nSchabenberger, Oliver, and Carol A. Gotway. 2004. Statistical Methods for Spatial Data Analysis. CRC Press. https://www.dropbox.com/scl/fi/25gj53qitsdzw9kvcvfjf/Oliver-Schabenberger-Carol-A.-Gotway-Statistical-methods-for-spatial-data-analysis.pdf?rlkey=p5ih232gmxzm3zstvszux2big&dl=1.",
    "crumbs": [
      "Week 1: Aug 27"
    ]
  },
  {
    "objectID": "w01/slides.html#your-final-project",
    "href": "w01/slides.html#your-final-project",
    "title": "Week 1: Introduction to GIS",
    "section": "Your Final Project",
    "text": "Your Final Project"
  },
  {
    "objectID": "w01/slides.html#unit-1-maps",
    "href": "w01/slides.html#unit-1-maps",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 1: Maps",
    "text": "Unit 1: Maps\n\n\n\n\nYour least favorite part of the course (per survey üòú)\nMy favorite part of the course (because I love overthinking things)\nMy goal given survey results: Let‚Äôs think of this unit like learning languages for expressing spatial information:\n\n\n\n\n\n\n\n\nTemporal Information\nSpatial Information\n\n\n\n\n\n\n\n\n\\(\\Rightarrow\\) 22.5 seconds\n\\(\\Rightarrow\\) POLYGON ((2 1, 3 1, 5 2, 6 3, 5 3, 4 4, 3 4, 1 3, 2 1),(2 2, 3 3, 4 3, 4 2, 2 2))\n\n\n\n\nI think you‚Äôll be surprised at how, complexity of geospatial/spatio-temporal data \\(\\implies\\) need for programming-language-independent representations"
  },
  {
    "objectID": "w01/slides.html#unit-2-using-code-to-make-maps",
    "href": "w01/slides.html#unit-2-using-code-to-make-maps",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 2: Using Code to Make Maps",
    "text": "Unit 2: Using Code to Make Maps\n\n(More on this in Prereqs section below!)\nGiven representations from Part 1, the task of coding becomes task of finding ‚Äúbest‚Äù library for loading/manipulating/plotting them\n\nWhere ‚Äúbest‚Äù = best for you!\n\nIn R: sf and friends (tidyverse)\nIn Python: geopandas"
  },
  {
    "objectID": "w01/slides.html#unit-3-spatial-data-science",
    "href": "w01/slides.html#unit-3-spatial-data-science",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 3: Spatial Data Science",
    "text": "Unit 3: Spatial Data Science\n\nDrawing inferences about spatial phenomena\nThe meat of the course\nHow can we write code (Unit 2) to analyze a map (Unit 1) so as to‚Ä¶\n\nDiscover patterns (EDA: Exploratory Data Analysis) or\nTest hypotheses (CDA: Confirmatory Data Analysis)"
  },
  {
    "objectID": "w01/slides.html#unit-4-applications-final-project",
    "href": "w01/slides.html#unit-4-applications-final-project",
    "title": "Week 1: Introduction to GIS",
    "section": "Unit 4: Applications / Final Project",
    "text": "Unit 4: Applications / Final Project\n\nTake everything you‚Äôve learned in Units 1-3 and Kamehameha them onto something you care about in the world!\nPublic Policy: Which counties are most in need of more transportation infrastructure?\nUrban Planning: Which neighborhoods are most in need of a new bus stop?\nEpidemiology: What properties of a region make it more/less susceptible to infectious diseases? Where should we intervene to ‚Äúcut the chain‚Äù of a disease vector?"
  },
  {
    "objectID": "w01/slides.html#who-am-i-why-am-i-teaching-you",
    "href": "w01/slides.html#who-am-i-why-am-i-teaching-you",
    "title": "Week 1: Introduction to GIS",
    "section": "Who Am I? Why Am I Teaching You?",
    "text": "Who Am I? Why Am I Teaching You?\n\nStarted out as PhD student in Computer Science\n\nUCLA: Algorithmic Game Theory\nStanford (MS): Economic Network Analysis\n\nEnded up with PhD in Political Economy\n\nColumbia: ‚ÄúComputational Political Theory‚Äù"
  },
  {
    "objectID": "w01/slides.html#my-gis-adventures",
    "href": "w01/slides.html#my-gis-adventures",
    "title": "Week 1: Introduction to GIS",
    "section": "My GIS Adventures",
    "text": "My GIS Adventures\n\nHigh school project: mine defusal in Indochina\nAs a Telecommunications Engineer for Huawei (HKUST)\nAs an Urban Economist at UC Berkeley\n\nUsed, e.g., Google Maps API to evaluate effects of Suburbanization of Poverty"
  },
  {
    "objectID": "w01/slides.html#my-gis-moment",
    "href": "w01/slides.html#my-gis-moment",
    "title": "Week 1: Introduction to GIS",
    "section": "My GIS ü§Ø Moment",
    "text": "My GIS ü§Ø Moment\n\n\n\nHorrors of ‚ÄúVietnam War‚Äù did not end in 1975‚Ä¶\nCasualties from unexploded ordnance (cluster bombs) continue to devastate the region, over 220,000 victims:\n\n&gt;105K in Vietnam\n&gt;50K in Laos\n&gt;65K in Cambodia\n\n\n\n\n\n\nFrom Robert (2016)"
  },
  {
    "objectID": "w01/slides.html#huawei-optimizing-cell-tower-placement",
    "href": "w01/slides.html#huawei-optimizing-cell-tower-placement",
    "title": "Week 1: Introduction to GIS",
    "section": "Huawei: Optimizing Cell Tower Placement",
    "text": "Huawei: Optimizing Cell Tower Placement\n\nFrom LTE 4G/5G Self-Organizing Networks"
  },
  {
    "objectID": "w01/slides.html#the-suburbanization-of-poverty",
    "href": "w01/slides.html#the-suburbanization-of-poverty",
    "title": "Week 1: Introduction to GIS",
    "section": "The Suburbanization of Poverty",
    "text": "The Suburbanization of Poverty\n\nSince 2008, a person living in poverty in the US is more likely to be in a suburb than an ‚Äúinner city‚Äù\nWhat does this mean for‚Ä¶\n\nAccess to Food / Public Services?\nFinding a job \\(\\leadsto\\) Commuting?\n\nMy job: computing ‚Äúsuburban accessibility indices‚Äù\nDoes commuting = straight line distance?"
  },
  {
    "objectID": "w01/slides.html#distance-vs.-distance",
    "href": "w01/slides.html#distance-vs.-distance",
    "title": "Week 1: Introduction to GIS",
    "section": "‚ÄúDistance‚Äù vs.¬†Distance!",
    "text": "‚ÄúDistance‚Äù vs.¬†Distance!\nYou‚Äôve just been hired as a fine art curator at The Whitney‚Ä¶ Congratulations!\n\n\n\n\n\n\n\nCommuting 1 mile to the Whitney\n\n\n\nAlso commuting 1 mile to the Whitney"
  },
  {
    "objectID": "w01/slides.html#as-humans",
    "href": "w01/slides.html#as-humans",
    "title": "Week 1: Introduction to GIS",
    "section": "As Humans",
    "text": "As Humans\n\nTo understand the world around you!\n\n\nCharles Dupin, Carte figurative de l‚Äôinstruction populaire de la France (1826)\n\\(\\implies\\) Crucial landmark in the genesis of social science"
  },
  {
    "objectID": "w01/slides.html#as-data-scientists",
    "href": "w01/slides.html#as-data-scientists",
    "title": "Week 1: Introduction to GIS",
    "section": "As Data Scientists",
    "text": "As Data Scientists\n\nAll data scientists are expected to know how to analyze ‚Äústandard‚Äù types of data: tabular, numeric data (think spreadsheets)\nHowever, you can differentiate yourself in the scary scary job market by developing a particular focus on some ‚Äúnon-standard‚Äù type:\n\n\nHello Mrs.¬†Google Meta OpenAI, yes, indeed, I have a wealth of experience working with [text data / temporal data / signal processing / geospatial data]. This job will be no problem for me."
  },
  {
    "objectID": "w01/slides.html#as-public-policy-experts",
    "href": "w01/slides.html#as-public-policy-experts",
    "title": "Week 1: Introduction to GIS",
    "section": "As Public Policy Experts",
    "text": "As Public Policy Experts\n\nOftentimes, all it takes is one map to see why a policy has failed üò±\n\n\nWho can guess what this map represents? (Source)\nhttp://www.radicalcartography.net/index.html?chicagodots, then adapted to DC: ‚Äú[Eric Fisher] was astounded by Bill Rankin‚Äôs map of Chicago‚Äôs racial and ethnic divides and wanted to see what other cities looked like mapped the same way. To match his map, Red is White, Blue is Black, Green is Asian, Orange is Hispanic, Gray is Other, and each dot is 25 people. Data from Census 2000. Base map ¬© OpenStreetMap, CC-BY-SA‚Äù https://commons.wikimedia.org/wiki/File:Race_and_ethnicity_map_of_Washington,_D.C..png"
  },
  {
    "objectID": "w01/slides.html#gis-as-an-umbrella-term",
    "href": "w01/slides.html#gis-as-an-umbrella-term",
    "title": "Week 1: Introduction to GIS",
    "section": "GIS as an ‚ÄúUmbrella Term‚Äù",
    "text": "GIS as an ‚ÄúUmbrella Term‚Äù\n\nLibraries and tools we‚Äôll use: specific systems/methods for geospatial analysis\nGIS is an ‚Äúumbrella term‚Äù, which just vaguely refers to this entire universe of libraries/tools/techniques/approaches\n\n\n\n\n\n\n\n\n\nUmbrella Term\nConcepts\nSpecific Skills\n\n\n\n\nCoding\n\nVariables\nControl Flow\nAlgorithms\n\n\nPython\nR\nJavaScript\n\n\n\nGIS\n\nProjections\nVector vs.¬†Raster\nSpatial Data Formats (shapefiles, .geojson)\n\n\nArcGIS\nGeoPandas (Python)\nsf (R)"
  },
  {
    "objectID": "w01/slides.html#arcgis",
    "href": "w01/slides.html#arcgis",
    "title": "Week 1: Introduction to GIS",
    "section": "ArcGIS‚Ä¶",
    "text": "ArcGIS‚Ä¶\n\nFor info on Georgetown‚Äôs provision of ArcGIS (Online, Pro, and Desktop), see the Library Guide\n\n\nUkraine Level-1 Administrative Regions Map (see CDTO talk)"
  },
  {
    "objectID": "w01/slides.html#then-why-cant-we-just-use-arcgis",
    "href": "w01/slides.html#then-why-cant-we-just-use-arcgis",
    "title": "Week 1: Introduction to GIS",
    "section": "Then‚Ä¶ Why Can‚Äôt We Just Use ArcGIS?",
    "text": "Then‚Ä¶ Why Can‚Äôt We Just Use ArcGIS?\nAnalogy from non-geospatial data science:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText\nDrawn Map\n‚Üí\nSpeadsheet\nDigital Map\n‚Üí\nEquations\nMaps w/ArcGIS\n‚Üí\nCode\nThis Class\n\n\n\n\n Start writing\n\n\ninfo.txt\n\nI gave Ana $3, then Ana paid me back $2. [...]\n\n Realize there‚Äôs regularity/structure ü§î\n Start entering info in rows\n\n\n\nFr\nTo\nAmt\nBal\n\n\n\n\nMe\nAna\n$3\n-$3\n\n\nAna\nMe\n$2\n-$1\n\n\n\n Realize you‚Äôre manually computing things that could be automated ü§î\n Start using equations\n\n\n\nFr\nTo\nAmt\nBal\n\n\n\n\nMe\nAna\n$3\n=0-C1\n\n\nAna\nMe\n$2\n=D1-C2\n\n\n\n Realize you need fancier equations, and/or need to coordinate with inputs (APIs), outputs (plotting libraries) ü§î\n Write code\n\n\nplot_balance.py\n\nimport pandas as pd\ndf = pd.read_csv(...)\ncalc_weekly_balance()\ndf.plot()\n\n \n Profit üí≤üí∞ü§ëüí∞üí≤"
  },
  {
    "objectID": "w01/slides.html#the-spatial-data-science-universe",
    "href": "w01/slides.html#the-spatial-data-science-universe",
    "title": "Week 1: Introduction to GIS",
    "section": "The Spatial Data Science Universe",
    "text": "The Spatial Data Science Universe\n\n\nWe‚Äôll cover key pieces:  GDAL (Geospatial Data Abstraction Library),  PROJ to convert between projections,  GEOS for computational geometry"
  },
  {
    "objectID": "w01/slides.html#pedagogical-principles",
    "href": "w01/slides.html#pedagogical-principles",
    "title": "Week 1: Introduction to GIS",
    "section": "Pedagogical Principles",
    "text": "Pedagogical Principles\n\nThere‚Äôs literally no such thing as ‚Äúintelligence‚Äù\nAnyone is capable of learning anything (neural plasticity)\nGrowth mindset: ‚ÄúI can‚Äôt do this‚Äù \\(\\leadsto\\) ‚ÄúI can‚Äôt do this yet!‚Äù\nThe point of a class is learning: understanding something about the world, either (a) For its own sake (end in itself) or (b) Because it‚Äôs relevant to something you care about (means to an end)\n\n\n\nOur teaching should be governed, not by a desire to make students learn things, but by the endeavor to keep burning within them that light which is called curiosity. (Montessori 1916)"
  },
  {
    "objectID": "w01/slides.html#chatgpt-and-whatnot",
    "href": "w01/slides.html#chatgpt-and-whatnot",
    "title": "Week 1: Introduction to GIS",
    "section": "ChatGPT and Whatnot",
    "text": "ChatGPT and Whatnot\n\nIf you feel like ChatGPT will help you learn something in the course, then use it!\nIf you feel like you‚Äôre using it as a ‚Äúcrutch‚Äù, try to hold yourself accountable for not using it!\n\n\n\n\n\n\n\n\nTake the time/energy you're using to worry about...\nUse it instead to worry about...\n\n\n\n\n\nChatGPT\nCollaboration Policies\nPlagiarism\n\nLearning GIS"
  },
  {
    "objectID": "w01/slides.html#on-not-worrying-about-prereqs",
    "href": "w01/slides.html#on-not-worrying-about-prereqs",
    "title": "Week 1: Introduction to GIS",
    "section": "On Not Worrying About Prereqs",
    "text": "On Not Worrying About Prereqs\n\nI genuinely believe that I can make the course accessible to you, meeting you wherever you‚Äôre at, no matter what!\nEveryone learns at their own pace (who says 14 weeks is ‚Äúcorrect‚Äù amount of time to learn GIS?), and I structure my courses as best as I possibly can to adapt to your pace\n\\(\\Rightarrow\\) Assessments (HW, Midterm) valuable in two ways:\n[Valuable for you] As an accountability mechanism to make sure you‚Äôre learn the material (how do we know when we‚Äôve learned something? When we can answer questions about it / use it to accomplish things!)\n[Valuable for me] For assessing and updating pace"
  },
  {
    "objectID": "w01/slides.html#r-andor-python-andor-js",
    "href": "w01/slides.html#r-andor-python-andor-js",
    "title": "Week 1: Introduction to GIS",
    "section": "R and/or Python and/or JS",
    "text": "R and/or Python and/or JS\n\nMy Geometry vs.¬†Algebra Rant‚Ä¶ Euclid‚Äôs Elements, Book VI, Proposition 28.\nThe problem: Divide a given straight line so that the rectangle contained by its segments may be equal to a given area, not exceeding the square of half the line.\n\n\n\nGeometers solved w/geometry (300 BC)‚Ä¶\n\n\n\n\n\n\n‚Ä¶Algebraists solved w/algebra (2000 BC)‚Ä¶\n\\[\n\\begin{align*}\n&ax^2 + bx + c = 0 \\\\\n\\Rightarrow \\; & x_+ = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}\n\\end{align*}\n\\]\n‚Ä¶From 1637 onwards, whichever is easier! ü§Øü§Øü§Ø (Isomorphism)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFig¬†1: Circle with radius 1? Or \\((x,y)\\) satisfying \\(x^2 + y^2 = 1\\)?"
  },
  {
    "objectID": "w01/slides.html#learning-how-to-learn",
    "href": "w01/slides.html#learning-how-to-learn",
    "title": "Week 1: Introduction to GIS",
    "section": "Learning How To Learn",
    "text": "Learning How To Learn\n\n\n\n\n\n\nFig¬†2: From The Carter (Documentary)"
  },
  {
    "objectID": "w01/slides.html#hes-literally-extremely-correct",
    "href": "w01/slides.html#hes-literally-extremely-correct",
    "title": "Week 1: Introduction to GIS",
    "section": "He‚Äôs Literally Extremely Correct!",
    "text": "He‚Äôs Literally Extremely Correct!\n\nFrom Elsevier Osmosis: Spaced Repetition"
  },
  {
    "objectID": "w01/slides.html#our-first-map-polygons",
    "href": "w01/slides.html#our-first-map-polygons",
    "title": "Week 1: Introduction to GIS",
    "section": "Our First Map: Polygons!",
    "text": "Our First Map: Polygons!\n(Quick demo adapted from Sherry Xie‚Äôs R Consortium Workshop: Analyzing Geospatial Data in R, using DC rather than Philadelphia open data.)\n\n\nCode\nlibrary(sf)\n# Load DC tracts data\ndc_sf_fpath &lt;- \"data/DC_Census_2020/Census_Tracts_in_2020.shp\"\ndc_sf &lt;- st_read(dc_sf_fpath);\n\n\nReading layer `Census_Tracts_in_2020' from data source \n  `/Users/jpj/gtown-local/ppol6805/w01/data/DC_Census_2020/Census_Tracts_in_2020.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 206 features and 315 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8584933 ymin: 4691871 xmax: -8561515 ymax: 4721078\nProjected CRS: WGS 84 / Pseudo-Mercator\n\n\nCode\ncols_to_keep &lt;- c(\"OBJECTID\", \"TRACT\", \"GEOID\", \"ALAND\", \"AWATER\", \"STUSAB\", \"SUMLEV\", \"GEOCODE\", \"STATE\", \"NAME\", \"POP100\", \"HU100\", \"geometry\")\ndc_sf &lt;- dc_sf |&gt; select(cols_to_keep)"
  },
  {
    "objectID": "w01/slides.html#sf-objects",
    "href": "w01/slides.html#sf-objects",
    "title": "Week 1: Introduction to GIS",
    "section": "sf Objects",
    "text": "sf Objects\ndc_sf is an object of type sf (short for ‚Äúsimple feature‚Äù), which extends data.frame, and contains features which have type POLYGON\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8577962 ymin: 4708107 xmax: -8572564 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n  OBJECTID  TRACT       GEOID  ALAND AWATER STUSAB SUMLEV     GEOCODE STATE\n1        1 002002 11001002002 849376      0     DC    140 11001002002    11\n2        2 002101 11001002101 600992      0     DC    140 11001002101    11\n3        3 002102 11001002102 725975      0     DC    140 11001002102    11\n4        4 002201 11001002201 415173      0     DC    140 11001002201    11\n5        5 002202 11001002202 698895    566     DC    140 11001002202    11\n6        6 000101 11001000101 199776   5261     DC    140 11001000101    11\n                NAME POP100 HU100                       geometry\n1 Census Tract 20.02   4072  1532 POLYGON ((-8575655 4714476,...\n2 Census Tract 21.01   5687  2335 POLYGON ((-8574745 4715676,...\n3 Census Tract 21.02   5099  2221 POLYGON ((-8573824 4715684,...\n4 Census Tract 22.01   3485  1229 POLYGON ((-8574654 4714781,...\n5 Census Tract 22.02   3339  1454 POLYGON ((-8573792 4714811,...\n6  Census Tract 1.01   1406   999 POLYGON ((-8577962 4708867,..."
  },
  {
    "objectID": "w01/slides.html#working-with-sf-objects",
    "href": "w01/slides.html#working-with-sf-objects",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\nWith some rare but important exceptions (which we‚Äôll learn!), can be used just like a data.frame / tibble:\n\n\nCode\nstr(dc_sf)   # view structure\n\n\nClasses 'sf' and 'data.frame':  206 obs. of  13 variables:\n $ OBJECTID: int  1 2 3 4 5 6 7 8 9 10 ...\n $ TRACT   : chr  \"002002\" \"002101\" \"002102\" \"002201\" ...\n $ GEOID   : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ ALAND   : int  849376 600992 725975 415173 698895 199776 1706484 505004 776435 1042157 ...\n $ AWATER  : int  0 0 0 0 566 5261 516665 0 439661 2305 ...\n $ STUSAB  : chr  \"DC\" \"DC\" \"DC\" \"DC\" ...\n $ SUMLEV  : int  140 140 140 140 140 140 140 140 140 140 ...\n $ GEOCODE : chr  \"11001002002\" \"11001002101\" \"11001002102\" \"11001002201\" ...\n $ STATE   : int  11 11 11 11 11 11 11 11 11 11 ...\n $ NAME    : chr  \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\" \"Census Tract 22.01\" ...\n $ POP100  : int  4072 5687 5099 3485 3339 1406 3417 4108 4672 6161 ...\n $ HU100   : int  1532 2335 2221 1229 1454 999 2053 11 2169 2845 ...\n $ geometry:sfc_POLYGON of length 206; first list element: List of 1\n  ..$ : num [1:155, 1:2] -8575655 -8575655 -8575655 -8575655 -8575655 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:12] \"OBJECTID\" \"TRACT\" \"GEOID\" \"ALAND\" ..."
  },
  {
    "objectID": "w01/slides.html#working-with-sf-objects-1",
    "href": "w01/slides.html#working-with-sf-objects-1",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf)  # view first several rows\n\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8577962 ymin: 4708107 xmax: -8572564 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n  OBJECTID  TRACT       GEOID  ALAND AWATER STUSAB SUMLEV     GEOCODE STATE\n1        1 002002 11001002002 849376      0     DC    140 11001002002    11\n2        2 002101 11001002101 600992      0     DC    140 11001002101    11\n3        3 002102 11001002102 725975      0     DC    140 11001002102    11\n4        4 002201 11001002201 415173      0     DC    140 11001002201    11\n5        5 002202 11001002202 698895    566     DC    140 11001002202    11\n6        6 000101 11001000101 199776   5261     DC    140 11001000101    11\n                NAME POP100 HU100                       geometry\n1 Census Tract 20.02   4072  1532 POLYGON ((-8575655 4714476,...\n2 Census Tract 21.01   5687  2335 POLYGON ((-8574745 4715676,...\n3 Census Tract 21.02   5099  2221 POLYGON ((-8573824 4715684,...\n4 Census Tract 22.01   3485  1229 POLYGON ((-8574654 4714781,...\n5 Census Tract 22.02   3339  1454 POLYGON ((-8573792 4714811,...\n6  Census Tract 1.01   1406   999 POLYGON ((-8577962 4708867,..."
  },
  {
    "objectID": "w01/slides.html#working-with-sf-objects-2",
    "href": "w01/slides.html#working-with-sf-objects-2",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\ndim(dc_sf)   # view dimensions\n\n\n[1] 206  13\n\n\nCode\ndc_sf[1,]    # select first row\n\n\nSimple feature collection with 1 feature and 12 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8575656 ymin: 4713958 xmax: -8574562 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n  OBJECTID  TRACT       GEOID  ALAND AWATER STUSAB SUMLEV     GEOCODE STATE\n1        1 002002 11001002002 849376      0     DC    140 11001002002    11\n                NAME POP100 HU100                       geometry\n1 Census Tract 20.02   4072  1532 POLYGON ((-8575655 4714476,..."
  },
  {
    "objectID": "w01/slides.html#working-with-sf-objects-3",
    "href": "w01/slides.html#working-with-sf-objects-3",
    "title": "Week 1: Introduction to GIS",
    "section": "Working With sf Objects",
    "text": "Working With sf Objects\n\n\nCode\nhead(dc_sf$NAME)  # select column by name  \n\n\n[1] \"Census Tract 20.02\" \"Census Tract 21.01\" \"Census Tract 21.02\"\n[4] \"Census Tract 22.01\" \"Census Tract 22.02\" \"Census Tract 1.01\" \n\n\nCode\nhead(dc_sf[,4])         # select column by number\n\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -8577962 ymin: 4708107 xmax: -8572564 ymax: 4716136\nProjected CRS: WGS 84 / Pseudo-Mercator\n   ALAND                       geometry\n1 849376 POLYGON ((-8575655 4714476,...\n2 600992 POLYGON ((-8574745 4715676,...\n3 725975 POLYGON ((-8573824 4715684,...\n4 415173 POLYGON ((-8574654 4714781,...\n5 698895 POLYGON ((-8573792 4714811,...\n6 199776 POLYGON ((-8577962 4708867,..."
  },
  {
    "objectID": "w01/slides.html#and-actually-displaying-the-map",
    "href": "w01/slides.html#and-actually-displaying-the-map",
    "title": "Week 1: Introduction to GIS",
    "section": "And‚Ä¶ Actually Displaying the Map!",
    "text": "And‚Ä¶ Actually Displaying the Map!\n\n\nCode\n# We can extract the geometry with the st_geometry function\ndc_geo &lt;- st_geometry(dc_sf)\n#pt_geo\n\n# Plot the geometry with base R's plot() function\nplot(dc_geo)"
  },
  {
    "objectID": "w01/slides.html#key-notation-definition",
    "href": "w01/slides.html#key-notation-definition",
    "title": "Week 1: Introduction to GIS",
    "section": "Key Notation / Definition",
    "text": "Key Notation / Definition\n\n\n\\(d\\)-Dimensional ‚ÄúSpatial Process‚Äù (Schabenberger and Gotway 2004, 6)\n\n\\[\n\\text{Data} = \\left\\{Z(\\mathbf{s}) \\mid \\mathbf{s} \\in D \\subset \\mathbb{R}^d\\right\\}\n\\]\n\n\\(d &gt; 1\\): Data forms a Random Field (this class: \\(d = 2\\)!)\n\n\n\n\n\n\n\n\n\n\n\n\nGeostatistical Data\nLattice/Region Data\nPoint Pattern\n\n\n\n\nCriteria\nFixed \\(D\\), Continuous\nFixed \\(D\\), Discrete\nRandom subset \\(D^* \\subseteq D\\)\n\n\nInterest\nInfer non-observed parts of \\(D\\)\nAutocorrelation, clustering\nPoint-generating process\n\n\nExample\n\n\\(N\\) trees \\(\\mathbf{s}_1, \\mathbf{s}_2, \\ldots, \\mathbf{s}_N\\), observed within a sample window \\(D \\subset \\mathbb{R}^2\\), (\\(D\\) some finite plot of land)\n\\(Z(\\mathbf{s}_i)\\): Attribute(s) at site \\(\\mathbf{s}_i\\)\nExample: Height. \\(Z(\\mathbf{s}_1) = 500\\text{m}\\), \\(Z(\\mathbf{s}_2) = 850\\text{m}\\), \\(\\ldots\\)\n\n\n\\(Z(\\mathbf{s})\\) observed over \\(N \\times N\\) grid of plots\n\\(\\Rightarrow\\) Contiguity, Neighbors (next section of slides!)\n\\(\\Rightarrow\\) Autocorrelation: Are points around \\(\\mathbf{s}_i\\) likely to have values similar to \\(Z(\\mathbf{s}_i)\\)?\n\n\nUnknown number of lightning strikes \\(\\mathbf{s}_1, \\mathbf{s}_2, \\ldots\\)\nContrast with geostatistical: all of \\(D\\) is observed, but what determines the subset \\(D^*\\) where events occur?\n‚ÄúUnmarked‚Äù: Just locations\n‚ÄúMarked‚Äù: Locations+info (e.g., intensity of strike)"
  },
  {
    "objectID": "w01/slides.html#spatial-randomness",
    "href": "w01/slides.html#spatial-randomness",
    "title": "Week 1: Introduction to GIS",
    "section": "Spatial Randomness",
    "text": "Spatial Randomness\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed \\(N\\)\n60\n\n60\n\n60"
  },
  {
    "objectID": "w01/slides.html#complete-spatial-randomness-csr",
    "href": "w01/slides.html#complete-spatial-randomness-csr",
    "title": "Week 1: Introduction to GIS",
    "section": "Complete Spatial Randomness (CSR)",
    "text": "Complete Spatial Randomness (CSR)\n\n\n\n\n\n\n\n\n\n\n\nAutocorrelation\n\\(I = -1\\)\n‚Üê\n\\(I = 0\\)\n‚Üí\n\\(I = 1\\)\n\n\n\n\nDescription\nNegative Autocorr\n\nNo Autocorr\n\nPositive Autocorr\n\n\nEvent at \\(\\mathbf{s} = (x,y)\\) Implies\nLess likely to find another point nearby\n\nNo information about nearby points\n\nMore likely to find another point nearby\n\n\nResulting Pattern\nRegularity\n\nReg/Clustered Mix\n\nClustering\n\n\nProcess(es) Which Could Produce Pattern\n1st Order: Random within even-spaced grid2nd Order: Competition\n\n1st Order: i.i.d. points2nd Order: i.i.d. distances\n\n1st Order: Tasty food at clust centers2nd Order: Cooperation\n\n\nFixed Intensity \\(\\lambda\\)\n60\n\n60\n\n60\n\n\nRandom \\(N\\)"
  },
  {
    "objectID": "w01/slides.html#references",
    "href": "w01/slides.html#references",
    "title": "Week 1: Introduction to GIS",
    "section": "References",
    "text": "References\n\n\nMontessori, Maria. 1916. Spontaneous Activity in Education: A Basic Guide to the Montessori Methods of Learning in the Classroom. Lulu Press.\n\n\nRobert, Am√©lie. 2016. ‚ÄúAt the Heart of the Vietnam War: Herbicides, Napalm and Bulldozers Against the A L∆∞·ªõi Mountains.‚Äù Journal of Alpine Research Revue de G√©ographie Alpine, no. 104-1 (April). https://doi.org/10.4000/rga.3266.\n\n\nSchabenberger, Oliver, and Carol A. Gotway. 2004. Statistical Methods for Spatial Data Analysis. CRC Press. https://www.dropbox.com/scl/fi/25gj53qitsdzw9kvcvfjf/Oliver-Schabenberger-Carol-A.-Gotway-Statistical-methods-for-spatial-data-analysis.pdf?rlkey=p5ih232gmxzm3zstvszux2big&dl=1."
  },
  {
    "objectID": "git_submodules.html",
    "href": "git_submodules.html",
    "title": "Git Submodules - Basic Explanation",
    "section": "",
    "text": "Git Submodules - Basic Explanation\n\nWhy submodules?\nIn Git you can add a submodule to a repository. This is basically a repository embedded in your main repository. This can be very useful. A couple of usecases of submodules:\n\nSeparate big codebases into multiple repositories.\nUseful if you have a big project that contains multiple subprojects. You can make every subproject a submodule. This way you‚Äôll have a cleaner Git log, because the commits are specific to a certain submodule.\nRe-use the submodule in multiple parent repositories.\nUseful if you have multiple repositories that share a common component. With this approach you can easily update that shared component in all the repositories that added them as a submodule. This is a lot more convienient than copy-pasting the code into the repositories.\n\n\n\nBasics\nWhen you add a submodule in Git, you don‚Äôt add the code of the submodule to the main repository, you only add information about the submodule that is added to the main repository. This information describes which commit the submodule is pointing at. This way, the submodule‚Äôs code won‚Äôt automatically be updated if the submodule‚Äôs repository is updated. This is good, because your main repository might not work with the latest commit of the submodule; it prevents unexpected behaviour.\n\n\nAdding a submodule\nYou can add a submodule to a repository like this:\ngit submodule add git@github.com:path_to/submodule.git path-to-submodule\ngit submodule add jpowerj@github.com:dsan-globals.git dsan-globals\nWith default configuration, this will check out the code of the submodule.git repository to the path-to-submodule directory, and will add information to the main repository about this submodule, which contains the commit the submodule points to, which will be the current commit of the default branch (usually the master branch) at the time this command is executed.\nAfter this operation, if you do a git status you‚Äôll see two files in the Changes to be committed list: the .gitmodules file and the path to the submodule. When you commit and push these files, you‚Äôll commit/push the submodule to the origin.\n\n\nGetting the submodule‚Äôs code\nIf a new submodule is created by one person, the other people in the team need to initiate this submodule. First you have to get the information about the submodule, this is retrieved by a normal git pull. If there are new submodules you‚Äôll see it in the output of git pull. Then you‚Äôll have to initiate them with:\ngit submodule init\nThis will pull all the code from the submodule and place it in the directory that it‚Äôs configured to.\nIf you‚Äôve cloned a repository that makes use of submodules, you should also run this command to get the submodule‚Äôs code. This is not automatically done by git clone. However, if you add the --recurse-submodules flag, it will.\n\n\nPushing updates in the submodule\nThe submodule is just a separate repository. If you want to make changes to it, you should make the changes in its repository and push them like in a regular Git repository: Just execute the git commands in the submodule‚Äôs directory. However, you should also let the main repository know that you‚Äôve updated the submodule‚Äôs repository, and make it use the new commit of the repository of the submodule. Because if you make new commits inside a submodule, the main repository will still point to the old commit.\nIf there are changes in the submodule‚Äôs repository, and you do a git status in the main repository, then the submodule will be in the Changes not staged for commit list, and will have the text (modified content) behind it. This means that the code of the submodule is checked out on a different commit than the main repository is pointing to. To make the main repository point to this new commit, you should create another commit in the main repository.\nThe next sections describe different scenarios on doing this.\n\nMake changes inside a submodule\n\ncd inside the submodule directory.\nMake the desired changes.\ngit commit the new changes.\ngit push the new commit.\ncd back to the main repository.\nIn git status you‚Äôll see that the submodule directory is modified.\nIn git diff you‚Äôll see the old and new commit pointers.\nWhen you git commit in the main repository, it will update the pointer.\n\n\n\nUpdate the submodule pointer to a different commit\n\ncd inside the submodule directory.\ngit checkout the branch/commit you want to point to.\ncd back to the main repository.\nIn git status you‚Äôll see that the submodule directory is modified.\nIn git diff you‚Äôll see the old and new commit pointers.\nWhen you git commit in the main repository, it will update the pointer.\n\n\n\nIf someone else updated the submodule pointer\nIf someone updated a submodule, the other team-members should update the code of their submodules. This is not automatically done by git pull, because with git pull it only retrieves the information that the submodule is pointing to another commit, but doesn‚Äôt update the submodule‚Äôs code.\nTo see the current commits that are checked out for all your submodules:\ngit submodule status\nTo update the code of your submodules:\ngit submodule update\nIf a submodule is not initiated yet, add the --init flag. If any submodule has submodules itself, you can add the --recursive flag to recursively init and update submodules.\n\nWhat happens if you don‚Äôt run this command?\nIf you don‚Äôt run this command, the code of your submodule is checked out to an old commit. When you do git status in the main repository, you will see the submodule in the Changes not staged for commit list with the text (modified content) behind it. If you would do a git status inside the submodule, it would say HEAD detached at &lt;commit-hash&gt;. This is not because you changed the submodule‚Äôs code, but because its code is checked out to a different commit than the commit used in the main repository. So in the main repo, Git sees this as a change, but actually you just didn‚Äôt update the submodule. So if you‚Äôre working with submodules, don‚Äôt forget to keep your submodules up-to-date.\n\n\n\n\nMaking it easier for everyone\nIt is sometimes annoying if you forget to initiate and update your submodules. Fortunately, there are some tricks to make it easier:\ngit clone --recurse-submodules\nThis will clone a repository and also init / update any possible submodules the repository has.\ngit pull --recurse-submodules\nThis will pull the main repository and also it‚Äôs submodules.\nAnd you can make it easier with aliases:\ngit config --global alias.clone-all 'clone --recurse-submodules'\ngit config --global alias.pull-all 'pull --recurse-submodules'"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Additional Resources",
    "section": "",
    "text": "I‚Äôm going to try to dump everything I used to develop the course materials here‚Äîsome of it I drew on explicitly (using images from books, for example), and the rest of it seeped into my mind implicitly over the course of preparing the materials. Explore them to see if their different approaches ‚Äúclick‚Äù in your mind more than my approach does!",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#the-core-textbooks",
    "href": "resources.html#the-core-textbooks",
    "title": "Additional Resources",
    "section": "The ‚ÄúCore‚Äù Textbooks",
    "text": "The ‚ÄúCore‚Äù Textbooks\n\n\n\n\n\n\n\nTip The Maps Book: Monmonier (2018)\n\n\n\nMark Monmonier, How To Lie With Maps [pdf, epub]\n\n\n\n\n\n\nThis is the perfect book for anyone worried about the‚Ä¶ maps-specific part of the course. For example, if you‚Äôre already comfortable coding in R, but perhaps you haven‚Äôt taken a course on principles of data visualization (like, say, DSAN 5200), this is a great book to focus on in the early weeks of the course!\n\n\n\n\n\n\n\n\n\n\n\nTip The Point Patterns Book: Baddeley, Rubak, and Turner (2015)\n\n\n\nBaddeley, Rubak, and Turner, Spatial Point Patterns: Methodology and Applications with R [pdf]\n\n\n\n\n\n\nI first started reading this book only because it was the ‚Äúcompanion‚Äù book for the spatstat library‚Ä¶ But, it ended up being hands-down my favorite GIS book of all time! It ends up having at least 50% of the course material in it, and definitely contains everything you would ever want to know about modeling point processes specifically (for the other 50% of the course, on areal and geospatial data, see Waller and Gotway (2004) below)\n\n\n\n\n\n\n\n\n\n\n\nTip The Spatial Stats Book: Waller and Gotway (2004)\n\n\n\nWaller and Gotway, Applied Spatial Statistics for Public Health Data [pdf]\n\n\n\n\n\n\nDon‚Äôt let the name fool you, this book contains a full-on tour through all major spatial-statistical methods! Each method is illustrated, in this case, with an example drawn from public health, but imo it‚Äôs immensely valuable regardless of what field you‚Äôre interested in (as you go through it, you can think about how the public health data they use may or may not be ‚Äúanalagous‚Äù to data you may find yourself using in that field!)\n\n\n\n\n\n\n\n\n\n\n\nTip The Spatial Regression Book: Ward and Gleditsch (2018)\n\n\n\nWard and Gleditsch, An Introduction to Spatial Regression Models in the Social Sciences [pdf]\n\n\n\n\n\n\nThis one is a new addition to the course, but feels like an important addition! Because, you could ‚Äúpiece together‚Äù how to estimate spatial regression models from Baddeley, Rubak, and Turner (2015) and Waller and Gotway (2004) mentioned above (which is what students did in previous versions of the course), but this book packs a full-on self-contained guide to how these models work into only about 80 pages. So, whereas the above books span many different topics in the course, consider this book to be a ‚Äúcompanion guide‚Äù to Homework 4 specifically üòé",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#learning-base-r",
    "href": "resources.html#learning-base-r",
    "title": "Additional Resources",
    "section": "Learning Base R",
    "text": "Learning Base R\nRecall from Week 2 that ‚Äúbase‚Äù R here just means, the pieces of R that are built-in, accessible to anyone with R on their computer. This is the ‚Äúskeleton‚Äù which the GIS-specific libraries we use in this class, such as sf, build upon!\n\nLessons 1 through 9 of Norm Matloff‚Äôs ‚ÄúFasteR‚Äù R tutorial will walk you gently through the basic syntax, data structures, and functions in ‚Äúbase‚Äù R that we‚Äôll build upon as the course progresses!\n\n\nGIS with R\nThe course‚Äôs R material is drawn mainly from the following books, where I‚Äôve tried to put them in order from most-used to least-used (in terms of the slides and assignments!):\n\nMoraga (2024): Spatial Statistics for Data Science: Theory and Practice with R\n\nThis book, along with the video tutorial from Sherrie Xie linked below, will get you up-to-speed on the main topics in this course!\n\nPebesma and Bivand (2023): Spatial Data Science with Applications in R\n\nThis book gets pretty in-depth after the first few chapters, and goes into a level of detail that is probably overkill for this course, but if there is a particular topic you want to pursue for your final project, this is where you can get a detailed account (from the creator of the sf library!)\n\nLovelace, Nowosad, and Muenchow (2024): Geocomputation with R\n\nThis book is almost my first choice, except that the figures and tables and etc. are generated in a kind of opaque way: if you have patience, and you want to reproduce a figure or table from the book as part of your own work, you can go to the book‚Äôs GitHub repository to find the .R scripts, but personally I wasn‚Äôt able to get a lot of them to run due to outdated/deprecated functions and libraries.\n\nComber and Brunsdon (2020): Geographical Data Science and Spatial Data Analysis: An Introduction in R [epub]\n\nI wanted to include this book as well because, if you‚Äôre like me and you read ebooks on a device that requires .epub files‚Ä¶ this is the only GIS book I was able to find that was well-formatted and easy-to-read in EPUB format!\n\n\n\n\nGIS with Python\n\nTenkanen, Heikinheimo, and Whipp (2024): Introduction to Python for Geographic Data Analysis\n\nI found this book even more straightforward and organized as an overview, the only issue is that the portion on Spatial Data Science is not yet finished (as of early September 2024), so for that portion of the course Rey, Arribas-Bel, and Wolf (2023) will be more helpful!\n\nRey, Arribas-Bel, and Wolf (2023): Geographic Data Science with Python\n\nThis book is especially nice if you‚Äôre interested in applying GIS to public policy or the social sciences!\n\nGraser et al. (2025): Geocomputation with Python\n\nThis is the Python companion book to Lovelace, Nowosad, and Muenchow (2024), and is not yet completed, but I wanted to include it here in case you‚Äôre looking for a pair of books where the Python and R content is aligned by chapter\n\n\n\n\nSpatial Statistics / Spatial Data Science\nWhereas the GIS with Python and R resources above are the key texts for this class, these books/resources dive deeper into the mathematical and statistical details of the models we look at towards the second half of the course. Here they‚Äôre ordered from most to least-approachable (for someone just getting started with GIS), based on my subjective experience going through them over the summer!\n\nSchabenberger and Gotway (2004): Statistical Methods for Spatial Data Analysis [pdf]\n\nDespite being among the oldest on this list, this is the book that really ‚Äúclicked‚Äù with me the most! If you‚Äôre like me and the intensive math right at the beginning of Gaetan and Guyon (2009) was a bit scary, for example, this one has much more gentle and slower-paced chapters at the beginning.\n\nGaetan and Guyon (2009): Spatial Statistics and Modeling [pdf]\n\nThis one has a pretty steep learning curve, as it starts right off the bat on the first page with some fairly intensive math introducing concepts like random fields. But, if you were a math major or you‚Äôd really like to know the mathematical underpinnings of the GIS methods we‚Äôll use towards the end of the course, this one may be for you!\n\nBivand, Pebesma, and G√≥mez-Rubio (2013): Applied Spatial Data Analysis with R [pdf]: This one has been superceded by Pebesma and Bivand (2023), discussed in the Using R section above, but I wanted to include it here since it was the textbook I used when first learning GIS with R back in the day‚Ä¶ It is actually double-outdated since, not only is there a newer book but also a newer library, since this book uses the sp library rather than the newer sf library we‚Äôve been using throughout the first few weeks of class!\n\n\n\nCartography and Geodesy\n\nWood and Fels (1992): The Power of Maps [pdf]\n\nI found Chapter 2, Maps Are Embedded in a History They Help Construct, especially helpful!",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#videos",
    "href": "resources.html#videos",
    "title": "Additional Resources",
    "section": "Videos",
    "text": "Videos\n\nFor the quickest and most accessible intro to GIS using R I‚Äôve ever found, you can watch Sherrie Xie‚Äôs R Consortium workshop talk, Analyzing Geospatial Data in R\nFor a high-level overview, that will prepare you well for this course, see Coursera: Introduction to GIS, which is an online version of UC Davis‚Äô Introduction to GIS course.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#libraries",
    "href": "resources.html#libraries",
    "title": "Additional Resources",
    "section": "Libraries",
    "text": "Libraries",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "resources.html#other-courses",
    "href": "resources.html#other-courses",
    "title": "Additional Resources",
    "section": "Other Courses",
    "text": "Other Courses\n\nIf you‚Äôre looking to dive headfirst into more intensive statistical modeling of geospatial (and spatiotemporal) data, definitely check out Data Over Space and Time, a course taught by Cosma Shalizi, a very cool professor of Statistics at Carnegie Mellon University.",
    "crumbs": [
      "Resources"
    ]
  },
  {
    "objectID": "w13/index.html",
    "href": "w13/index.html",
    "title": "Week 13: In-Class Office Hours",
    "section": "",
    "text": "Open slides in new tab ‚Üí",
    "crumbs": [
      "Week 13: Nov 19"
    ]
  },
  {
    "objectID": "w13/index.html#choose-your-own-adventure",
    "href": "w13/index.html#choose-your-own-adventure",
    "title": "Week 13: In-Class Office Hours",
    "section": "Choose Your Own Adventure",
    "text": "Choose Your Own Adventure\n\nBonus HW5A: Re-doing Midterm Q4-Q5 (with new dataset)\n\nYou‚Äôve incurred ‚Äúfixed cost‚Äù of understanding Q1-Q3‚Ä¶\n\\(\\implies\\) Build on this fixed cost and complete ~Q4 + ~Q5 without time limit!\n\nBonus HW5B: Spatial Regression\n\nYour final project uses areal rather than point data‚Ä¶\n\\(\\implies\\) To prepare, do HW5B to learn/practice spatial regression and earn bonus points for doing so!",
    "crumbs": [
      "Week 13: Nov 19"
    ]
  },
  {
    "objectID": "w13/index.html#visualizing-spatial-data",
    "href": "w13/index.html#visualizing-spatial-data",
    "title": "Week 13: In-Class Office Hours",
    "section": "Visualizing Spatial Data",
    "text": "Visualizing Spatial Data\n\nMy recommendation for final presentations: Leaflet",
    "crumbs": [
      "Week 13: Nov 19"
    ]
  },
  {
    "objectID": "w13/index.html#remote-sensed-raster-data",
    "href": "w13/index.html#remote-sensed-raster-data",
    "title": "Week 13: In-Class Office Hours",
    "section": "Remote-Sensed / Raster Data",
    "text": "Remote-Sensed / Raster Data\n\nYou‚Äôve seen (to some extent) terra\nstars: Same group behind sf\nGoogle solar panel data\n.tif files: Dynamically loaded",
    "crumbs": [
      "Week 13: Nov 19"
    ]
  },
  {
    "objectID": "w13/index.html#anonymization-synthetic-datasets",
    "href": "w13/index.html#anonymization-synthetic-datasets",
    "title": "Week 13: In-Class Office Hours",
    "section": "Anonymization / Synthetic Datasets",
    "text": "Anonymization / Synthetic Datasets\n\nDifferential privacy\nUsed by the US Census(!) Since 2020",
    "crumbs": [
      "Week 13: Nov 19"
    ]
  },
  {
    "objectID": "w13/index.html#references",
    "href": "w13/index.html#references",
    "title": "Week 13: In-Class Office Hours",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Week 13: Nov 19"
    ]
  },
  {
    "objectID": "w13/slides.html#choose-your-own-adventure",
    "href": "w13/slides.html#choose-your-own-adventure",
    "title": "Week 13: In-Class Office Hours",
    "section": "Choose Your Own Adventure",
    "text": "Choose Your Own Adventure\n\nBonus HW5A: Re-doing Midterm Q4-Q5 (with new dataset)\n\nYou‚Äôve incurred ‚Äúfixed cost‚Äù of understanding Q1-Q3‚Ä¶\n\\(\\implies\\) Build on this fixed cost and complete ~Q4 + ~Q5 without time limit!\n\nBonus HW5B: Spatial Regression\n\nYour final project uses areal rather than point data‚Ä¶\n\\(\\implies\\) To prepare, do HW5B to learn/practice spatial regression and earn bonus points for doing so!"
  },
  {
    "objectID": "w13/slides.html#visualizing-spatial-data",
    "href": "w13/slides.html#visualizing-spatial-data",
    "title": "Week 13: In-Class Office Hours",
    "section": "Visualizing Spatial Data",
    "text": "Visualizing Spatial Data\n\nMy recommendation for final presentations: Leaflet"
  },
  {
    "objectID": "w13/slides.html#remote-sensed-raster-data",
    "href": "w13/slides.html#remote-sensed-raster-data",
    "title": "Week 13: In-Class Office Hours",
    "section": "Remote-Sensed / Raster Data",
    "text": "Remote-Sensed / Raster Data\n\nYou‚Äôve seen (to some extent) terra\nstars: Same group behind sf\nGoogle solar panel data\n.tif files: Dynamically loaded"
  },
  {
    "objectID": "w13/slides.html#anonymization-synthetic-datasets",
    "href": "w13/slides.html#anonymization-synthetic-datasets",
    "title": "Week 13: In-Class Office Hours",
    "section": "Anonymization / Synthetic Datasets",
    "text": "Anonymization / Synthetic Datasets\n\nDifferential privacy\nUsed by the US Census(!) Since 2020"
  },
  {
    "objectID": "w13/slides.html#references",
    "href": "w13/slides.html#references",
    "title": "Week 13: In-Class Office Hours",
    "section": "References",
    "text": "References"
  }
]